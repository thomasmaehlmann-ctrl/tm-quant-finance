[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "",
    "text": "1 Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“\nHerzlich willkommen zu diesem interaktiven Webbuch, das sich mit den Grundlagen und modernen Ansätzen des quantitativen Portfoliomanagements beschäftigt. Dieses Buch richtet sich an Masterstudierende der Finanzwissenschaften, Young Professionals in der Finanzbranche sowie berufstätige Quantitative Analysten, die ihr Wissen im Bereich Portfoliooptimierung vertiefen und gleichzeitig praxisnah mit Python umsetzen möchten.\nZiel dieses Buches ist es, die Brücke zwischen theoretischem Wissen und praktischer Anwendung zu schlagen. Jedes Kapitel beginnt mit einer klaren Darstellung der theoretischen Grundlagen und führt anschließend in die praktische Umsetzung der Konzepte anhand realer Daten und Python-Code. Sie werden in die Lage versetzt, die vorgestellten Methoden direkt auf eigene Portfolios anzuwenden, eigene Analysen durchzuführen und die Python-Beispiele für individuelle Fallstudien anzupassen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#motivation-für-das-buch",
    "href": "index.html#motivation-für-das-buch",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.1 Motivation für das Buch",
    "text": "1.1 Motivation für das Buch\nPortfoliooptimierung ist ein zentrales Thema in der modernen Finanzwirtschaft. Klassische Ansätze wie die Mean-Variance-Optimierung nach Markowitz bieten eine fundierte mathematische Grundlage, haben jedoch in der Praxis oft Einschränkungen:\n\nSchätzfehler bei Inputparametern wie erwarteten Renditen, Kovarianzen und Volatilitäten können zu instabilen und nicht robusten Portfolios führen.\n\nKlassische Optimierungsansätze reagieren empfindlich auf kleine Änderungen in den Daten.\n\nIn der Realität existieren Abhängigkeiten, die über die Standardannahmen hinausgehen und alternative Ansätze erforderlich machen.\n\nUm diese Schwächen zu adressieren, wurden im Laufe der Zeit zahlreiche Erweiterungen entwickelt. Dazu gehören beispielsweise geschrumpfte Schätzer, das Black-Litterman-Modell, Portfolio-Resampling, Risk-Parity-Strategien sowie Ansätze, die den Fokus auf die Risikoverteilung legen und die Schätzung der erwarteten Rendite vermeiden.\nDie Motivation dieses Buches besteht darin, diese Methoden praktisch erfahrbar zu machen und zu zeigen, wie sie in der täglichen Arbeit eines quantitativen Portfoliomanagers umgesetzt werden können. Durch den Einsatz von Python lernen die Leser nicht nur die Theorie, sondern entwickeln zugleich praktische Fähigkeiten, die direkt auf eigene Investmentportfolios übertragen werden können.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#aufbau-des-buches",
    "href": "index.html#aufbau-des-buches",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.2 Aufbau des Buches",
    "text": "1.2 Aufbau des Buches\nDieses Buch ist so strukturiert, dass Theorie und Praxis eng miteinander verzahnt sind. Jedes Kapitel folgt einem konsistenten Aufbau:\n\nTheoretische Grundlagen: Jedes Kapitel beginnt mit der Darstellung der zugrunde liegenden Theorie. Die Konzepte werden schrittweise erklärt, um sowohl die mathematische Logik als auch die wirtschaftliche Intuition zu vermitteln.\n\nFallstudien und Python-Implementierung: Direkt im Anschluss wird die Theorie anhand eines praxisnahen Beispiels umgesetzt. Sie werden reale oder synthetische Datensätze analysieren und die Konzepte in Python implementieren.\n\nCode-Chunks zum Ausprobieren und Anpassen: Alle Python-Beispiele sind modular aufgebaut und können extrahiert oder angepasst werden. So können Sie eigene Analysen durchführen oder die Methoden auf andere Datensätze anwenden.\n\nDie Kapitelübersicht:\n\nWillkommen – Einführung, Motivation, Lernziele und Nutzungshinweise.\n\nGrundlagen der klassischen (absoluten) Portfoliooptimierung – Mean-Variance-Ansatz, Erwartungswert-Varianz-Optimierung, Einschränkungen.\n\nRelative Portfoliooptimierung – Benchmarks, Tracking Error Minimization.\n\nSchätzrisiken in der Portfoliotheorie – Einfluss von Unsicherheiten bei Renditen und Kovarianzen.\n\nVerbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer – Regularisierung von Kovarianzmatrizen und Renditeschätzungen.\n\nDas Black-Litterman-Modell – Integration subjektiver Ansichten und Marktrückschlüsse.\n\nBerücksichtigung des Schätzrisikos: Portfolio-Resampling – Monte-Carlo-Techniken zur Risikominderung.\n\nRisikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite – Risk Parity, Minimum-Variance-Ansätze.\n\nIndex Tracking – Passive Portfolios und Benchmark-Nachbildung.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#lernziele",
    "href": "index.html#lernziele",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.3 Lernziele",
    "text": "1.3 Lernziele\nNach der Lektüre dieses Buches werden Sie in der Lage sein:\n\nKlassische und moderne Methoden der Portfoliooptimierung in Python zu implementieren.\n\nSchätzrisiken zu erkennen und mit geschrumpften Schätzern oder Resampling-Methoden zu mindern.\n\nDas Black-Litterman-Modell anzuwenden und eigene Ansichten in Portfolioentscheidungen zu integrieren.\n\nRisikogesteuerte Ansätze wie Risk Parity zu verstehen und umzusetzen.\n\nIndex-Tracking-Portfolios zu konstruieren und ihre Performance zu evaluieren.\nEigenen Python-Code für individuelle Fallstudien abzuleiten und weiterzuentwickeln.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#voraussetzungen",
    "href": "index.html#voraussetzungen",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.4 Voraussetzungen",
    "text": "1.4 Voraussetzungen\nDieses Buch setzt folgende Kenntnisse voraus:\n\nStatistik und Portfoliotheorie auf Bachelor-Niveau\n\nPython-Grundkenntnisse, insbesondere in den Bibliotheken Pandas und NumPy\n\nGrundverständnis von Finanzdaten, Renditen und Risikoaggregation\n\nSie müssen kein Experte in Machine Learning oder fortgeschrittener Finanzmathematik sein. Das Buch konzentriert sich auf praktische Umsetzung und die Verbindung von Theorie und Python-Anwendungen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#technische-hinweise",
    "href": "index.html#technische-hinweise",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.5 Technische Hinweise",
    "text": "1.5 Technische Hinweise\n\nDie Notebooks sind so aufgebaut, dass sie leicht extrahierbar sind. Sie können Code-Chunks kopieren, ändern und in eigenen Projekten wiederverwenden.\n\nDie verwendeten Datensätze sind entweder öffentlich zugänglich oder für Lehrzwecke synthetisch erzeugt. Die Datensätze liegen den Unterlagen zu diesem Buch bei.\n\nVisualisierungen werden direkt in der Ausgabe angezeigt, und alle Plots können individuell angepasst werden.\nEmpfehlung: Um die Fallstudien in diesem Buch nachzubauen, laden Sie sich die kostenlose Anaconda Distribution [https://www.anaconda.com/download] herunter und verwenden über den Anaconda Navigator entweder JupyterLab oder Jupyter Notebook als Ihre webbasierte Programmierumgebung.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "index.html#praxisbeispiel-ein-einfaches-portfolio",
    "href": "index.html#praxisbeispiel-ein-einfaches-portfolio",
    "title": "Grundlagen des quantitativen Portfoliomanagements mit Python",
    "section": "1.6 Praxisbeispiel: Ein einfaches Portfolio",
    "text": "1.6 Praxisbeispiel: Ein einfaches Portfolio\nUm Ihnen direkt einen Eindruck zu geben, wie Theorie und Praxis zusammenfließen, betrachten wir ein kleines Beispiel eines Portfolios aus drei Assets:\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# Beispiel-Daten\nreturns = pd.DataFrame({\n    \"Aktie A\": [0.02, 0.03, 0.01],\n    \"Aktie B\": [0.01, 0.02, 0.04],\n    \"Aktie C\": [0.03, 0.01, 0.02]\n})\n\n# Gewichtung\nweights = np.array([0.4, 0.4, 0.2])\n\n# Portfolio-Rendite\nportfolio_return = (returns * weights).sum(axis=1)\nportfolio_return\n\n\n0    0.018\n1    0.022\n2    0.024\ndtype: float64\n\n\nDieses kleine Beispiel zeigt bereits, wie Python die Berechnung von Portfoliorenditen erleichtert und wie flexibel sich die Daten anpassen lassen. In den kommenden Kapiteln werden wir komplexere Methoden einsetzen, die auf diese Grundstruktur aufbauen.\nDieses Kapitel soll Sie motivieren und vorbereiten. Ab dem nächsten Kapitel starten wir mit den theoretischen Grundlagen der klassischen Portfoliooptimierung, gefolgt von praktischen Fallstudien, die Sie Schritt für Schritt in Python umsetzen werden.\nIch wünsche Ihnen eine inspirierende und lehrreiche Reise durch die Welt des quantitativen Portfoliomanagements!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen zu „Grundlagen des quantitativen Portfoliomanagements mit Python“</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html",
    "href": "kapitel1a.html",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "",
    "text": "2.1 \\((\\mu-\\sigma)\\)-effiziente Portfolios ohne risikoloses Asset\nGegenstand der Portfoliobildung bzw. Portfoliorealisierung ist die wertmäßige Aufteilung des Anlagebetrages auf die Assets des in Frage kommenden Anlageuniversums.\nBei der Portfoliobildung durch Anwendung von Optimierungsverfahren erfolgt die Bestimmung der optimalen Portfoliostruktur (Anteilsgewichte der Assets) in Bezug auf den jeweils verfolgten Zweck (operationalisiert durch eine Zielfunktion ZF) unter Beachtung eventueller Nebenbedingungen.\nWas sind optimale Portfolios und wie lassen sie sich bestimmen? Markowitz (1952, 1998) beschränkt zur Bewältigung dieses Problems seine Lösung darauf, dass aus der Menge aller möglichen und zulässigen Portfolios diejenigen ausgeschlosen werden, welche eindeutig schlechter sind als andere. Die verbleibenden sogenannten \\((\\mu-\\sigma)\\)-effizienten Portfolios bestimmen sich durch die Auswahl derjenigen Portfolios aus der Menge aller möglichen Portfolios, welche bei gegebenem Erwartungswert der Rendite \\((\\mu_{p})\\) das minimale Risiko (Varianz bzw. Standardabweichung der Rendite - \\(\\sigma^2_{p}\\) bzw. \\(\\sigma_{p}\\)) aufweisen, oder bei gegebenem Risiko die maximale Rendite erwarten lassen. Diese Portfolios werden auch als dominant gegenüber den anderen Portfolios bezeichnet.\nDiese Auswahl effizienter Portfolios basiert jedoch implizit auf zwei zentralen Annahmen:\nDamit unterstellt Markowitz implizit risikoaverse Anleger. Das Dominanzkriterium lässt sich also hier in folgender Weise formulieren:\nEine Anlage (Portfolio) dominiert eine andere, wenn sie\nEin Portfolio wird genau dann effizient genannt, wenn kein anderes Portfolio existiert, welches\nbesitzt. Damit ergibt sich unter Verwendung des Dominanzkriteriums die äquivalente Aussage:\nDie Menge aller effizienten Portfolios wird auch als Rand oder Kurve aller effizienten Portfolios oder kurz Effizienzkurve (“Efficient Frontier”) bezeichnet.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#mu-sigma-effiziente-portfolios-ohne-risikoloses-asset",
    "href": "kapitel1a.html#mu-sigma-effiziente-portfolios-ohne-risikoloses-asset",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "",
    "text": "Investoren bevorzugen mehr Rendite gegenüber weniger.\nWeisen zwei Portfolios dieselbe erwartete Rendite auf, so wird dasjenige mit dem geringeren Risiko gewählt.\n\n\n\n\nbei gleicher Rendite ein geringeres Risiko aufweist, oder\nbei gleichem Risiko eine höhere Rendite besitzt.\n\n\n\nbei gleicher erwarteter Rendite ein geringeres Risiko oder\nbei gleichem Risiko eine höhere erwartete Rendite oder\nbei höherer erwarteter Rendite gleichzeitig ein geringeres Risiko\n\n\n\nEin Portfolio ist genau dann effizient, wenn kein anderes Portfolio existiert, welches dieses dominiert.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#analytische-bestimmung-der-effizienzkurve",
    "href": "kapitel1a.html#analytische-bestimmung-der-effizienzkurve",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.2 Analytische Bestimmung der Effizienzkurve",
    "text": "2.2 Analytische Bestimmung der Effizienzkurve\n\n2.2.1 Allgemein (mit Leerverkaufsverbot)\nUm die Effizienzkurve rechnerisch zu bestimmen, ist das folgende quadratische Optimierungsproblem (in Matrizenschreibweise) zu lösen:\n\\[\n\\begin{split}\n\\\\(OP1) \\quad ZF(w) = \\sigma_P^2=w^{T}\\Sigma w \\rightarrow \\min_{w}!, \\\\\n\\text{unter den Nebenbedingungen}\\quad\n& \\text{(a)}\\ w^{T}\\mu = \\mu_{P}, \\\\\n& \\text{(b)}\\ w^{T}\\iota = 1 \\quad \\text{(Budgetrestriktion)}, \\\\\n& \\text{(c)}\\ w\\geqq 0 \\quad \\text{(Leerverkaufsverbot)},\n\\end{split}\n\\]\nwobei\n\\[\nw = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_N \\end{bmatrix}, \\quad\n\\mu = \\begin{bmatrix} \\mu_1 \\\\ \\vdots \\\\ \\mu_N \\end{bmatrix}, \\quad\n\\Sigma = \\begin{bmatrix} \\sigma_1^2 & \\cdots & \\sigma_{1N} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\sigma_{N1} & \\cdots & \\sigma_N^2 \\\\\n\\end{bmatrix}.\n\\]\n\n\\(\\mu_{P}\\) : beliebige, fest vorgegebene Portfoliorendite\n\\(\\mu\\) : Vektor der erwarteten Assetrenditen\n\\(\\Sigma\\) : zukünftige Varianz-Kovarianzmatrix der Assetrenditen\n\\(\\iota\\) : Einheitsvektor (alle Elemente des Vektors sind eins)\n\nFür eine beliebige, fest vorgegebene Portfoliorendite \\(\\mu_{P}\\) werden also die Gewichte \\(w_{i}\\) (\\(i=1, ..., N\\), und \\(N=\\) Anzahl der Assets im Anlageuniversum) derart bestimmt, dass das resultierende Portfoliorisiko (Varianz der Portfoliorendite) minimal wird. Die Lösung des Optimierungsproblems OP1 liefert einen Punkt \\((\\mu_{P}, \\sigma^2_{p})\\) der Effizienzkurve. Löst man nun das Optimierungsproblem für variierende \\(\\mu_{P}\\), so lässt sich die Effizienzkurve punktweise konstruieren.\n\n\n2.2.2 Diskussion der Nebenbedingungen\nAls mögliche Nebenbedingungen wurden die Budgetrestriktion und die Nichtnegativitätsbedingung (Leerverkaufsverbot) eingeführt. Die Budgetrestriktion beinhaltet die Anforderung, dass die Summe der Einzelgewichte gleich eins ist. Der Investor kann also nicht mehr als den zur Verfügung stehenden Anlagebetrag auf die Anlagen aufteilen. Dies schließt die Aufnahme von Fremdkapital (Leverage) aus. Gleichzeitig wird aber auch die Vollinvestition gefordert. Ist eventuell eine Bargeldhaltung zu berücksichtigen, so ist Bargeld einfach als ein Asset mit erwarteter Rendite und Risiko von Null in das Anlageuniversum zu integrieren.\nDie Möglichkeit von Leerverkäufen wird durch die Nichtnegativitätsanforderung an die Einzelgewichte ausgeschlossen. Dies ist eine in der Praxis übliche Beschränkung, die sich z.B. aufgrund eines gesetzlichen oder satzungsmäßigen Verbots von Leerverkäufen ergeben kann. Unter einem Leerverkauf versteht man den Verkauf eines Wertpapiers, welches sich nicht im Eigentum des Verkäufers befindet, sondern von ihm mittels Wertpapierleihe beschafft wird. Ein Leerverkäufer zielt darauf ab, unter Erwartung fallender Kurse, das Wertpapier später zu einem niedrigeren Kurs erwerben zu können, so dass die Differenz zwischen Kaufkurs und Verkaufkurs die zu entrichtende Leihgebühr überkompensiert.\nFerner kann es eine Vielzahl von weiteren Nebenbedingungen gesetzlicher, statutarischer oder persönlicher Art geben. Hierzu zählen z.B. Mindest- und Höchstbestandsgrenzen für einzelne Assets, zulässige Höchstbestandsgrenzen für Gruppen von Assets, eine geforderte Mindestdividendenrendite des Portfolios, Ausschluss bestimmter Assets (z.B. “Sin Stocks”), Beachtung von Nachhaltigkeitskriterien (z.B. ein Portfoliominimum-ESG-Score), Beschränkung des Umschichtungsvolumens, der Transaktionskosten usw.\nOffensichtlich erschwert das Hinzufügen von (linearen und nichtlinearen) Nebenbedingungen die Lösungsfindung bei der Optimierung. Da bei einem Optimierungsproblem eine hochgradig nichtlineare Zielfunktion mit ebenfalls hochgradig komplexen, nichtlinearen Nebenbedingungen vorliegen kann, lässt sich schon intuitiv vermuten, dass kein gleichermaßen allgemein gültiges wie zugleich effizientes Lösungsverfahren existiert.\n\n\n2.2.3 Sonderfall (ohne Leerverkaufsverbot)\n\n2.2.3.1 Geschlossene Lösung\nIn der Regel lässt sich keine geschlossene Lösung des obigen Optimierungsproblems angeben. Entfällt aber die Nebenbedingung (c), das Leerverkaufsverbot (bzw. die Nichtnegativitätsbedingung), kann über einen Lagrangeansatz die folgende geschlossene Lösung für den optimalen (d.h., varianzminimalen) Portfoliogewichtsvektor \\(w\\) bei gegebener erwarteter Portfoliorendite \\(\\mu_{P}\\) ermittelt werden (siehe z.B. Franzen und Schäfer, 2018, S. 182-189, für die Herleitung)\n\\[\nw =\n\\frac{C\\mu_P-A}{D}\\Sigma^{-1}\\mu + \\frac{B-A\\mu_P}{D}\\Sigma^{-1}\\iota,\n\\]\nwobei\n\\[\nA =\\mu^{T}\\Sigma^{-1}\\iota,\\ B=\\mu^{T}\\Sigma^{-1}\\mu,\\\nC =\\iota^{T}\\Sigma^{-1}\\iota,\\ D = B C - A^2.\n\\]\nDie Beziehung zwischen der gegebenen Portfoliorendite \\(\\mu_P\\) und dem dazugehörigen minimalen Portfoliorisiko \\(\\sigma_P\\) läßt sich dann schreiben als:\n\\[\n\\sigma_P = \\sqrt{\\frac{C\\mu_P^2 - 2A\\mu_P + B}{D}}\n= \\sqrt{\\frac{C}{D}\\left(\\mu_P-\\frac{A}{C}\\right)^2+\\frac1{C}},\n\\]\nund für die \\((\\mu_P-\\sigma_{P})\\)-Effizienzkurve gilt\n\\[ (1) \\quad\n\\mu_P = \\begin{cases}\n\\displaystyle\n\\frac{A + \\sqrt{D(C\\sigma_P^2 - 1)}}{C}, & \\mu_P &gt; \\frac{A}{C}; \\\\\n& \\\\\n\\displaystyle\n\\frac{A - \\sqrt{D(C\\sigma_P^2 - 1)}}{C}, & \\mu_P &lt; \\frac{A}{C}.\n\\end{cases}\n\\]\n\n\n2.2.3.2 Two-Fund Theorem\nIm \\((\\mu-\\sigma)\\)-Koordinatensystem stellen die varianzminimalen Portfolios, die für eine gegebene erwartete Rendite das Risiko (Varianz oder Standardabweichung der Rendite) minimieren, eine Parabel (Möglichkeitskurve - “Envelop”) dar. Der effiziente obere Rand der Parabel ist die Effizienzkurve. Der untere Rand (die “Ineffizienzkurve”) enthält ineffiziente Portfolios, die von den Portfolios des effizienten Rands dominiert werden (diese Portfolios besitzen für ein gegebenes \\(\\sigma_{p}\\) jeweils ein größeres \\(\\mu_{p})\\). Der Scheitelpunkt der Parabel, der den effizienten vom ineffizienten Rand trennt, ist das sogenannte Minimum-Varianz-Portfolio (siehe unten).\nWir können nun zwei Theoreme, die auf Black (1972) und Merton (1972) zurückgehen (siehe hierzu auch Benninga, 2014, Kapitel 9), verwenden, um mit Hilfe zweier beliebiger Basisportfolios auf der Parabel die gesamte Parabel aufzuspannen.\nDas erste Theorem besagt, dass sich die Anteilsgewichte eines jeden Portfolios der Parabel beschreiben lassen durch:\n\\[ (2) \\quad w(c)=\\frac{\\Sigma^{-1}(\\mu-c \\iota)}{\\iota^T[\\Sigma^{-1}(\\mu-c\\iota)]},\\]\nwobei \\(c\\) eine beliebige Konstante und \\(\\iota\\) den Einheitsvektor der Dimension \\(N\\) darstellt. Durch Variation von \\(c\\) erhalten wir unterschiedliche Punkte auf der Parabel. Nun wählen wir zwei beliebige Basisportfolios \\(X\\) und \\(Y\\) auf der Parabel. Für \\(X\\) setzen wir z.B. \\(c=2\\) und für \\(Y\\) \\(c=4\\).\nDas zweite Theorem besagt, gegeben zwei Basisportfolios \\(X\\) und \\(Y\\) auf der Parabel, jedes weitere Portfolio \\(Z\\) (Punkt auf der Parabel) lässt sich als konvexe Kombination von \\(X\\) und \\(Y\\) darstellen: \\(Z=\\alpha X+(1-\\alpha)Y\\), wobei \\(\\alpha\\) eine beliebige Konstante ist. Daraus folgt für die erwartete Rendite und das Risiko von \\(Z\\):\n\\[(3a) \\quad \\mu_{Z} = \\alpha \\mu_{X} + (1-\\alpha) \\mu_{Y} \\]\n\\[(3b) \\quad \\sigma_{Z}=\\sqrt{\\alpha^2 \\sigma^2_{X} + (1-\\alpha^2) \\sigma^2_{Y}+ 2\\alpha (1-\\alpha)Cov(X,Y)} \\]\n\\(Cov(X,Y)\\) bezeichnet hier die Renditekovarianz zwischen den beiden Basisportfolios.\nDie Bestimmung der Parabel der varianzminimalen Portfolios (effizienter + ineffizienter Rand) anhand des Two-Fund Theorems erfordert somit die folgenden Schritte:\n\nWahl der Basisportfolios \\(X\\) und \\(Y\\) durch die Festlegung zweier beliebiger Werte für \\(c\\).\nBestimmung der Anteilsgewichte von \\(X\\) und \\(Y\\) anhand Gleichung (2).\nErmittlung der erwarteten Rendite, Varianz der Rendite und der Renditekovarianz zwischen \\(X\\) und \\(Y\\).\nFür eine große Zahl unterschiedlicher Werte für \\(\\alpha\\): Berechnung der erwarteten Rendite und der Renditevarianz für \\(Z\\) gemäß der Gleichungen (3a) und (3b).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#zwei-extreme-optimale-portfolios-mvp-und-mep",
    "href": "kapitel1a.html#zwei-extreme-optimale-portfolios-mvp-und-mep",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.3 Zwei extreme optimale Portfolios: MVP und MEP",
    "text": "2.3 Zwei extreme optimale Portfolios: MVP und MEP\nDie Effizienzkurve optimaler, d.h. \\((\\mu-\\sigma)\\)-effizienter, Portfolios wird begrenzt von zwei Extrempositionen, dem Minimum-Varianz-Portfolio (MVP) und dem Maximum-Ertrag-Portfolio (MEP).\nDas MVP ist dasjenige Portfolio, welches das global geringste zu erwartende Risiko aufweist. Das Optimierungsproblem (in Matrizenschreibweise) lautet: \\[\n\\begin{split}\n\\\\(OP2) \\quad ZF(w) = \\sigma_P^2=w^{T}\\Sigma w \\rightarrow \\min_{w}!, \\\\\n\\text{unter den Nebenbedingungen}\\quad\n& \\text{(a)}\\ w^{T}\\iota = 1 \\quad \\text{(Budgetrestriktion)}, \\\\\n& \\text{(b)}\\ w\\geqq 0 \\quad \\text{(Leerverkaufsverbot)},\n\\end{split}\n\\]\nFür das am anderen Ende der Effizienzkurve liegende MEP gilt:\n\\[ (OP3) \\quad ZF(w) = \\mu_{P}=w^{T}\\mu  \\rightarrow \\max_{w}! \\]\nDie obigen Nebenbedingungen gelten hier analog. Für das MEP bildet das Portfolio folglich die Lösung, welches zu 100% aus dem Asset mit der höchsten zu erwartenden Rendite besteht.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#einführung-eines-risikolosen-assets",
    "href": "kapitel1a.html#einführung-eines-risikolosen-assets",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.4 Einführung eines risikolosen Assets",
    "text": "2.4 Einführung eines risikolosen Assets\nDas Problem der Bestimmung aller effizienten Portfolios kann unter Anwendung der Tobin-Separation vereinfacht werden. Diese ermöglicht es, durch Einführung einer risikofreien Anlage, nur noch ein effizientes Portfolio bestimmen zu müssen. Die Einführung einer risikolosen Anlagemöglichkeit mit Zinssatz \\(r_{f}\\) führt zu einem modifizierten Problem: Der Anleger hat nun die Möglichkeit, Mischportfolios aus der risikolosen Anlagemöglichkeit und einem beliebigen Portfolio auf der Effizienzkurve zu bilden, z.B. mit dem Portfolio P. Die sich dann ergebenden \\((\\mu-\\sigma)\\)-Kombinationen für variierende Mischungsverhältnisse von \\(r_{f}\\) und P liegen auf einer Geraden. Ziel ist es nun, dasjenige Portfolio TP auf der Effizienzkurve für die Mischung mit \\(r_{f}\\) zu verwenden, für dass die resultierenden Mischportfolios nicht durch Kombinationen von \\(r_{f}\\) mit anderen effizienten Portfolios P dominiert werden.\nDas Portfolio TP wird dabei in folgenden Weise bestimmt:\n\\[\n\\begin{split}\n\\\\(OP4) \\quad ZF(w) =  \\frac{\\mu_p-r_f}{\\sigma_p} \\rightarrow \\max_{w}!, \\\\\n\\text{unter den Nebenbedingungen}\\quad\n& \\text{(a)}\\ w^{T}\\iota = 1 \\quad \\text{(Budgetrestriktion)}, \\\\\n& \\text{(b)}\\ w\\geqq 0 \\quad \\text{(Leerverkaufsverbot)},\n\\end{split}\n\\]\nDas obige Optimierungsproblem OP4 entspricht der Maximierung der Steigung der Geraden durch den Punkt \\(r_{f}\\) einerseits und durch einen durch ein effizientes Portfolio bestimmten Punkt andererseits. Dies ist gleichbedeutend mit der Bestimmung der Tangente an die Effizienzkurve ausgehend vom Punkt \\(r_{f}\\). Der Ausdruck \\(\\frac{\\mu_p-r_f}{\\sigma_p}\\) wird auch als die Sharpe-Ratio des Portfolios \\(P\\) bezeichnet.\nDie sich für den risikoaversen Investor neu ergebende Effizienzline wird durch alle möglichen Kombinationen aus dem Tangentialportfolio TP und der risikofreien Anlage \\(r_{f}\\) gebildet. Für dieses Mischportfolio ergeben sich die erwartete Rendite und dessen Risiko wie folgt:\n\\[\n\\begin{split}\n\\ \\mu_{Misch}=\\alpha\\mu_{TP}+(1-\\alpha)r_{f} \\\n\\text{und}\\\n\\ \\sigma_{Misch}=\\alpha \\sigma_{TP}, \\\n\\end{split}\n\\]\nmit \\(\\alpha=\\) Anteil der Investitionssumme, der in das risikobehaftete Portfolio TP investiert wird.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#bestimmung-des-anlegerindividuell-optimalen-portfolios",
    "href": "kapitel1a.html#bestimmung-des-anlegerindividuell-optimalen-portfolios",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.5 Bestimmung des anlegerindividuell-optimalen Portfolios",
    "text": "2.5 Bestimmung des anlegerindividuell-optimalen Portfolios\nMit der Bestimmung der effizienten Portfolios ist man aber noch nicht am Ziel. Gewünscht ist schlussendlich die Bestimmung eines für den individuellen Anleger optimalen Portfolios (Poddig et al., S. 84).\nIm Rahmen der absoluten Optimierung werden wir die Bestimmung anlegerindividuell-optimaler Portfolios hier nicht behandeln. Wir fokussieren in der folgenden Fallstudie ausschließlich auf die Ermittlung der vollständigen Effizienzkurve. Für die Bestimmung anlegerindividuell-optimaler Portfolios sei auf die nachfolgenden Kapitel verwiesen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#beginn-der-fallstudie",
    "href": "kapitel1a.html#beginn-der-fallstudie",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.6 Beginn der Fallstudie",
    "text": "2.6 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nimport numpy.linalg as la\n\n\n\n2.6.1 Anmerkungen zur Umsetzung der numerischen Optimierung in Python\nWir setzen im Folgenden die numerische Optimierung der jeweils formulierten Zielfunktion (OP1-OP4) unter Nebenbedingungen mit Hilfe der Funktion minimize aus dem Modul scipy.optimize um. Bei der Umsetzung sind einige Besonderheiten zu beachten.\nErstens bietet Scipy eine “Minimieren”-Funktionalität, aber keine “Maximieren”-Funktion. Möchten wir beispielsweise die Sharpe-Ratio im Optimierungsproblem 4 (OP4) maximieren, mag dies auf den ersten Blick wie ein kleines Problem erscheinen, aber es lässt sich leicht lösen, wenn man bedenkt, dass die Maximierung der Sharpe-Ratio analog zur Minimierung der negativen Sharpe-Ratio ist - also buchstäblich nur der Sharpe-Ratio-Wert mit einem vorangestellten Minuszeichen.\nDas grundsätzliche Vorgehen bei der Optimierung ist immer identisch: Zuerst schreiben wir die zu optimierende Zielfunktion als Funktion und definieren dann über das Objekt constraints die Struktur der Nebenbedingungen.\nLassen Sie uns die einzelnen Einträge durchgehen, um sie besser zu verstehen:\nDa wir die SLSQP-Methode in unserer “Minimieren”-Funktion verwenden werden (was für “Sequential Least Squares Programming” steht), muss das constraints Objekt das Format eines Tupels von Dictionaries haben, das die Felder type und fun mit den optionalen Feldern jac und args enthält. Wir brauchen nur die Felder type, fun und args. Ein Tupel ist eine unveränderliche Sequenz fester Länge aus Python-Objekten, eingebettet in runde Klammern () wobei die einzelnen Objekte kommasepariert sind.\nDer type kann entweder eq oder ineq sein, was sich auf equality bzw. inequality bezieht. Das fun bezieht sich auf die Funktion, die die Beschränkung definiert, in unserem Fall die Beschränkung, dass die Summe der Anteilsgewichte Eins sein muss (Budgetrestriktion). Die Art und Weise, wie dies eingegeben werden muss, ist etwas umständlich. Das eq bedeutet, dass wir nach einer Funktion suchen, deren Ausgabewert gleich Null ist (das ist es, worauf sich die Gleichheit bezieht - Gleichheit mit Null). Der einfachste Weg, dies zu erreichen, besteht darin, eine Lambda-Funktion zu erstellen, die die Summe der Portfoliogewichte minus Eins liefert. Die Beschränkung, dass der Ausgabewert dieser Funktion gleich Null sein muss, bedeutet per Definition, dass die Gewichte zu Eins summiert werden müssen.\nÜber das Tuple bounds, das \\(N\\) identische bound=(Mindestbestandsgrenze, Höchstbestandsgrenze) Tuple enthält, legen wir fest, dass jedes einzelne Anteilsgewicht zwischen Null und Eins liegen muss (Leerverkaufsverbot). Die args sind die Argumente, die wir an die Funktion übergeben wollen, die wir zu minimieren versuchen (Zielfunktion) - das sind alle Argumente AUßER dem Anteilsvektor, der natürlich das Zielfunktionsargument ist, das wir zur Optimierung der ZF-Ausgabe ändern.\nÜber die Liste Startgewichte legen wir den Ausgangspunkt für die numerische Suche nach den optimalen Gewichten fest. Der grundlegende Code für die Anwendung der minimize-Optimierungsfunktion sieht demnach folgendermaßen aus:\n\n\nCode\n# basic structure of code for optimization\nconstraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\nbound = (0.0,1.0)\nbounds = tuple(bound for i in range(Anzahl_Assets))\nminimize(Zielfunktion, Startgewichte, args=args,\n               method='SLSQP', bounds=bounds, constraints=constraints)\n\n\nminimize liefert als Ausgabe das Array x mit den optimierten Anteilsgewichten.\n\n\n2.6.2 Laden und Beschreiben der Datenbasis\nDas beispielhafte Anlageuniversum der Fallstudie umfasst zehn Unternehmen aus den folgenden Branchen: Technologie, Gesundheit, Nahrungsmittel, Pharma, Energie sowie Luft- und Raumfahrt. Die Unternehmen sind: Abbott Laboratories (ABT), Boeing Industries (BA), Costco Wholesale (COST), Cisco Systems (CSCO), IBM (IBM), Intel (INTC), Merk (MRK), Microsoft (MSFT), AT&T (T), und Exxon Mobil Corporation (XOM).\nDie Datengrundlage stellen Monatsanfangskurse (“Adjusted Close”) über einen 5-Jahres-Zeitraum vom 1.12.2004 bis zum 1.12.2009 dar. Die Stichprobe enthält somit 61 Zeitreihenbeobachtungen.\n\n\nCode\n# Hier Ihren lokalen Pfad zur Datei 'Kapitel A1' eingeben!\n# cd \"...\"\n\n\n\n\nCode\nframe = pd.read_excel('Kapitel A1.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe.head()\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n2004-12-01\n46.65\n51.77\n48.41\n19.32\n98.58\n23.39\n32.14\n26.72\n25.77\n51.26\n\n\n2005-01-03\n45.02\n50.60\n47.27\n18.04\n93.42\n22.45\n28.05\n26.28\n23.76\n51.60\n\n\n2005-02-01\n45.99\n54.97\n46.59\n17.42\n92.58\n23.99\n31.70\n25.16\n24.06\n63.31\n\n\n2005-03-01\n46.62\n58.46\n44.18\n17.89\n91.38\n23.23\n32.37\n24.17\n23.69\n59.60\n\n\n2005-04-01\n49.16\n59.52\n40.63\n17.27\n76.38\n23.52\n33.90\n25.30\n23.80\n57.03\n\n\n\n\n\n\n\n\n\n2.6.3 Schätzung der Inputdaten für die Optimierung\nAlle oben formulierten Optimierungsprobleme benötigen als Ausgangsdaten den Vektor der erwarteten, zukünftigen Assetrenditen \\(\\mu\\) und die zukünftige Varianz-Kovarianzmatrix \\(\\Sigma\\). Unterschiedliche Methode stehen zur Schätzung dieser Parameter zur Verfügung.\nDie denkbar einfachste Vorgehensweise besteht darin, anhand einer beobachteten Renditereihe ihren historischen Mittelwert und empirische Varianz als Schätzer für den Erwartungswert der Rendite und die zukünftige Varianz zu ermitteln. In gleicher Weise kann man die empirische Kovarianz zweier Renditereihen als Schätzer der zukünftigen Kovarianz berechnen. Diese Vorgehensweise wird auch als einfache historisch basierte Schätzung bezeichnet. Sie wird im Folgenden wegen ihrer leichten Umsetzbarkeit und Anschaulichkeit als Verfahren zur Rendite- bzw. Risikoprognose eingesetzt, obwohl die damit erzielbaren Ergebnisse im Regelfall eher schlecht sind. Die Verwendung begründet sich hier ausschließlich mit der didaktischen Zielsetzung, die verschiedenen Verfahren der Portfoliooptimierung verfahrenstechnisch zu demonstrieren, wofür zwar Prognosen benötigt werden, deren Güte aber für den hier verfolgten Zweck keine Rolle spielt.\nPoddig et al. (2009, S. 116-121) geben einen Überblick über komplexere Methoden zur Prognose von Renditen und Risiken.\nWir berechnen zunächst diskrete Monatsrenditen über frame.pct_change(), erhöhen diese um Eins und berechnen davon den Logarithmus (über die Funktion log1p) um stetige (Log-) Renditen zu erhalten. Hierauf wenden wir die Schätzung an und übertragen die historisch geschätzen (und annualiserten) Mittelwerte und die empirische Varianz-Kovarianzmatrix in die Arrays means und Sigma.\n\n\nCode\n# simple, historical estimation based on log returns\nlog_returns = np.log1p(frame.pct_change().dropna()) \nmeans = log_returns.mean().values*100*12 # annualised\nSigma = log_returns.cov().values*12 # annualised\n\n\n\n\n2.6.4 Anwendung der absoluten Portfoliooptimierung\n\n2.6.4.1 Berechnung des Minimum-Varianz-Portfolios (MVP)\n\n2.6.4.1.1 Ohne Leerverkaufsverbot\nWir beginnen mit der Formulierung der Zielfunktion des Optimierungsproblems OP2 in der Funktion calculate_portfolio_var. Über matrix(w) transformieren wir das Array w in einen Zeilenvektor der Dimension \\(1xN\\).\n\n\nCode\n# definition of target function to be minimized\ndef calculate_portfolio_var(w,Sigma):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    return (w*Sigma*w.T)[0,0]\n\n\nFür die Startgewichte der Optimierung verwenden wir ein gleichgewichtetes Portfolio. Durch Aufruf von np.tile(A,x) wird ein Array generiert, welches x-Mal den Wert A enthält. Die Anzahl der Assets in unserem Beispieluniversum erhalten wir über means.shape[0].\n\n\nCode\n# use equal weights \"Weight_1N\" as starting values \nWeight_1N = np.tile(1.0/means.shape[0], means.shape[0])\n\n\nNun sind wir bereit für die Optimierung, die optimierten Anteilsgewichte speichern wir im Array Weight_MV1. Durch setzen von options={'disp': True} werden allgemeine Informationen zum Ablauf der Optimierung angezeigt, und tol legt die Genauigkeit der gefundenen Lösung fest.\n\n\nCode\n# unconstrained portfolio (only sum(w) = 1 )\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\nres1= minimize(calculate_portfolio_var, Weight_1N, args=Sigma,\n              method='SLSQP',constraints=cons, tol=1e-10,\n              options={'disp': True})\nWeight_MV1 = res1.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.010828658442158556\n            Iterations: 31\n            Function evaluations: 341\n            Gradient evaluations: 31\n\n\nAus Gründen der besseren Übersicht transformieren wir Weight_MV1 in ein DataFrame.\n\n\nCode\npd.DataFrame([round(x,4) for x in Weight_MV1],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.4359\n-0.0418\n0.2083\n-0.0125\n0.141\n0.0902\n-0.1451\n-0.0239\n0.0445\n0.3035\n\n\n\n\n\n\n\nPositive Gewichte stellen Long-Positionen und negative Gewichte Short-Positionen dar. Assets mit negativen Gewichten werden somit leerverkauft.\n\n\n2.6.4.1.2 Leerverkaufsverbot\nWir implementieren nun die Beschränkung auf positive Gewichte über eine Liste von zehn (0, 1)-Tuplen.\n\n\nCode\n# positive weight portfolio\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\nres2= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MV2 = res2.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.012112846573987465\n            Iterations: 21\n            Function evaluations: 231\n            Gradient evaluations: 21\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in Weight_MV2],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.3617\n0.0\n0.1652\n0.0\n0.1621\n0.0137\n0.0\n0.0\n0.0523\n0.2449\n\n\n\n\n\n\n\nIn der gefundenen Lösung fällt auf, das vier der zehn Aktien nicht im optimierten Portfolio enthalten sind und mehr als 60% des Portfolios auf die beiden Aktien ABT und XOM entfällt. Um ein stärker diversifiziertes Portfolio zu konstruieren, wird bei der Berechnung eines dritten MVP eine zusätzliche Nebenbedingung eingeführt. Die einzelnen Assets sollen mindestens mit einem Anteilsgewicht von 5%, aber maximal mit einem Höchstanteil von 35% im Portfolio enthalten sein.\n\n\n2.6.4.1.3 Zusätzliche Nebenbedingung: Bestandsgrenzen (min=5%, max=35%)\n\n\nCode\n# position constraints\nbnd=[(0.05, 0.35),(0.05, 0.35),(0.05, 0.35),(0.05, 0.35),(0.05, 0.35),\n     (0.05, 0.35),(0.05, 0.35),(0.05, 0.35),(0.05, 0.35),(0.05, 0.35)]\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\nres3= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MV3 = res3.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.014612315837805704\n            Iterations: 18\n            Function evaluations: 198\n            Gradient evaluations: 18\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in Weight_MV3],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.3313\n0.05\n0.0689\n0.05\n0.1062\n0.05\n0.05\n0.05\n0.05\n0.1935\n\n\n\n\n\n\n\n\n\n\n2.6.4.2 Berechnung des Maximum-Ertrag-Portfolios (MEP) mit Leerverkaufsverbot\nWir beginnen wieder mit der Formulierung der Zielfunktion des Optimierungsproblems OP3 in der Funktion calculate_negative_portfolio_ret. Beachte: Minimieren der mit -1 multiplizierten erwarteten Portfoliorendite ist äquivalent zur Renditemaximierung.\n\n\nCode\n# definition of target function to be minimized\ndef calculate_negative_portfolio_ret(w,means):\n    # function that calculates -1 times portfolio expected return\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return -(w*means.T)[0,0]\n\n\n\n\nCode\n# positive weight portfolio\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\nres4= minimize(calculate_negative_portfolio_ret, Weight_1N, args=means, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MRP = res4.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -7.886975933686317\n            Iterations: 2\n            Function evaluations: 22\n            Gradient evaluations: 2\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in Weight_MRP],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n\n\n\n\n\nDas Portfolio ist zu 100% investiert in XOM, der Aktie mit der höchsten mittleren Rendite im Datensatz. Um ein breiter diversifiziertes Portfolio zu erhalten könnten wir wieder Bestandsgrenzen als zusätzliche Nebenbedingung einführen.\n\n\n2.6.4.3 Berechnung eines Punktes der Effizienzkurve mit Leerverkaufsverbot\nWir bestimmen nun einen Punkt der Effizienzkurve in dem wir im Optimierungsproblem OP1 die Zielrendite \\(\\mu_P\\) z.B. auf 6% setzen. Wir implementieren diese zusätzliche Nebenbedingung in zwei Schritten. Zunächst schreiben wir die Funktion calculate_portfolio_ret, die die erwartete Portfoliorendite berechnet. Dann fügen wir diese Funktion als Lambda-Funktion in das Tuple cons der Nebenbedingungs-Dictionaries.\n\n\nCode\n# definition of function for portfolio expected return\ndef calculate_portfolio_ret(w,means):\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return (w*means.T)[0,0]\n\n# positive weight portfolio\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\n\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n        {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,means)-6.0})\n\n\nres4= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_tar6 = res4.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.0149725199855123\n            Iterations: 13\n            Function evaluations: 143\n            Gradient evaluations: 13\n\n\nWir überprüfen kurz ob die optimierten Portfoliogewichte wirklich zu einer erwarteten Portfoliorendite von 6% führen.\n\n\nCode\ncalculate_portfolio_ret(Weight_tar6,means)\n\n\n6.000000000000562\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in Weight_tar6],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.2001\n0.0\n0.149\n0.0\n0.1609\n0.0\n0.0\n0.0\n0.0\n0.49\n\n\n\n\n\n\n\n\n\n2.6.4.4 Berechnung der vollständigen Effizienkurve mit Leerverkaufsverbot\nZunächst berechnen wir das Intervall der erwarteten Renditen aller Portfolios auf der Effizienzkurve. Dies ist gleichbedeutend mit dem Intervall der Zielrenditen im Optimierungsproblem OP1. Hierbei gilt: Minimum Zielrendite = Rendite des MVP, und Maximum Zielrendite = Rendite der MEP.\n\n\nCode\n# calculation of min and max target return\n# min: expected return of GMVP, max: expected return of MRP\n\nmin = calculate_portfolio_ret(Weight_MV2, means)\nmax = calculate_portfolio_ret(Weight_MRP, means)\n\n\nÜber np.linspace generieren wir nun das Array V_Target mit 45 gleichmäßig verteilten Zielrenditen zwischen den oben definierten Minimum und Maximum. Wir definieren die Arrays V_Risk und V_Return in denen wir später die aus der Optimierung resultierenden \\(\\sigma_P\\) und \\(\\mu_P\\) speichern. Zudem definieren wir die Matrix V_Weight der Dimension 45x10. In den Zeilen dieser Matrix speichern wir die zehn Anteilsgewichte der zehn Assets für die 45 optimierten Portfolios (eins für jede Zielrendite).\nNun iterieren wir über eine for-Schleife durch das Array der Zielrenditen. Wir verwenden enumerate um den Iterationsindex (hier als idx bezeichnet) bei den Iterationen “mitzunehmen” und damit die Positionen in den Ergebnis-Arrays bzw. der Gewichtsmatrix zu indexieren.\n\n\nCode\nV_Target = np.linspace(min, max, num=45)\nV_Risk = np.zeros(V_Target.shape)\nV_Return = np.zeros(V_Target.shape)\nV_Weight = np.zeros((V_Target.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight[idx, :] = res.x.T\n    V_Return[idx] = calculate_portfolio_ret(res.x,means)\n    V_Risk[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\nWir plotten die resultierende Effizienkurve und die Positionen der zehn Assets.\n\n\nCode\nfig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nplt.plot(V_Risk, V_Target, 'g:', label='Efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nplt.legend(loc='best',  frameon=False)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\nHier plotten wir die optimalen Anteilsgewichte für die 45 Zielrenditen.\n\n\nCode\nfig2 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target, V_Weight.T*100)\n# colors=tuple([tuple(gray*np.ones(3)) for gray in np.linspace(0.4, 0.8, num=means.shape[0])]))\nplt.axis([min, max, 0.0, 100.0])\nplt.legend(list(frame.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return (%)')\nplt.ylabel('Allocation weight (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2.6.4.5 Berechnung der vollständigen Effizienzkurve ohne Leerverkaufsverbot\nIm Sonderfall ohne Leerverkaufsverbot (und nur Gültigkeit der Budgetrestriktion) kann die Parabel varianzminimaler Portfolios auch ohne numerische Optimierung über eine geschlossene Lösung ermittelt werden (siehe oben Kapitel 2.2.3). Wir berechnen nun die Parabel über Gleichung (1).\nHierfür benötigen wir das NumPy Module numpy.linalg für Lineare Algebra, dass wir oben als la importiert hatten. Wichtig: In Sonderfall ohne Leerverkaufsverbot gilt für die Varianz des MVP: \\(\\sigma^2_{MVP}=\\frac{1}{C}\\), wobei \\(C=\\iota^{T}\\Sigma^{-1}\\iota\\) (siehe zur Herleitung z.B. Franzen und Schäfer, 2018, S. 189).\ninv bezeichnet die Funktion zur Berechnung der Inversen einer Matrix, und @ ist der Operator für Matrixmultiplikationen. Wichtig: Beachten Sie, dass in Python @ anwendbar ist, solange die Länge eines Vektors mit der Länge der entsprechenden Zeile/Spalte einer Matrix übereinstimmt. Wir müssen also den Transponierungsoperator T nicht auf means oder iota anwenden.\nZunächst generieren wir den Einheitsvektor der Dimension \\(N\\) und extrahieren die Standardabweichungen der Assets.\n\n\nCode\niota = np.ones(means.shape)\nStdev = np.sqrt(np.diagonal(Sigma))\n\n\nDann berechnen wir die Inverse der Varianz-Kovarianzmatrix und die vier Komponenten A, B, C, und D der Gleichung (1).\n\n\nCode\ninv_Sigma = la.inv(Sigma)\nA = means @ inv_Sigma @ iota\nB = means @ inv_Sigma @ means\nC = iota @ inv_Sigma @ iota\nD = B * C - A ** 2\n\n\nWir speichern die Standardabweichung des MVP als sigma_gmv. Diese dient als Minimum der \\(\\sigma_P\\)’s für die wir die beiden (effizienten und ineffizienten) \\(\\mu_P\\)’s gemäß Gleichung (1) berechnen. Das Maximum der \\(\\sigma_P\\)’s legen wir in Form der maximalen Standardabweichung (np.max(Stdev)) unter allen Assets fest. Für 250 gleichmäßig verteilte \\(\\sigma_P\\)’s innerhalb dieser Grenzen berechnen wir den effizienten und ineffizienten Bereich der Parabel varianzminimaler Portfolios (in den beiden Arrays mu_p_efficient und mu_p_inefficient) .\n\n\nCode\nsigma_gmv = 1.0 / np.sqrt(C)\nsigma_p = np.linspace(sigma_gmv, np.max(Stdev), num=250)\nmu_p_efficient = (A + np.sqrt(np.abs(C * sigma_p ** 2 - 1.0) * D)) / C\nmu_p_inefficient = (A - np.sqrt(np.abs(C * sigma_p ** 2 - 1.0) * D)) / C\n\n\nAbschließend plotten wir die Effizienzkurve mit und ohne Leerverkaufsverbot gemeinsam in einem Graph.\n\n\nCode\nfig2 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nplt.plot(sigma_p, mu_p_efficient, 'b-', label='Efficient frontier with short selling')\nplt.plot(V_Risk, V_Target, 'g:', label='Efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nplt.legend(loc='best',  frameon=False)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\nWir erwartet liegt die Effizienzkurve ohne Leerverkaufsverbot oberhalb derjenigen mit Leerverkaufsverbot. Zusätzliche Nebenbedingungen schränken den Lösungsraum optimaler Portfolios immer weiter ein.\n\n\n2.6.4.6 Berechnung der Effizienzkurve auf Basis des Two-Fund Theorems\nWichtig: Dieser Ansatz ist nur gültig wenn Leerverkäufe erlaubt sind!\nIm ersten Schritt ermitteln wir die Gewichte (port1 und port2) von zwei Basisportfolios \\(X\\) und \\(Y\\) gemäß Gleichung (2) oben. Wir wählen die Werte 2.0 und 4.0 für die Konstante \\(c\\).\nFür beide Portfolios berechnen wir die erwartete Rendite, Varianz der Rendite, und die Renditekovarianz zwischen \\(X\\) und \\(Y\\).\nBeachten Sie: die Renditekovarianz ist gegeben durch \\(Cov(X,Y)=w^{T}_X\\Sigma w_Y\\)\n\n\nCode\n# use 2.0 and 4.0 as constant values\n# calculate the two basis portfolios 1 and 2\nport1 = (inv_Sigma*np.matrix(means-2.0).T)/np.sum(inv_Sigma*np.matrix(means-2.0).T)\nport2 = (inv_Sigma*np.matrix(means-4.0).T)/np.sum(inv_Sigma*np.matrix(means-4.0).T)\ncovariance=(port1.T*Sigma*port2)[0,0]\nret1 = (np.matrix(means) * port1)[0,0] \nret2 = (np.matrix(means) * port2)[0,0] \nvar1 = (port1.T*Sigma*port1)[0,0]\nvar2 = (port2.T*Sigma*port2)[0,0]\n\n\nDanach berechnen wir gemäß der Formeln (3a) und (3b) die erwartete Rendite und die Renditevarianz für ein Portfolio \\(Z=\\alpha X+(1-\\alpha)Y\\). Über np.linspace wählen wir dabei 250 gleichmäßig verteilte Werte für \\(\\alpha\\) zwischen 0 und 1.5. Die resultierende erwartete Rendite und das Risiko der 250 \\(Z\\)-Portfolios speichern wir dann in den Arrays Risk und Return. Wir verwenden wieder die enumerate Funktion um die Arrays zu indexieren.\n\n\nCode\n# construction of portfolios from the two basis portfolios for \n# different weights w\nweight = np.linspace(0, 1.5, num=250)\nRisk = np.zeros(weight.shape)\nReturn = np.zeros(weight.shape)\nfor idx, w in enumerate(weight):\n    Return[idx] = w*ret1 + (1-w)*ret2\n    Risk[idx] = np.sqrt(w**2 * var1 + (1-w)**2 * var2 + 2*w*(1-w)*covariance)\n    \n\n\nFinal plotten wir die sich ergebende Effizienzkurve zusammen mit der oben numerisch bestimmten Kurve für den Fall dass Leerverkäufe unzulässig sind.\n\n\nCode\nfig3 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nplt.plot(Risk, Return, 'b-', label='Efficient frontier with short selling')\nplt.plot(V_Risk, V_Target, 'g:', label='Efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nplt.legend(loc='best',  frameon=False)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2.6.4.7 Bestimmung des Tangentialportfolios (TP) mit Leerverkaufsverbot\nWie schon oben geschildert, ergibt sich unter der Annahme der Existenz einer risikofreien Anlage eine neue Effizienzline. Die Bestimmung des Tangentialportfolios TP (das Portfolio mit der maximalen Sharpe-Ratio) beinhaltet die Frage: Welches Portfolio maximiert die Überschussrendite (über den risikolosen Zins hinaus) relativ zum Portfoliorisiko?\nDie Zielfunktion des Optimierungsproblems OP4 implementieren wir in der Funktion calc_neg_sharpe. Diese Funktion erfordert als Eingabe \\(w\\), \\(\\mu\\), \\(\\Sigma\\), \\(r_f\\) und die Zeitfrequenz freq der Renditebeobachtungen. Liegen beispielsweise monatliche Renditen vor, ist freq=12. Um als Ausgabe der Funktion die (negative) annualisierte Sharpe-Ratio zu erhalten, wird die erwartete Portfoliorendite (portfolio_return) mit freq multipliziert, und die Standardabweichung der Rendite (portfolio_std) mit der Wurzel aus freq. \\(r_f\\) sollte als Jahreszins angegeben werden. Die Annualisierung entfällt natürlich (und freq ist auf den Wert Eins zu setzen) falls die Schätzungen von \\(\\mu\\) und \\(\\Sigma\\) bereits annualisiert wurden (wie in unserem Fall oben).\nBeachten Sie, dass die Portfoliovarianz in Matrizenschreibweise durch \\(\\sigma_P^2=w^{T}\\Sigma w\\) gegeben ist. In der Funktion führen wir die Matrizenmultiplikation zweimal hintereinander über np.dot durch.\n\n\nCode\n# definition of target function for maximum Sharpe portfolio\n# \"freq\" denotes the return frequency (daily=252, monthly=12, annual=1, etc.)\ndef calc_neg_sharpe(weights, mean_returns, cov, rf, freq):\n    portfolio_return = np.sum(mean_returns * weights) * freq\n    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov, weights))) * np.sqrt(freq)\n    sharpe_ratio = (portfolio_return - rf) / portfolio_std\n    return -sharpe_ratio\n\n\nDas vollständige Optimierungsproblem schreiben wir in die Funktion max_sharpe_ratio. Es gilt hier zwei Besonderheiten zu beachten:\n\nDas Tuple bounds mit den identischen Positionsgrenzen für alle Assets generieren wir elegant über eine for-Schleife.\nDas gleichgewichtete Portfolio als Startlösung erzeugen wir als Liste durch num_assets*[1./num_assets,].\n\n\n\nCode\n# function that implements the Sharpe portfolio optimization\ndef max_sharpe_ratio(mean_returns, cov, rf, freq):\n    num_assets = len(mean_returns)\n    args = (mean_returns, cov, rf, freq)\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0.0,1.0)\n    bounds = tuple(bound for asset in range(num_assets))\n    result = minimize(calc_neg_sharpe, num_assets*[1./num_assets,], args=args,\n                        method='SLSQP', bounds=bounds, constraints=constraints,tol=1e-10)\n    return result\n\n\nFür einen jährlichen risikolosen Zins von 3% berechnen für nun für unser Beispiel-Anlageuniversum die Gewichte des Tangentialportfolios.\n\n\nCode\n# set annual risk-free rate to 3% and calculate maximum Sharpe portfolio\nrf = 3.0\noptimal_port_sharpe = max_sharpe_ratio(means, Sigma, rf, 1)\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in optimal_port_sharpe['x']],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.0\n0.0\n0.0979\n0.0\n0.1474\n0.0\n0.0\n0.0\n0.0\n0.7547\n\n\n\n\n\n\n\nAugenscheinlich besteht des Tangentialportfolio zu 75% aus XOM. Ein breiter diversifiziertes Portfolio würde Bestandshöchstgrenzen (z.B. 35%) erfordern.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#lernvideos",
    "href": "kapitel1a.html#lernvideos",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.7 Lernvideos",
    "text": "2.7 Lernvideos\n\n2.7.1 Video Teil 1\n\n\n\n2.7.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel1a.html#literatur",
    "href": "kapitel1a.html#literatur",
    "title": "2  Grundlagen der klassischen (absoluten) Portfoliooptimierung",
    "section": "2.8 Literatur",
    "text": "2.8 Literatur\nBenninga, S., (2014). Financial Modeling, 4. Auflage, MIT Press, London.\nFranzen, D., Schäfer, K. (2018). Assetmanagement, 1. Auflage, Schäffer-Poeschel, Stuttgart.\nPoddig, T., Brinkmann, U., Seiler, K. (2009). Portfolio Management: Konzepte und Strategien, 2. Auflage, Uhlenbruch Verlag, Wiesbaden.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen der klassischen (absoluten) Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html",
    "href": "kapitel2a.html",
    "title": "3  Relative Portfoliooptimierung",
    "section": "",
    "text": "3.1 Motivation\nDie folgenden Ausführungen zur relativen Portfoliooptimierung sind angelehnt an Poddig et al. (2009), S. 197-216. Der grundlegende Ansatz der relativen Optimierung im Rahmen der Portfoliokonstruktion geht dabei zurück auf Grinold und Kahn (2000).\nEin möglicher Ausgangspunkt für einen relativen Optimierungsansatz ergibt sich durch die häufige Trennung der Ergebnisverantwortlichkeit beim aktiven Management. So ist bei Fremdverwaltung des Portfolios streng genommen eine Separierung der Rendite- und Risikoverantwortung notwendig. Der Investor überträgt hier die Vermögensverwaltung auf einen (Fremd-) Manager unter Vorgabe einer für den Portfoliomanager bindenden Benchmark. Der Investor akzeptiert also die Rendite und das Risiko der Benchmark. Er ist bereit, dieses zu tragen. Der Manager trägt demzufolge nicht die Verantwortung für die Benchmarkrendite und das Benchmarkrisiko, sondern nur für die zusätzliche Rendite und das zusätzliche Risiko des aktiven Portfolios. Konsequenz für den (Portfolio-) Manager ist, dass die absolute Optimierung eines Portfolios für ihn gar nicht sinnvoll ist. Relevant ist hier nur die zusätzliche Rendite (aktive Rendite) gegenüber dem dabei entstehenden zusätzlichen Risiko (aktives Risiko). Das optimale “relative” Portfolio ist gekennzeichnet durch den bestmöglichen Trade-off zwischen aktiver Rendite und aktivem Risiko relativ zur Benchmark. Gesucht ist also das optimale Portfolio relativ zur Benchmark. Eine solche Trennung der Ergebnisverantwortlichkeit ergibt sich beispielsweise auch bei der Verwaltung von Publikumsfonds, deren stratgische Ausrichtung für den Portfoliomanager zumeist gegeben ist und durch eine Benchmark fixiert wird. Eine aktive Portfoliostrategie kann dann mit der relativen Optimierung umgesetzt werden.\nAusgehend von einigen Kritikpunkten zur Vorgehensweise bei der absoluten Optimierung kann der Einsatz der relativen Optimierung ebenfalls begründet werden. Zentrale Voraussetzungen der absoluten Optimierung sind die “genaue” Prognostizierbarkeit der benötigten Inputparameter (im Sinne der ersten beiden Momente der Renditeverteilung) und die Tatsache, dass der Investor seine Nutzenfunktion kennt und diese auch genau beschreiben kann. Unter diesen Voraussetzungen liefert die absolute Optimierung konsequent das optimale Portfolio.\nEin Hauptkritikpunkt setzt an den Voraussetzungen der Erwartungsnutzentheorie an. Im Wesentlichen geht es um die Identifikation der Nutzenfunktion, welche sich in der Praxis als schwierig erweist.\nZudem ist die Prognose der Inputparameter aus der Sache heraus mit Unsicherheit behaftet. Finanzmarktprognosen sind nicht in der eigentlich benötigten Präzision bereitstellbar, selbst wenn es “nur” um die Momente der Verteilung von Zufallsvariablen geht. Aber gerade dies führt bei der absoluten Portfoliooptimierung zu Problemen. Die Sensitivität der Portfoliooptimierung in Bezug auf relativ kleine Veränderungen der geschätzten Inputparameter, gerade bei den prognostizierten Renditeerwartungswerten, ist im Allgemeinen vergleichsweise hoch. Aufgrund dessen ergibt sich schon bei kleinen Veränderungen der Renditeschätzungen ein relativ großer Umschichtungsbedarf bei der Portfoliobildung und somit auch eine gewisse “Instabilität” der Portfoliostruktur.\nNeben der Instabilität ist bei der praktischen Portfoliooptimierung ferner eine Neigung zu “extremen” Positionen beim optimalen Portfolio und sogar die Bildung ökonomisch unplausibler Portfoliostrukturen zu beobachten. Dies ist zwar auch ein Folge der Prognoseproblematik, nicht der Optimierung an sich, aber die absolute Optimierung liefert aufgrund dieser Problematik oftmals Portfolios, welche der Investor wegen extremer Positionen in den einzelnen Assets nicht halten möchte. Eine ausführlichere Diskussion um die Schächen des Mean-Variance-Ansatzes mit entsprechenden Beispielen findet sich in Drobetz (2003, S. 206 ff.) und in Kapitel A3.1.\nDamit sind weder die Effizienzkurve (wegen der Prognoseproblematik) noch die Nutzenfunktion (wegen der Identifikationsproblematik) hinreichend präzise bestimmbar. Nur mit beiden zusammen ist jedoch streng genommen das optimale Portfolio auffindbar.\nZur Lösung dieses Problems sind in Wissenschaft und Praxis verschiedene Ansätze entwickelt worden:\nEin weiterer Ansatz ist die relative Optimierung. Hier werden die Inputparameter der Assets des Anlageuniversums in Relation zu einer Benchmark betrachtet und die Optimierung der Portfoliostruktur wird mit diesen relativen Größen durchgeführt. So bleibt eine Bindung des optimalen Portfolios an die Benchmark erhalten, womit inakzeptable Lösungen tendenziell vermieden werden.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#motivation",
    "href": "kapitel2a.html#motivation",
    "title": "3  Relative Portfoliooptimierung",
    "section": "",
    "text": "als Konsequenz aus der Unmöglichkeit präziser Finanzmarktprognosen, Verzicht auf das aktive Portfoliomanagement und stattdessen die Durchführung eines passiven Managements mit Index Tracking (siehe Kapitel 9.);\nAnsätze der robusten Portfoliooptimierung (siehe die Kapitel 5-8.): Einsatz verschiedenster Nebenbedingungen, robuste Schätzung der Inputparameter, Black-Litterman Portfoliooptimierungsansatz, Portfolio Resampling, risikogesteuerte Ansätze;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#grundlagen-und-grundbegriffe-der-relativen-optimierung",
    "href": "kapitel2a.html#grundlagen-und-grundbegriffe-der-relativen-optimierung",
    "title": "3  Relative Portfoliooptimierung",
    "section": "3.2 Grundlagen und Grundbegriffe der relativen Optimierung",
    "text": "3.2 Grundlagen und Grundbegriffe der relativen Optimierung\nBei der relativen Optimierung ist es üblich, die Rendite \\(r_i\\) eines Assets \\(i\\) in Form einer Überschussrendite \\(r^´_i\\) über den risikofreien Zinssatz \\(r_f\\) hinaus aufzufassen: \\(r^´_i=r_i-r_f\\). Wird der risikolose Zins als zeitkonstant angenommen, ist die Varianz-Kovarianzmatrix der Überschussrenditen gleich der Varianz-Kovarianzmatrix der totalen (absoluten) Renditen, d.h. \\(\\Sigma^´=\\Sigma\\).\n\n3.2.1 Linearer Renditegenerierungsprozess\nDie relative Optimierung unterstellt einen univariaten Renditegenerierungsprozess für jedes Asset \\(i\\):\n\\[ (1) \\quad r^´_i=\\alpha_i + \\beta_i*r^´_B+\\epsilon_i, \\]\nmit:\n\n\\(r^´_i\\): Überschussrendite des i-ten Assets\n\\(r^´_B\\): Überschussrendite des Benchmarkportfolios B\n\\(\\alpha_i\\): autonome Eigenrendite des i-ten Assets, Konstante\n\\(\\beta_i\\): Sensitivität gegenüber dem Benchmarkportfolio\n\\(\\epsilon_i\\): unsystematische, zufällige, nicht erklärbare Restgröße (auch Residualrendite oder residuale Rendite genannt).\n\nDabei wird ferner für die Residualrenditen angenommen:\n\\((2) \\quad E(\\epsilon_i)=0\\) \\(\\qquad\\) für alle \\(i\\), mit \\(E()\\): Erwartungswertoperator;\n\\((3) \\quad Var(\\epsilon_i)=\\sigma^2_{\\epsilon_i}\\) \\(\\quad\\) endlich und konstant für alle \\(i\\)\n\\((4) \\quad Cov(\\epsilon_i, r^´_B)=E((\\epsilon_i-0)(r^´_B-\\mu^´_B))=0\\) \\(\\quad\\) mit \\(\\mu^´_B=E(r^´_B)\\): Erwartungswert der Benchmarkrendite\n\\((5) \\quad Cov(\\epsilon_i, \\epsilon_j)=E((\\epsilon_i-0)(\\epsilon_j-0))=0\\) \\(\\qquad\\) für alle \\(i, j, i \\neq j.\\)\nDamit lassen sich leicht die Erwartungswerte der Assetrenditen, deren Varianzen und die Kovarianzen zwischen den Assetrenditen bestimmen.\nFür die erwartete (Überschuss-) Rendite, Varianz und Kovarianz des Assets \\(i\\) gilt damit unter den gesetzten Annahmen:\n\\((6) \\quad E(r^´_i)=\\mu^´_i=\\alpha_i+\\beta_i*\\mu^´_B\\)\n\\((7) \\quad \\sigma^2_i=\\beta^2_i*\\sigma^2_B+\\sigma^2_{\\epsilon_i}\\)\n\\((8) \\quad \\sigma_{ij}=\\beta_i*\\beta_j*\\sigma^2_B\\)\nDie Varianz, also das mit Asset \\(i\\) verbundene Risiko, kann nach (7) in zwei Komponenten zerlegt werden. Ein Teil des Risikos \\((\\beta^2_i\\sigma^2_B)\\) wird durch die Benchmark erklärt. Der zweite Teil \\((\\sigma^2_{\\epsilon_i})\\) ist das sogenannte Restrisiko, auch residuales Risiko (“residual risk”) genannt. Aus den bisherigen Annahmen und Definitionen ergeben sich nun die für die relative Portfoliooptimierung relevanten Formeln.\n\n\n3.2.2 Portfolio-Alpha und Beta\nFür die Portfolioüberschussrendite gilt:\n\\((1) \\quad r^´_p=\\alpha_p+\\beta_p*r^´_B+\\epsilon_P=\\alpha^*_P+\\beta_P*r^´_B\\) \\(\\qquad\\) mit \\(\\alpha^*_P=\\alpha_P+\\epsilon_P\\)\nDas Portfolio-Alpha und Beta wird durch die Gewichtung der Assets im Portfolio und deren Alpha- und Beta-Werte determiniert:\n\\((2) \\quad \\alpha_P=w^T_P\\alpha\\)\nmit \\(\\qquad\\) \\(\\alpha:\\) \\(\\quad\\) Vektor der autonomen Eigenrenditen der Assets\n\\((3) \\quad \\beta_P=w^T_P\\beta\\)\nmit \\(\\qquad\\) \\(\\beta:\\) \\(\\quad\\) Vektor der Sensitivitäten der enthaltenen Assets gegenüber dem Benchmarkportfolio \\(B\\).\nDas Risiko (die Varianz) eines Portfolios kann ebenso wie nach Gleichung (7) oben in zwei Komponenten zerlegt werden. Ein Teil des Risikos \\((\\beta^2_P\\sigma^2_B)\\) wird durch die Benchmark erklärt. Der zweite Teil \\((\\sigma^2_{\\epsilon_P})\\) stellt das Restrisiko (residuales Risiko) dar:\n\\((4) \\quad \\sigma^2_P=\\beta^2_P*\\sigma^2_B+\\sigma^2_{\\epsilon_P}\\)\nbzw. ergibt sich das residuale Risiko des Portfolios als:\n\\((5) \\quad \\sigma^2_{\\epsilon_P}=\\sigma^2_P-\\beta^2_P*\\sigma^2_B.\\)\nDas Risiko von Portfolio \\(P\\) und Benchmark \\(B\\) berechnen sich wie bekannt:\n\\((6) \\quad \\sigma^2_P=w^T_P\\Sigma w_P\\)\n\\((7) \\quad \\sigma^2_B=w^T_B\\Sigma w_B\\)\nEingesetzt in (5) folgt:\n\\((8) \\quad \\sigma^2_{\\epsilon_P}=w^T_P\\Sigma w_P-(w^T_P\\beta)^2*w^T_B\\Sigma w_B.\\)\n\n\n3.2.3 Aktive Position und aktives Risiko\nDie relative Optimierung zeichnet sich im Gegensatz zur absoluten Optimierung durch den Bezug zur Benchmark aus, ohne jedoch zum passiven Portfoliomanagement zu zählen. Die Abweichung der Assetgewichte im Portfolio zu den jeweiligen Assetgewichten in der Benchmark wird auch als aktive Position bezeichnet. Die aktive Position ist folglich definiert als Differenzgewichte zwischen gehaltenem Portfolio \\(P\\) und Benchmark \\(B\\):\n\\((1) \\quad w_A=w_P-w_B.\\)\nDas auf die aktive Position zurückzuführende Risiko wird auch aktives Risiko (aktive Varianz) bezeichnet und ergibt sich als:\n\\((2) \\quad \\sigma^2_{AP}=w^T_A\\Sigma w_A.\\)\n\n\n3.2.4 Aktives Beta\nAnalog zur Bestimmung des aktiven Risikos ergibt sich auch ein aktives Beta. Das aktive Beta ist die Differenz zwischen Portfolio- und Benchmark-Beta (welches definitionsgemäß eins beträgt):\n\\((1) \\quad \\beta_{AP}=\\beta_P-\\beta_B=\\beta_P-1\\)\nmit \\(\\qquad\\) \\(\\beta_{AP}:\\) \\(\\quad\\) aktives Beta.\nFür die aktive Varianz (das aktive Risiko) gilt damit (siehe zur Herleitung der Formel Poddig et al., 2009, S. 240-241):\n\\((2) \\quad \\sigma^2_{AP}=\\beta^2_{AP}\\sigma^2_B + \\sigma^2_{\\epsilon_P}\\)\n\n\n3.2.5 Selektions- und Timingrisiko\nFür die Interpretation der Gleichung (2) sind zwei verschiedene Risikoarten zu definieren. Man unterscheidet Risiko aufgrund von Selektion und Risiko aufgrund von Timing. Selektionsfähigkeit beschreibt das Können eines Portfoliomanagers, überdurchschnittlich renditeträchtige Wertpapiere zu identifizieren. Dies bedeutet eine gute Portfolioperformance aufgrund der Auswahl der einzelnen Assets. Einem Portfoliomanager wird Selektionsfähigkeit beispielsweise dann zugeschrieben, wenn das von ihm zusammengestellte Portfolio ein signifikant positives Alpha aufweist. Timingfähigkeit beschreibt hingegen die Fähigkeit des Portfoliomanagers in Zeiträumen, in denen die Benchmark eine positive (Überschuss-) Rendite aufweist, mit dem gemanagten Portfolio eine zur Benchmarkrendite stärker steigende (Überschuss-) Rendite durch aktive Gestaltung der Sensitivität \\(\\beta\\) zu erzielen. Umgekehrt sollte das aktiv gemanagte Portfolio bei Timingfähigkeit in fallenden Marktphasen eine zur Benchmark weniger stark fallende (Überschuss-) Rendite erzielen.\nDas aktive Risiko (vgl. Formel (2)) ist infolgedessen in das Risiko aufgrund von Timing \\(\\beta^2_{AP}\\sigma^2_B\\) und das durch \\(\\sigma^2_{\\epsilon_P}\\) repräsentierte Risiko aufgrund von Selektion zu trennen.\nSofern bei der relativen Optimierung die Timingkomponente bewusst ausgeschlossen wird, also:\n\\((1) \\quad \\beta_{P}=\\beta_B = 1 \\Leftrightarrow \\beta_{AP}=0\\)\nexplizit gefordert wird, so vereinfacht sich (2) zu:\n\\((2^´) \\quad \\sigma^2_{AP}= \\sigma^2_{\\epsilon_P}\\)\nDies impliziert die Gleichsetzung des aktiven Risikos mit dem residualen Risiko, welches das “Selektionsrisiko” widerspiegelt. Die Forderung nach \\((2^´)\\) wird im Folgenden stets gesetzt (vgl. Grinold und Kahn, 2000, S. 102, und Poddig et al., 2009, S. 213f., zur Begründung des Ausschlusses der Timingkomponente bei der relativen Optimierung).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#zielfunktion-der-relativen-optimierung",
    "href": "kapitel2a.html#zielfunktion-der-relativen-optimierung",
    "title": "3  Relative Portfoliooptimierung",
    "section": "3.3 Zielfunktion der relativen Optimierung",
    "text": "3.3 Zielfunktion der relativen Optimierung\nAus den bisherigen Überlegungen und unter Vernachlässigung der Timingkomponente des aktiven Risikos lässt sich folgende Zielfunktion der relativen Optimierung aus der Zielfunktion der absoluten Optimierung herleiten (siehe Poddig et al., 2009, S. 209-216):\n\\[\n\\begin{split}\n\\\\(1) \\quad ZF(w) = \\alpha_P-\\lambda\\sigma^2_{\\epsilon_P} \\rightarrow \\max_{w}!, \\\\\n\\end{split}\n\\]\nwobei \\(\\lambda\\) den anlegerindividuellen Risikoaversionskoeffizienten angibt. In Matrizenschreibweise erhält man:\n\\[(2) \\quad ZF(w) = w_p ^T\\alpha-\\lambda(w_P^T\\Sigma w_P-(w_P^T\\beta)^2*w_B^T\\Sigma w_B)\\]\nbzw. alternativ (da \\(\\beta_P=1\\) bzw. \\(\\beta_{AP}=0\\) im Folgenden gesetzt werden)\n\\((3) \\quad ZF(w) = w_p ^T\\alpha-\\lambda(w_A^T\\Sigma w_A).\\)\nDies entspricht der Maximierung der Differenz von Portfolio-Alpha und dem mit dem Risikoaversionsparameter gewichteten Selektionsrisiko (oder residualen Risiko), welches unter der Annahme einer nicht existenten Timingkomponente zugleich dem aktiven Risiko entspricht.\nDie zentralen Nebenbedingungen (Budgetrestriktion und Verbot von Leerverkäufen) werden um den Ausschluss der Timingkomponente ergänzt:\n\\[\n\\begin{split}\n& \\text{(a)}\\ w^{T}\\iota = 1 \\quad bzw. \\quad \\ w_A^{T}\\iota = 0 \\qquad \\text{(Budgetrestriktion)}, \\\\\n& \\text{(b)}\\ w\\geqq 0 \\qquad \\text{(Leerverkaufsverbot)}, \\\\\n& \\text{(c)}\\ \\beta_P=1 \\quad \\Leftrightarrow \\quad \\beta_{AP}=0 \\quad \\text{(kein Timing)}.\n\\end{split}\n\\]\nDamit ist das Optimierungsproblem für die relative Optimierung formuliert. Es wird im nächsten Kapitel im Rahmen einer Fallstudie näher veranschaulicht.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#beginn-der-fallstudie",
    "href": "kapitel2a.html#beginn-der-fallstudie",
    "title": "3  Relative Portfoliooptimierung",
    "section": "3.4 Beginn der Fallstudie",
    "text": "3.4 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\n\n\n\n3.4.1 Laden und Beschreiben der Datenbasis\nDas beispielhafte Anlageuniversum der Fallstudie umfasst acht Unternehmen aus den folgenden Branchen: Technologie, Gesundheit, Nahrungsmittel, Pharma, Energie sowie Luft- und Raumfahrt. Die Unternehmen sind: Costco Wholesale (COST), Cisco Systems (CSCO), IBM (IBM), Intel (INTC), Merk (MRK), Microsoft (MSFT), AT&T (T), und Exxon Mobil Corporation (XOM).\nDie Datengrundlage stellen Monatsanfangskurse (“Adjusted Close”) über einen 5-Jahres-Zeitraum vom 1.12.2004 bis zum 1.12.2009 dar. Die Stichprobe enthält somit 61 Zeitreihenbeobachtungen.\n\n\nCode\n# hier den Pfad zur Datei eingeben\n# cd \"...\"\n\n\n\n\nCode\nframe = pd.read_excel('Kapitel A1.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe.head()\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n2004-12-01\n46.65\n51.77\n48.41\n19.32\n98.58\n23.39\n32.14\n26.72\n25.77\n51.26\n\n\n2005-01-03\n45.02\n50.60\n47.27\n18.04\n93.42\n22.45\n28.05\n26.28\n23.76\n51.60\n\n\n2005-02-01\n45.99\n54.97\n46.59\n17.42\n92.58\n23.99\n31.70\n25.16\n24.06\n63.31\n\n\n2005-03-01\n46.62\n58.46\n44.18\n17.89\n91.38\n23.23\n32.37\n24.17\n23.69\n59.60\n\n\n2005-04-01\n49.16\n59.52\n40.63\n17.27\n76.38\n23.52\n33.90\n25.30\n23.80\n57.03\n\n\n\n\n\n\n\n\n\n3.4.2 Fall A: Das aktive Portfolio und die Benchmark entspringen demselben Anlageuniversum\nWir berechnen zunächst diskrete Monatsrenditen über frame.pct_change(). Annahmegemäß beträgt der zeitkonstante annualisierte risikolose Zins 4%, was einem Monatszinssatz von 0,327374% entspricht. Die absoluten Renditen werden dann in Überschussrenditen überführt (DataFrame ex_returns). Auf Basis der Überschussrenditen ermitteln wir den Vektor der zukünftigen erwarteten Assetrenditen \\(\\mu\\) und die zukünftige Varianz-Kovarianzmatrix \\(\\Sigma\\) nach der Methode der historisch basierten Schätzung.\n\n\nCode\n# calculation based on discrete returns\nreturns = frame.pct_change().dropna()\nreturns_new = returns.drop(['ABT', 'BA'], 1) # we drop first two tickers\n\nrf = (1+0.04)**(1/12)-1 # risk-free rate assumed 4% p.a.\nex_returns = returns_new - rf\nmeans = ex_returns.mean().values*100 # non-annualised!\nSigma = ex_returns.cov().values # non-annualised!\n\n\nDas Benchmarkportfolio wird hier willkürlich als gleich gewichtetes Portfolio aller Assets gewählt. Durch Aufruf von np.tile(A,x) wird ein Array generiert, welches x-Mal den Wert A enthält. Die Anzahl der Assets in unserem Beispieluniversum erhalten wir über means.shape[0].\nIm Folgenden werden wir für die Matrizenmultiplikation häufig Arrays der Dimension \\(N\\) über np.matrix in \\(1xN\\) Zeilenvektoren transformieren.\nDie Zeitreihe benchmark der Überschussrenditen \\(r^´_B\\) der Benchmark erhalten wir indem zunächst die Assetrenditen über ex_returns.multiply(Weight_1N) zeilenweise mit den Benchmarkgewichten Weight_1N multipliziert werden und dann die gewichtete Summe der Zeilen gebildet wird.\n\n\nCode\n# using an equally-weighted benchmark\nWeight_1N = np.tile(1.0/means.shape[0], means.shape[0])\nbench_w = np.matrix(Weight_1N) # benchmark portfolio weights as row vector\nbenchmark = ex_returns.multiply(Weight_1N).sum(axis=1)\n\n\nSchätzung weiterer Inputparameter: Alpha und Beta\nAls zentrale Inputparameter für eine relative Optimierung gehen die Alpha- und Beta-Parameter in die Berechnungen ein. Diese erklären die Überschussrenditen der einzelnen Assets als Summe der autonomen Eigenrendite des jeweiligen Assets und aus einem von der Benchmark abhängigen Renditeanteil. Wird ein linearer Renditegenerierungsprozess unterstellt, so ist eine einfache historisch basierte Schätzung in diesem Fall über eine Regression der Renditen der Assets auf die Benchmark möglich.\nGrundsätzlich gelten für Alpha- und Beta-Parameter dieselben Überlegungen wie hinsichtlich der erwarteten Renditen und zukünftigen Risiken bei der absoluten Optimierung. Die Alpha- und Beta-Werte sind ex ante Größen, womit Prognosen (Schätzungen) dieser Größen unvermeidbar sind. Ebenso ist hier zu bedenken, dass die Güte der Alpha- und Beta-Prognosen die spätere Performance des aktiven Portfolios bestimmt. Auch hier ist die Prognose der wertgenerierende Prozess.\nZum Zwecke der Fallstudie wird nachfolgend der pragmatische Ansatz der einfachen historisch basierten Schätzung mittels univariater linearer Regression umgesetzt. Poddig et al. (2009, S. 220-223) geben einige Hinweise auf weitere Verfahren speziell zur Prognose von Alpha- und Beta-Parametern.\nZur Umsetzung der linearen Kleinste-Quadrate (Ordinary Least Squares - OLS) Regression laden wir zunächst die Module linear_model und tools aus dem Paket statsmodels.\n\n\nCode\nimport statsmodels.regression.linear_model as sm\nimport statsmodels.tools.tools as sm2\n\n\nDie Matrix x2 unten enthält die exogenen Variablen der Regression. In unserem Fall stellt die erste Spalte einen Vektor mit Einsen dar, die die Konstante (Achsenabschnitt=Alpha) der Regression modellieren. Diese Spalte wird über add_constant erzeugt. Die zweite Spalte ist der Vektor der Benchmarkrenditen. Die y-Variable der Regression ist die entsprechende Spalte des DataFrames der Überschussrenditen der Assets.\nDie Schätzung eines OLS Models erfolgt über sm.OLS(y-Variable, (Konstante,x-Variablen)).fit(). Die geschätzen Regressionskoeffizienten sind im Array params enthalten. Die Regressionen werden in Form einer for-Schleife über die Spalten von ex_returns iteriert, wobei wiederum die enumerate Methode verwendet wird, um den Interationsindex für die Indixierung der Ergebnis-Arrays alpha und beta zu verwenden.\n\n\nCode\n# calculating vectors of alphas and betas\nalpha = np.zeros(ex_returns.columns.shape)\nbeta = np.zeros(ex_returns.columns.shape)\n\nx1 = benchmark\nx2 = sm2.add_constant(x1)\n\nfor idx, ticker in enumerate(ex_returns.columns):\n    reg = sm.OLS(ex_returns[ticker], x2).fit()\n    parameter = np.asarray(reg.params)\n    alpha[idx] = parameter[0]\n    beta[idx] = parameter[1]\ndf =pd.DataFrame({'Alpha': alpha, 'Beta': beta}, index=ex_returns.columns)\n\n\nAus Gründen der besseren Übersicht geben wir die Schätzergebnisse in Form eines DataFrames wieder.\n\n\nCode\ndf\n\n\n\n\n\n\n\n\n\nAlpha\nBeta\n\n\n\n\nCOST\n0.000870\n0.900610\n\n\nCSCO\n0.001147\n1.285882\n\n\nIBM\n0.001738\n0.798834\n\n\nINTC\n-0.005285\n1.366525\n\n\nMRK\n0.000367\n1.158739\n\n\nMSFT\n-0.000665\n1.146965\n\n\nT\n-0.002151\n0.812048\n\n\nXOM\n0.003978\n0.530397\n\n\n\n\n\n\n\nFür die nachfolgende Matrizenmultiplikation transformieren wir die beiden Ergebnis-Arrays in Zeilenvektoren.\n\n\nCode\nalpha = np.matrix(alpha)\nbeta = np.matrix(beta)\n\n\nNun schreiben wird die Zielfunktion der Optimierung in Form der Funktion relative_opt1. Wichtig: Diese Funktion erfordert, dass die Arrays der Alpha’s, Beta’s, und der Benchmark-Gewichte vorher(!) in Zeilenvektoren überführt wurden.\nDie Funktion berechnet auf Basis eines Eingabe-Arrays von Portfolio-Anteilsgewichten \\(w_P\\) das Portfolio Alpha \\((w_p ^T\\alpha)\\), Beta \\((w_P^T\\beta)\\), die Varianz der Portfoliorendite \\((w_P^T\\Sigma w_P)\\) und der Benchmarkrendite \\((w_B^T\\Sigma w_B)\\), und das residuale Risiko \\((w_P^T\\Sigma w_P-(w_P^T\\beta)^2*w_B^T\\Sigma w_B)\\). Als Ausgabe liefert die Funktion den mit -1 multiplizierten Zielfunktionswert, da es sich um ein Maximierungsproblem handelt:\n\\(\\quad ZF(w) = w_p ^T\\alpha-\\lambda(w_P^T\\Sigma w_P-(w_P^T\\beta)^2*w_B^T\\Sigma w_B)\\)\n\n\nCode\n# target function: active alpha - lambda * residual risk\n# alpha, beta, bench_w have to be defined prior as vectors\ndef relative_opt1(w, lambda0):\n    port_w = np.matrix(w) # w is a row (not column!) vector\n    port_alpha = (port_w*alpha.T)[0,0]\n    port_beta = (port_w*beta.T)[0,0]\n    port_var = (port_w * Sigma*port_w.T)[0,0]\n    bench_var = (bench_w * Sigma * bench_w.T)[0,0]\n    resid_var = port_var - port_beta**2*bench_var\n    return -(port_alpha - lambda0 * resid_var) # -1 for minimization problem\n\n\nDie zusätzliche Nebenbedingung (kein Timing), dass das Portfolio-Beta eins bzw. das aktive Beta null betragen muss, implementieren wir ähnlich wie die Budgetrestriktion über eine lambda-Funktion, die wir null setzen und dem Tuple cons der Nebenbedingungs-Dictionaries hinzufügen.\n\n\nCode\ncons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n        {'type': 'eq', 'fun': lambda x: (np.matrix(x)*beta.T)[0,0] - 1})\n\n\nWir setzen den Risikoaversionskoeffizienten auf den Wert \\(\\lambda=-0.3705867\\), verwenden ein gleich gewichtetes Portfolio als Startlösung für die numerische Optimierung und implementieren Bestandsgenzen (min=5%, max=40%). Die Anwendung von minimize ergibt die folgenden optimierten Portfoliogewichte.\n\n\nCode\nlambda0 = -0.3705867\nbound = (0.05,0.40)\nbounds = tuple(bound for asset in range(alpha.shape[1]))\nres = minimize(relative_opt1, Weight_1N, args=lambda0,\n                        method='SLSQP', bounds=bounds, constraints=cons,tol=1e-10)\npd.DataFrame([round(x,4) for x in res.x],index=ex_returns.columns).T \n\n\n\n\n\n\n\n\n\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.05\n0.4\n0.05\n0.05\n0.0776\n0.05\n0.05\n0.2724\n\n\n\n\n\n\n\nWir überprüfen kurz ob dieser Gewichtsvektor die No-Timing-Bedingung auch wirklich einhält:\n\n\nCode\n# function to calculate the portfolio beta\ndef port_beta(w,beta):\n    port_w = np.matrix(w) # w is a row (not column!) vector\n    port_beta = (port_w*beta.T)[0,0]\n    return port_beta\n\n\nport_beta(res.x,beta)\n\n\n0.9999999999038441\n\n\nDies ist offensichtlich der Fall! Das Portfolio liefert eine erwartete annualisierte Rendite von:\n\n\nCode\n(np.matrix(means)* np.matrix(res.x).T)[0,0]*12\n\n\n3.6127468232671593\n\n\n\n\n3.4.3 Fall B: Relative Optimierung bei unterschiedlichen Anlageuniversen\nIn der obigen Fallstudie ist das Anlageuniversum für das aktive Portfolio und die Benchmark identisch. Dies ist jedoch ein Idealfall, der in der Praxis so nicht immer vorliegt. In der Praxis ergibt sich häufig das Problem unterschiedlicher Anlageuniversen. Oftmals stehen also nicht alle Anlagen des Benchmarkportfolios für eine Aufnahme in das aktive Portfolio zur Verfügung. Im Extremfall ist das Benchmarkportfolio ein synthetischer Index, gegen das ein aus nicht im Index enthaltenen Einzeltiteln bestehendes aktives Portfolio zu optimieren ist. Aus diesen Umständen resultiert die Frage, wie eine relative Optimierung durchgeführt wird, wenn sich die Anlageuniversen unterscheiden.\nZur Illustration des geschilderten Problems verwenden wir nun den S&P500 Index als Benchmark. Die Aufgabenstellung besteht darin, die relative Optimierung des aktiven Portfolios gegen diese Benchmark durchzuführen. Dabei wird im Folgenden bewusst so getan, als ob der S&P500 ein synthetischer Index sei.\n\n\nCode\n# benchmark is now the S&P500 index, therefore we need a new dataframe\nframe1 = pd.read_excel('Kapitel A2_1.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe1.head()\n\n\n\n\n\n\n\n\n\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\nS&P500\n\n\n\n\n2004-12-01\n48.41\n19.32\n98.58\n23.39\n32.14\n26.72\n25.77\n51.26\n1211.92\n\n\n2005-01-03\n47.27\n18.04\n93.42\n22.45\n28.05\n26.28\n23.76\n51.60\n1181.27\n\n\n2005-02-01\n46.59\n17.42\n92.58\n23.99\n31.70\n25.16\n24.06\n63.31\n1203.60\n\n\n2005-03-01\n44.18\n17.89\n91.38\n23.23\n32.37\n24.17\n23.69\n59.60\n1180.59\n\n\n2005-04-01\n40.63\n17.27\n76.38\n23.52\n33.90\n25.30\n23.80\n57.03\n1156.85\n\n\n\n\n\n\n\nDie grundsätzliche Vorgehensweise ändert sich im Vergleich zu oben nicht. Zunächst erfolgt eine Umrechnung der Kursreihen in diskrete Monatsrenditen, die als Überschussrenditen über den risiklosen Zins formuliert werden.\n\n\nCode\n# calculation based on discrete returns\nreturns = frame1.pct_change().dropna()\n\nrf = (1+0.04)**(1/12)-1 # risk-free rate assumed 4% p.a.\nex_returns = returns - rf\n\n# important: we use only the first 60 returns!\nmeans = ex_returns.iloc[:60,:].mean().values*100*12 # annualised!\nSigma = ex_returns.iloc[:60,:].cov().values # non-annualised!\n\n\nDiese bilden die Ausgangsbasis für eine historisch basierte Schätzung der Alpha- und Beta-Parameter, welche mittels univariater linearer Regression der jeweiligen Assetrenditen auf die Benchmarkrendite ermittelt werden.\n\n\nCode\n# calculating vectors of alphas and betas\nalpha = np.zeros(ex_returns.columns.shape)\nbeta = np.zeros(ex_returns.columns.shape)\n\nx1 = ex_returns['S&P500']\nx2 = sm2.add_constant(x1)\n\nfor idx, ticker in enumerate(ex_returns.columns):\n    reg = sm.OLS(ex_returns[ticker].iloc[:60], x2.iloc[:60]).fit()\n    parameter = np.asarray(reg.params)\n    alpha[idx] = parameter[0]\n    beta[idx] = parameter[1]\ndf =pd.DataFrame({'Alpha': alpha, 'Beta': beta}, index=ex_returns.columns)\n\n\n\n\nCode\ndf\n\n\n\n\n\n\n\n\n\nAlpha\nBeta\n\n\n\n\nCOST\n5.317110e-03\n0.793253\n\n\nCSCO\n7.774840e-03\n1.208840\n\n\nIBM\n6.029992e-03\n0.798688\n\n\nINTC\n1.309308e-03\n1.161773\n\n\nMRK\n5.708572e-03\n0.916956\n\n\nMSFT\n4.811190e-03\n0.959172\n\n\nT\n1.748128e-03\n0.684994\n\n\nXOM\n6.592676e-03\n0.465999\n\n\nS&P500\n-8.673617e-19\n1.000000\n\n\n\n\n\n\n\n\n\nCode\nalpha = np.matrix(alpha)\nbeta = np.matrix(beta)\n\n\nDie Formulierung des relativen Optimierungsansatzes und die Bestimmung des aktiven Portfolios erfolgt wie bisher. Die Modifikation der Fallstudie liegt in der Wahl unterschiedlicher Anlageuniversen. Ein genereller Lösungsansatz zum Umgang mit unterschiedlichen Anlageuniversen besteht darin, bei zwei gegebenen Portfolios \\(P\\) und \\(B\\) mit Anlageuniversen \\(X\\) und \\(Y\\) ein gemeinsames Anlageuniversum \\(Z\\) als Vereinigungsmenge von \\(X\\) und \\(Y\\), d.h. \\(Z=X \\cup Y\\), zu bilden. Damit sind die Anlagen beider Portfolios \\(P\\) und \\(B\\) nun Elemente des identischen Anlageuniversums \\(Z\\). Assets, die in \\(P\\), aber nicht in \\(B\\) gehalten werden, haben in \\(B\\) ein fixiertes Gewicht von null und entsprechend erhalten Assets, die in \\(B\\), aber nicht in \\(P\\) gehalten werden, in \\(P\\) ein fixiertes Gewicht von null.\nDas Anlageuniversum in der Fallstudie hat nunmehr neun Assets, nämlich die betrachteten acht Einzeltitel sowie den S&P500 als “virtuelle” Anlage. Die historisch basierte Berechnung von \\(\\mu\\), \\(\\Sigma\\), \\(\\alpha\\), und \\(\\beta\\) erfolgte oben bereits für diese neun Anlagen.\nIm nächsten Schritt muss der Vektor der Benchmark-Gewichte derart ausgestaltet sein, dass die ersten acht Gewichte (für die Einzeltitel) den Wert null und das letzte Gewicht (für den S&P500) den Wert eins zugewiesen bekommen.\n\n\nCode\n# calculation of weight vector for active portfolio and benchmark\n# using S&P500 as a benchmark implies that all benchmark weights (first N-1)\n# elements are zero and 1 for S&P500 (last element)\nbench_w = np.zeros(means.shape)\nbench_w[-1]=1.0\nbench_w = np.matrix(bench_w)\n\n\nZudem muss der Vektor der Startgewichte für das aktive Portfolio jeweils den Wert \\(1/8\\) (1/(means.shape[0]-1)) auf den ersten acht Positionen enthalten, und den Wert null auf der letzten Position.\n\n\nCode\n# vector of starting weights is equally-weighted for the first N-1 \n# elements and zero for the last element\nWeight_start = np.zeros(means.shape)\nWeight_start[0:-1]=1/(means.shape[0]-1)\nWeight_start = np.matrix(Weight_start)\n\n\nDie Definition der Zielfunktion relative_opt1 bleibt unverändert. Ebenso das Tuple cons der Nebenbedingungen.\nBeachten Sie, dass nur die ersten acht Gewichte in \\(w_P\\) die änderbaren Parameter der Optimierung darstellen, das neunte Gewicht in \\(w_P\\) (für den S&P500) ist fest auf null fixiert und nicht Gegenstand der Optimierung. Dieses Prinzip gilt immer für alle Gewichte in \\(P\\), die explizit auf null gesetzt und fixiert werden, weil die zugehörigen Anlagen nicht Elemente des Anlageuniversums von \\(P\\) sind.\nWir implementieren die Nullgewichtung der Benchmark in \\(w_p\\) über das Tuple bounds der Bestandsgrenzen indem wir bounds += ((0.0, 1e-10), ) setzen. Hierdurch fügen wir am Ende von bounds ein weiteres Tuple der Form (0.0, 1e-10) hinzu. Wichtig: die Obergrenze des Tuples muss zwingend größer sein als die Untergenze (daher die Wahl von 1e-10). Dies hat aber keinen Einfluss auf die Optimierungsergebnisse.\nMit \\(\\lambda=-0.1075445\\) ergibt sich der folgende optimierte Anteilsvektor.\n\n\nCode\nbound = (0.05,0.40)\nbounds = tuple(bound for asset in range(alpha.shape[1]-1))\n# weight of the benchmark is fixed to zero; Important: lb==ub is no longer allowed!\nbounds += ((0.0, 1e-10), ) \nlambda0 = -0.1075445\n\ncons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n        {'type': 'eq', 'fun': lambda x: (np.matrix(x)*beta.T)[0,0] - 1})\n\nres1 = minimize(relative_opt1, Weight_start, args=lambda0,\n                        method='SLSQP', bounds=bounds, constraints=cons,tol=1e-10)\npd.DataFrame([round(x,4) for x in res1.x],index=ex_returns.columns).T\n\n\n\n\n\n\n\n\n\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\nS&P500\n\n\n\n\n0\n0.05\n0.4\n0.05\n0.05\n0.296\n0.05\n0.05\n0.054\n0.0\n\n\n\n\n\n\n\nKurzer Check ob Timing Bedingung (Portfolio-Beta gleich eins, aktives Beta gleich null) eingehalten wird.\n\n\nCode\nport_beta(res1.x,beta)\n\n\n1.0000000000585922\n\n\n\n\nCode\n# portfolio variance\n(np.matrix(res1.x)* Sigma* np.matrix(res1.x).T)[0,0]\n\n\n0.0030267295902247117\n\n\n\n\nCode\n# portfolio alpha\n(np.matrix(res1.x)*alpha.T)[0,0]\n\n\n0.006116489277362495",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#lernvideos",
    "href": "kapitel2a.html#lernvideos",
    "title": "3  Relative Portfoliooptimierung",
    "section": "3.5 Lernvideos",
    "text": "3.5 Lernvideos\n\n3.5.1 Video Teil 1\n\n\n\n3.5.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel2a.html#literatur",
    "href": "kapitel2a.html#literatur",
    "title": "3  Relative Portfoliooptimierung",
    "section": "3.6 Literatur",
    "text": "3.6 Literatur\nDrobetz, W. (2003). Einsatz des Black-Litterman-Verfahrens in der Asset Allocation, in: Dichtl, H., Kleeberg, J., und C. Schlenger (Hrsg.), Handbuch Asset Allocation, Uhlenbruch Verlag: Bad Soden/Ts.\nGrinold, R. C., Kahn, R. N. (2000). Active Portfoliomanagement, Quantitative Theory and Applications, 2. Auflage, New York u.a..\nPoddig, T., Brinkmann, U., Seiler, K. (2009). Portfolio Management: Konzepte und Strategien, 2. Auflage, Uhlenbruch Verlag, Bad Soden/Ts..",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Relative Portfoliooptimierung</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html",
    "href": "kapitel3a.html",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "",
    "text": "4.1 Einleitung\nDie folgende Darstellung ist angelehnt an:\nIn seinem bahnbrechenden Journal of Finance Artikel “Portfolio Selection” aus dem Jahr 1952 legt Harry Markowitz dar, dass risikoaverse Investoren sich bei ihrer Anlageentscheidung an Erwartungswert und Varianz der Rendite ihres Gesamtportfolios orientieren sollten. Der Anleger strebt danach, eine vorgegebene erwartete Portfoliorendite mit dem geringsten Risiko zu erreichen. Die mathematische Formalisierung dieser Idee führt zu einem quadratischen Optimierungsproblem mit N-1 Entscheidungsparametern, wobei N die Anzahl der zulässigen Anlageinstrumente darstellt.\nDie praktische Implementierung des Portfolioansatzes von Markowitz ist mit einem zentralen Problem verbunden. Der Anleger kennt die Parameter der Renditeverteilungen (Erwartungswerte, Varianzen, Kovarianzen) nicht. Diese Parameter können beispielsweise aus den fundamentalen Unternehmensdaten ermittelt werden oder - und darauf werden wir uns konzentrieren - aus historischen Zeitreihen geschätzt werden. Diese Schätzung stellt für große Wertpapierportfolios zunächst in quantitativer Hinsicht eine Hausforderung dar, da N erwartete Renditen und Varianzen bzw. 0,5 · N · (N-1) Kovarianzen zu schätzen sind. Selbst wenn das Anlageuniversum eines Investors nur aus 500 Aktien besteht, sind bereits 125.750 Parameter zu schätzen. Neben diesem reinen Mengenproblem besteht allerdings ein zweites gravierenderes Problem, das im Zentrum der folgenden Ausführungen stehen wird. Jede Schätzung ist mit einem Schätzrisiko verbunden, d.h., der geschätzte Parameter wird im allgemeinen nicht dem (unbeobachtbaren) wahren Parameter der Renditeverteilung entsprechen. Dies kann zu suboptimalen Portfoliozusammensetzungen und damit zu mangelndem Anlageerfolg führen. Das Ziel dieses Notebooks besteht darin, die Bedeutung des Schätzrisikos für die Portfoliozusammensetzung aufzuzeigen und anschließend Wege darzustellen, wie der Einfluss des Schätzrisikos auf die Portfoliozusammensetzung verringert werden kann.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html#einfluß-des-schätzfehlers-auf-die-portfoliozusammensetzung",
    "href": "kapitel3a.html#einfluß-des-schätzfehlers-auf-die-portfoliozusammensetzung",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "4.2 Einfluß des Schätzfehlers auf die Portfoliozusammensetzung",
    "text": "4.2 Einfluß des Schätzfehlers auf die Portfoliozusammensetzung\nZunächst werden wir in einer kleinen Simulationsstudie aufzeigen, wie stark das Schätzrisiko die Portfoliozusammensetzung beeinflusst. Hierzu simulieren wir für vier Aktien unabhängig identisch normalverteilte Wochenrenditen über einen Zeitraum von zwei Jahren. Für jede Aktie unterstellen wir einen Erwartungswert der Rendite von 11% p.a. und eine Standardabweichung von 25% p.a. Außerdem nehmen wir an, dass die Renditen der verschiedenen Aktien paarweise eine Korrelation von 0,3 aufweisen. Daneben unterstellen wir, dass es ein risikoloses Instrument mit einer Rendite \\(r_f\\) = 6% p.a. gibt. Dieses risikolose Instrument berücksichtigen wir, damit die optimale Zusammensetzung des Aktienportfolios unabhangig vom Ausmaß der Risikoaversion des Anlegers ist (Tobin-Separation). Tobin (1958) hat gezeigt, dass alle Anleger in diesem Fall unabhängig von dem Ausmaß ihrer Risikoaversion das gleiche Aktienportfolio halten, das sogenannte Tangentialportfolio.\nUm die Größenordnung der Schätzrisiken zu verdeutlichen, analysieren wir die optimale Zusammensetzung des Tangentialportfolios eines Anlegers in zwei Fällen. Im ersten Fall kennt der Anleger die obigen Verteilungsparameter, während er sie im zweiten Fall aus den simulierten Renditerealisationen schätzen muss. Kennt der Anleger die Verteilungsparameter, so ist es für ihn optimal, sein in Aktien anzulegendes Vermögen gleichmäßig auf die vier Aktien zu verteilen. Diese Gleichverteilungsstrategie führt zu einer erwarteten Aktienportfoliorendite von 11% p.a. bei einer Standardabweichung von 17,23% p.a. Betrachten wir nun den Fall, dass der Anleger die Verteilungsparameter aus den realisierten Renditen schätzt.\n\n\nCode\n# import of necessary libaries\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\n\n\nAusgangssituation für die Simulation:\n\nwahre Parameter (annualisiert): \\(\\mu_i=0,11, \\sigma_i=0,25, \\rho_{ij}=0,3\\), für \\(i,j =1,..., 4,\\) und \\(i \\neq j\\).\nDie Varianz auf Wochenebene beträgt: \\(0,25^{2}/52=0,00120192\\).\nFür die wöchentliche erwartete Rendite gilt: \\(0,11/52=0,00211538\\).\nDer konstante Korrelationskoeffizient ist 0,3. Damit folgt für die wöchentliche Kovarianz: \\(0,25^{2}/52 * 0,3=0,00036058\\).\n\n\n\nCode\n# Die wöchentliche Varianz-Kovarianzmatrix nennen wir *Sigma_true*:\nSigma_true=[[0.00120192, 0.00036058, 0.00036058, 0.00036058],\\\n            [0.00036058, 0.00120192, 0.00036058, 0.00036058],\\\n            [0.00036058, 0.00036058, 0.00120192, 0.00036058],\\\n            [0.00036058, 0.00036058, 0.00036058, 0.00120192]]\n\n# Der Vektor der erwarteten, wöchentlichen Renditen:\nmeans_true=[0.00211538, 0.00211538, 0.00211538, 0.00211538]\n\n\n\n\nCode\n# eine Monte Carlo Ziehung mit jeweils einer 2-jährigen Zeitreihe \n# (104 Wochen) für jede Aktie\nnp.random.seed(42)\ndf = pd.DataFrame(np.asarray(np.random.multivariate_normal(means_true,\\\n                Sigma_true, size = 104)), columns=['A1', 'A2', 'A3', 'A4'])\nmeans_est = df.mean().values * 52 # annualsiert\nSigma_est = df.cov().values * 52 # annualisiert\nstd_est=np.sqrt(np.diag(Sigma_est))\n\n\nIn den folgenden zwei Tabellen sind die geschätzten Parameter eines exemplarischen Zufallspfades der Simulation sowie die wahren Werte angegeben. Zunächst ein Vergleich der wahren und geschätzen erwarteten Renditen:\n\n\nCode\npd.DataFrame({'wahr': 0.11, 'geschätzt': means_est, \\\n              'Schätzfehler (%)': (0.11-means_est)*100}, index=df.columns)\n\n\n\n\n\n\n\n\n\nwahr\ngeschätzt\nSchätzfehler (%)\n\n\n\n\nA1\n0.11\n0.193280\n-8.328017\n\n\nA2\n0.11\n0.214416\n-10.441623\n\n\nA3\n0.11\n0.099346\n1.065403\n\n\nA4\n0.11\n0.145107\n-3.510683\n\n\n\n\n\n\n\nUnd nun der Vergleich der wahren (0,25) und der geschätzten Standardabweichung:\n\n\nCode\npd.DataFrame({'wahr': 0.25, 'geschätzt': std_est, \\\n              'Schätzfehler (%)': (0.25-std_est)*100}\\\n             , index=df.columns)\n\n\n\n\n\n\n\n\n\nwahr\ngeschätzt\nSchätzfehler (%)\n\n\n\n\nA1\n0.25\n0.233158\n1.684243\n\n\nA2\n0.25\n0.226982\n2.301796\n\n\nA3\n0.25\n0.236087\n1.391323\n\n\nA4\n0.25\n0.239289\n1.071104\n\n\n\n\n\n\n\nBerechnen wir nun die optimalen Gewichte für das Tangentialportfolio, d.h., das Portfolio mit der maximalen Sharpe Ratio. Wir setzen als Nebenbedingung nur die Budget-Restriktion: kein Leverage (Fremdkapitalaufnahme), Summe der Portfoliogewichte entspricht 1.\n\n\nCode\n# function that implements the Sharpe portfolio optimization\n# with no short sale constraint!\n\n# definition of target function for maximum Sharpe portfolio\ndef calc_neg_sharpe(weights, mean_returns, cov, rf):\n    portfolio_return = np.sum(mean_returns * weights)\n    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))\n    sharpe_ratio = (portfolio_return - rf) / portfolio_std\n    return -sharpe_ratio\n\ndef max_sharpe_ratio(mean_returns, cov, rf):\n    num_assets = len(mean_returns)\n    args = (mean_returns, cov, rf)\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    result = minimize(calc_neg_sharpe, num_assets*[1./num_assets,], args=args,\n                        method='SLSQP', constraints=constraints,tol=1e-10)\n    weights=[round(x,4) for x in result['x']]\n    return weights\n\n\n\n\nCode\nweights=max_sharpe_ratio(means_est, Sigma_est, 0.06)\n\n\nGraphischer Vergleich der optimalen Portfoliogewichte: tatsächlich (1/N) versus ermittelt auf Basis geschätzter Input-Parameter:\n\n\nCode\npd.DataFrame({'wahres Gewicht': 0.25, 'geschätztes Gewicht': weights},index=df.columns). \\\nplot.bar(stacked=False, alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\nZwei Ergebnisse fallen auf. Das erste bemerkenswerte Ergebnis besteht darin, dass sich die optimalen Gewichte auf Basis der geschätzten Parameter sehr stark von den wahren optimalen Werten unterscheiden. Offensichtlich schlagen sich Schätzfehler gravierend in der Portfoliozusammensetzung nieder. Daneben weichen die Schätzwerte für die erwartete Rendite sehr stark von deren wahren Wert ab, während die Schätzwerte der Standardabweichung wesentlich näher am wahren Parameter liegen. Dies ist ein erster Hinweis darauf, dass die Schätzung der erwarteten Rendite die größten Schwierigkeiten verursacht. Diesem Hinweis gehen wir im folgenden Abschnitt weiter nach.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html#komponenten-des-schätzfehlers",
    "href": "kapitel3a.html#komponenten-des-schätzfehlers",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "4.3 Komponenten des Schätzfehlers",
    "text": "4.3 Komponenten des Schätzfehlers\nBisher haben wir den Einfluss des gesamten Schätzfehlers auf die Portfoliozusammensetzung herausgearbeitet, ohne allerdings der Frage nachzugehen, welche Quelle des Schätzfehlers (Fehlschätzung bei erwarteten Renditen, Fehlschätzung bei Varianzen, Fehlschätzung bei Korrelationen) sich besonders stark auf die Portfoliogewichte durchschlägt. Die Stärke des Einflusses hängt hierbei von zwei Größen ab, der Sensitivität der Portfoliozusammensetzung auf die Fehlschätzung und dem Ausmaß der Fehlschätzung. Im folgenden werden wir zunächst die Sensitivität der Portfoliozusammensetzung für die verschiedenen Komponenten des Schätzfehlers analysieren und anschließend Fragen nach der erreichbaren Schätzgenauigkeit für die verschiedenen Parameter diskutieren.\n\n4.3.1 Sensitivitat des optimalen Portfolios bezüglich Schätzfehlern in den verschiedenen Parametern\nZur Analyse der Sensitivitat der Portfoliogewichte in bezug auf Fehlschätzungen in den einzelnen Parametern verwenden wir wiederum die vier Aktien des Abschnittes 1 mit den wahren Parametern \\(\\mu_i\\) = 11% (erwartete Rendite), \\(\\sigma_i\\) = 25% (Standardabweichung) und \\(rho_{ij}\\) = 30% (Korrelationskoeffizient). Als Vergleichsmaßstab betrachten wir den Fall, das der Anleger sämtliche Parameter exakt kennt und sein optimales Aktienportfolio deshalb aus gleichen Anteilen in allen vier Aktien besteht. Hiermit werden drei Fälle verglichen, in denen der Anleger einen Schätzfehler bezüglich der Parameter der Aktie 1 begeht. Im ersten Fall täuscht er sich bei der erwarteten Rendite der Aktie 1, im zweiten Fall bei der Standardabweichung der Aktie 1 und im dritten Fall bei der Korrelation zwischen den Renditen von Aktie 1 und Aktie 2. Die einzelnen Fälle zur Bestimmung der Komponenten des Schatzrisikos sind in der nachfolgenden Tabelle dargestellt.\n\nWir untersuchen den Einfluß des Schätzfehlers, indem wir in einer komparativ-statischen Analyse den jeweiligen mit Schätzfehler versehenen Parameter ausgehend vom wahren Wert um ±10 Prozentpunkten in Schritten der Größe 2,0 Prozentpunkte variieren. Die erwartete Rendite bewegt sich somit im Wertebereich zwischen 1% und 21%, die Volatilitat zwischen 15% und 35% und die Korrelation zwischen 20% und 40%. Für die verschiedenen Parameterkonstellationen bestimmen wir die optimale Portfoliozusammensetzung und vergleichen diese mit der optimalen Portfoliozusammensetzung bei Kenntnis aller Parameter.\nFall 1: Schätzfehler in der erwarteten Rendite von Aktie 1, zwischen 1% und 21% um den wahren Wert 11%.\n\n\nCode\n# Berechnung der Fehlgewichtung in A1 für Fehler in der geschätzten\n# erwarteten Rendite\nest_error_mean=np.linspace(0.01, 0.21, 11) # symmetrische Fehler um wahren Wert 11%\nwa1_means=np.zeros(11) # enthält die optimierten Gewichte\nfor i in range(11):\n    means_mod=np.multiply(means_true,52) # annualisieren nicht vergessen!\n    Sigma_true_ann=np.multiply(Sigma_true,52) # annualisieren nicht vergessen!\n    means_mod[0]=est_error_mean[i]\n    weights=max_sharpe_ratio(means_mod, Sigma_true_ann, 0.06)\n    wa1_means[i]=weights[0]\n    \n\n\nFall 2: Schätzfehler in der Standardabweichung der Rendite von Aktie 1, zwischen 15% und 35% um den wahren Wert 25%.\n\n\nCode\n# Berechnung der Fehlgewichtung in A1 für Fehler in der geschätzten\n# (annualisierten) Standardabweichung\nest_error_std=np.linspace(0.15, 0.35, 11) # symmetrische Fehler um wahren Wert 25%\n# Berechnung der neuen Varianz und der Kovarianz\na1_var=np.zeros(11) # enthält die neue Varianz\na1_cov=np.zeros(11) # enthält die neue Kovarianz\nwa1_std=np.zeros(11) # enthält die optimierten Gewichte\n\nfor i in range(11):\n    a1_var[i]=est_error_std[i]**2\n    a1_cov[i]=est_error_std[i]*0.25*0.3\n    # Berechnung der neuen Varanz-Kovarianzmatrix; 7 Änderungen vornehmen\n    Sigma_true_ann=np.multiply(Sigma_true,52) # annualisieren nicht vergessen!\n    Sigma_mod=Sigma_true_ann\n    Sigma_mod[0,0]=a1_var[i]\n    Sigma_mod[0,1]=a1_cov[i]\n    Sigma_mod[0,2]=a1_cov[i]\n    Sigma_mod[0,3]=a1_cov[i]\n    Sigma_mod[1,0]=a1_cov[i]\n    Sigma_mod[2,0]=a1_cov[i]\n    Sigma_mod[3,0]=a1_cov[i]\n    means_ann=np.multiply(means_true,52) # annualisieren nicht vergessen!\n    weights=max_sharpe_ratio(means_ann, Sigma_mod, 0.06)\n    wa1_std[i]=weights[0]\n   \n\n\nFall 3: Schätzfehler in der Korrelation der Rendite von Aktie 1, zwischen 20% und 40% um den wahren Wert 30%.\n\n\nCode\n# Berechnung der Fehlgewichtung in A1 für Fehler in der geschätzten\n# Korrelation zwischen Aktie 1 und 2\nest_error_corr=np.linspace(0.20, 0.40, 11) # symmetrische Fehler um wahren Wert 25%\n# Berechnung der neuen Kovarianz\na1_cov=np.zeros(11) # enthält die neue Kovarianz\nwa1_corr=np.zeros(11) # enthält die optimierten Gewichte\n\nfor i in range(11):\n    a1_cov[i]=est_error_corr[i]*0.25*0.25\n    # Berechnung der neuen Varanz-Kovarianzmatrix; 2 Änderungen vornehmen\n    Sigma_true_ann=np.multiply(Sigma_true,52) # annualisieren nicht vergessen!\n    Sigma_mod=Sigma_true_ann\n    Sigma_mod[0,1]=a1_cov[i]\n    Sigma_mod[1,0]=a1_cov[i]\n    means_ann=np.multiply(means_true,52) # annualisieren nicht vergessen!\n    weights=max_sharpe_ratio(means_ann, Sigma_mod, 0.06)\n    wa1_corr[i]=weights[0]\n   \n\n\nDie folgende Tabelle gibt die optimalen Gewichte für Aktie 1 für die verschiedenen Fälle an.\n\n\nCode\ndf=pd.DataFrame({'1. Fall': np.round(wa1_means,2), '2. Fall': np.round(wa1_std,2), \\\n              '3. Fall': np.round(wa1_corr,2)}\\\n             , index=np.linspace(-10, 10, 11)).T\ndf.columns.name='Abweichungen vom wahren Parameterwert in (%)'\ndf\n\n\n\n\n\n\n\n\nAbweichungen vom wahren Parameterwert in (%)\n-10.0\n-8.0\n-6.0\n-4.0\n-2.0\n0.0\n2.0\n4.0\n6.0\n8.0\n10.0\n\n\n\n\n1. Fall\n-1.79\n-1.11\n-0.62\n-0.26\n0.02\n0.25\n0.44\n0.59\n0.72\n0.83\n0.93\n\n\n2. Fall\n0.66\n0.56\n0.47\n0.38\n0.31\n0.25\n0.20\n0.16\n0.12\n0.09\n0.07\n\n\n3. Fall\n0.27\n0.27\n0.26\n0.26\n0.25\n0.25\n0.25\n0.24\n0.24\n0.24\n0.23\n\n\n\n\n\n\n\nIn der Tabelle ist klar zu erkennen, dass sich Änderungen der erwarteten Rendite am stärksten auf die Portfoliozusammensetzung durchschlagen. Wird beispielsweise die erwartete Rendite von Aktie 1 um 6 Prozentpunkte überschätzt, so ergibt sich hierdurch ein optimales Gewicht für Aktie 1 in Höhe von 0,72. Im Vergleich zum optimalen Gewicht ohne Schätzfehler bedeutet dies eine Übergewichtung der Aktie 1 um 47 Prozentpunkte. Eine Fehlschätzung der Standardabweichung in gleicher Höhe schlägt sich demgegenüber wesentlich weniger stark (-0,13 = 0,12 - 0,25) auf die Portfoliozusammensetzung durch, und eine Fehlschätzung der Korrelation besitzt keinen nennenswerten Einfluss (-0,01 = 0,24 - 0,25). Dies wird anhand der nachfolgenden Abbildung nochmals verdeutlicht. Dort ist die Über- oder Untergewichtung von Aktie 1 in Abhängigkeit der Stärke des Schätzfehlers graphisch dargestellt.\n\n\nCode\nfig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig1.add_subplot(111)\nax.spines['left'].set_position('zero')\nax.spines['right'].set_position('zero')\nax.spines['top'].set_position('zero')\n\nax.spines['bottom'].set_position('zero')\nplt.plot(np.linspace(-10, 10, 11), (wa1_means-0.25)*100, 'r-', label='Fehler in der erwarteten Rendite')\nplt.plot(np.linspace(-10, 10, 11), (wa1_std-0.25)*100, 'g-', label='Fehler in der Standardabweichung')\nplt.plot(np.linspace(-10, 10, 11), (wa1_corr-0.25)*100, 'b-', label='Fehler im Korrelationskoeffizienten')\n\nplt.legend(loc=4,  frameon=True)\nplt.xlabel('Ausmaß der Fehlschätzung (in %)')\nax.yaxis.set_label_coords(-0.01,0.75)\nax.xaxis.set_label_coords(0.5,-0.01)\n\nplt.ylabel('Fehlgewichtung in Aktie 1 (in %)')\nplt.title('Auswirkung von Schätzfehlern auf die optimalen Gewichte in Aktie 1')\nplt.show()\n\n\n\n\n\n\n\n\n\nDie Abbildung zeigt deutlich, dass bereits kleine Fehler in den Parameterschätzungen zu erheblichen Änderungen bei den optimierten Gewichten führen. Dies gilt im besonderen für Schätzfehler bei den erwarteten Renditen. Die Sensitivität der Portfoliozusammensetzung auf Schätzfehler ist somit ein zentrales Problem bei der Anwendung des Portfolioansatzes von Markowitz. Wie stark ein Anleger allerdings hierdurch berührt ist, hängt außer von der Sensitivität von der erzielbaren Genauigkeit bei der Schätzung der verschiedenen Parameter ab. Wie groß die Schätzgenauigkeit für die verschiedenen Parameter ist, wird im folgenden analysiert.\n\n\n4.3.2 Größe der Schätzfehler für die verschiedenen Parameter\nAus historischen Daten sollen möglichst verläßliche Schätzwerte für die erwartete annualisierte Rendite \\((\\mu_i)\\) und die annualisierte Standardabweichung \\((\\sigma_i)\\) ermittelt werden. (Auf eine Analyse für die Korrelation verzichten wir im folgenden, da - wie oben berichtet - die Sensitivität der Portfoliozusammensetzung auf Fehlschätzungen der Korrelation sehr gering ist.) Hierzu stehe eine Zeitreihe zur Verfügung, die n (nicht annualisierte) Periodenrenditen \\(r_{t,i}\\) enthält, welche unabhängig, identisch und normalverteilt seien. Ihre Verteilung ist durch den Erwartungswert \\(\\mu_i\\Delta t\\) und die Varianz \\(\\sigma^2_i\\Delta t\\) charakterisiert. Um den Schätzfehler zu reduzieren, wird der Anleger versuchen, die Anzahl der Beobachtungen, die in seine Schätzung eingehen, zu erhöhen. Dies kann er dadurch erreichen, dass er den Schätzzeitraum \\(T\\) (gemessen in Jahren) verlängert oder den Schätzzeitraum in kürzere Teilintervalle einteilt, also \\(\\Delta t\\) verkürzt.\nAus verschiedenen Gründen ist einem Anleger jedoch die Verlängerung des Beobachtungszeitraums \\(T\\) häufig nicht möglich. Bei jungen Unternehmen liegt keine lange Kurshistorie vor. Andere Unternehmen weisen zwar eine längere Kurshistorie auf, jedoch sind diese durch Brüche gekennzeichnet, die durch Umstrukturierungen oder Unternehmenszukäufe verursacht sind. Schließlich ist gegen die Verwendung einer sehr langen Kurshistorie einzuwenden, dass die Renditeparameter nicht über Jahrzehnte konstant bleiben. Dagegen genießt der Anleger bei der Wahl der Länge der Teilintervalle größere Freiheiten. Er kann von Jahresdaten auf Quartals-, Monats-, Wochen-, Tagesdaten oder gar innertägliche Daten wechseln, um so die Anzahl der Beobachtungen zu erhöhen. Im folgenden wollen wir prüfen, wie sich dies auf die Qualität des Schätzers für die erwartete Rendite und die Varianz niederschlägt. Hierzu müssen wir zunächst eine Annahme treffen, welche Schätzer der Anleger verwendet. Wir unterstellen, dass er wiederum die einfache historisch basierte Schätzung verwendet, also das arithmetische Mittel für das erste Verteilungsmoment. Unter Verwendung der Tatsache, dass die Schätzperiode \\(T\\) sich ergibt als die Anzahl der Subperioden n multipliziert mit deren Länge \\(\\Delta t\\), lässt sich der Mittelwert-Schätzer schreiben als:\n\\[ (1)\\quad \\hat{\\mu_i}=\\frac{1}{\\Delta t}\\frac{1}{n}\\sum_{t=1}^{n}r_{t,i}=\\frac{1}{T}\\sum_{t=1}^{n}r_{t,i}.\\]\nDieser Schätzer ist erwartungstreu, d.h., er trifft im Mittel den wahren Parameterwert \\(\\mu_i\\). Die Varianz des Schätzers ist ein Maß für dessen Güte. Je geringer die Varianz ist, um so weniger streut der Schätzer um den wahren Parameterwert. Die Varianz des Schätzers beträgt:\n\\[ (2)\\quad var(\\hat{\\mu_i})=\\frac{\\sigma^2_i}{T}.\\]\nBemerkenswerterweise hängt dieses Gütemaß bei gleichbleibendem Beobachtungszeitraum \\(T\\) nicht von der Datenfrequenz ab. Dies bedeutet, dass eine Erhöhung der Beobachtungsfrequenz nicht zu genaueren Schätzergebnissen führt. Daneben fällt auf, dass der Schätzfehler im Verhältnis zu der zu schätzenden Größe sehr groß ist. Dies kann man sich verdeutlichen, wenn man erneut die Daten aus unserem Beispiel in Abschnitt 1 verwendet. Die erwartete Rendite einer Aktie beträgt 11% p.a. und die Standardabweichung der Rendite 25% p.a. In der folgenden Tabelle wird die Breite eines 95%-Konfidenzintervalls in Abhängigkeit der Länge des Schätzzeitraums \\(T\\) dargestellt. Allgemein lautet die Formel zur Längenberechnung des (asymptotischen) \\((1-\\alpha)\\)-Konfidenzintervalls:\n\\[ (3)\\quad 2\\cdot[Q_{1-\\frac{\\alpha}{2}}\\cdot\\frac{\\sigma_i}{\\sqrt{T}}].\\]\nHierbei bezeichnet \\(Q_{1-\\frac{\\alpha}{2}}\\) das \\((1-\\frac{\\alpha}{2})\\)-Quantil der Standardnormalverteilung. Für \\(\\alpha=5\\%\\) gilt: \\(Q_{97,5}=1,96\\)\n\n\nCode\n# Länge des Schätzzeitraums T in Jahren\nest_period=[1, 5, 10, 20, 50]\n# Breite des Konfidenzintervalls\nconfidence=np.zeros(5)\nfor i in range(5):\n    confidence[i]=round((2*1.96*0.25/np.sqrt(est_period[i]))*100, 2)\npd.DataFrame({'Schätzzeitraum T in Jahren': est_period, \\\n              'Breite des Konfidenzintervalls (%)': confidence})    \n\n\n\n\n\n\n\n\n\nSchätzzeitraum T in Jahren\nBreite des Konfidenzintervalls (%)\n\n\n\n\n0\n1\n98.00\n\n\n1\n5\n43.83\n\n\n2\n10\n30.99\n\n\n3\n20\n21.91\n\n\n4\n50\n13.86\n\n\n\n\n\n\n\nSelbst bei einem Schätzzeitraum von 10 Jahren beträgt die Breite dieses Intervalls noch mehr als 30 Prozentpunkte. Dies bedeutet, dass mit einer Wahrscheinlichkeit von 95% der Schätzfehler nicht mehr als 15,5 Prozentpunkte beträgt, der Schätzwert also im Intervall [-4,5%;+26,5%] liegt. Wie wir aber oben gezeigt haben, besitzt bereits eine deutlich geringere Fehlschätzung einen dramatischen Einfluß auf die Portfoliozusammensetzung.\nNun wenden wir uns dem Schätzwert für die Varianz zu. Unter Verwendung der definitorischen Beziehung \\(T = n \\cdot \\Delta t\\) lässt sich der einfache historisch basierte Schätzer schreiben als:\n\\[ (4)\\quad \\hat{\\sigma}^2_i=\\frac{1}{T-\\Delta t}\\sum_{t=1}^{n}(r_{t,i}-\\hat{\\mu_i}\\Delta t)^2.\\]\nDie asymptotische Varianz dieses Schätzers beträgt (siehe Memmel, 2004, S. 33):\n\\[ (5)\\quad var(\\hat{\\sigma}^2_i)=\\frac{2\\sigma^4_i\\Delta t}{T}.\\]\nDie Güte des Varianzschätzers lässt sich somit bei gegebenem Schätzzeitraum \\(T\\) durch eine Erhöhung der Datenfrequenz (Verkleinerung von \\(\\Delta t\\)) verbessern. So verdreifacht sich beispielsweise durch Übergang von Quartalsdaten auf Monatsdaten die Anzahl der Beobachtungen, und der Schätzfehler reduziert sich ungefähr auf ein Drittel des ursprünglichen Wertes.\nDie asymptotische Varianz des Schätzers für die Renditestandardabweichung lässt sich bestimmen als :\n\\[ (6)\\quad var(\\hat{\\sigma}_i)=\\frac{1}{2}\\sigma^2_i\\frac{\\Delta t}{T}.\\]\nIn der folgenden Tabelle sind die Breiten des 95%-Konfidenzintervalles (in %) für den Schätzer der Standardabweichung der annualisierten Renditen für verschiedene Längen der Schätzperioden und verschiedene Datenfrequenzen aufgeführt.\n\n\nCode\n# Länge des Schätzzeitraums T in Jahren\nest_period=[1, 5, 10, 20, 50]\n# Breite des Konfidenzintervalls\nconfidence_daily=np.zeros(5) # delta_t=1/250\nconfidence_weekly=np.zeros(5) # delta_t=1/52\nconfidence_monthly=np.zeros(5) # delta_t=1/12\nconfidence_quarterly=np.zeros(5) # delta_t=1/4\n\nfor i in range(5):\n    confidence_daily[i]=round(2*1.96*np.sqrt(0.25**2/ \\\n                    (2*est_period[i]*250))*100, 2)\n    confidence_weekly[i]=round(2*1.96*np.sqrt(0.25**2/ \\\n                    (2*est_period[i]*52))*100, 2)\n    confidence_monthly[i]=round(2*1.96*np.sqrt(0.25**2/ \\\n                    (2*est_period[i]*12))*100, 2)\n    confidence_quarterly[i]=round(2*1.96*np.sqrt(0.25**2/ \\\n                    (2*est_period[i]*4))*100, 2)\nZeitraum=['T=1 Jahr', 'T=5 Jahre', 'T=10 Jahre', 'T=20 Jahre', 'T=50 Jahre']    \npd.DataFrame({'Tagesdaten': confidence_daily, 'Wochendaten': confidence_weekly,\\\n              'Monatsdaten': confidence_monthly, 'Quartalsdaten': confidence_quarterly},\\\n             index=Zeitraum) \n\n\n\n\n\n\n\n\n\nTagesdaten\nWochendaten\nMonatsdaten\nQuartalsdaten\n\n\n\n\nT=1 Jahr\n4.38\n9.61\n20.00\n34.65\n\n\nT=5 Jahre\n1.96\n4.30\n8.95\n15.50\n\n\nT=10 Jahre\n1.39\n3.04\n6.33\n10.96\n\n\nT=20 Jahre\n0.98\n2.15\n4.47\n7.75\n\n\nT=50 Jahre\n0.62\n1.36\n2.83\n4.90\n\n\n\n\n\n\n\nIm Vergleich mit der vorherigen Tabelle fällt auf, dass die Standardabweichung wesentlich genauer geschätzt werden kann als die erwartete Rendite. Dies gilt c.p. um so stärker, je größer die Datenfrequenz ist. So kann unter Verwendung von Tagesdaten bereits bei einer Schätzperiode von einem Jahr eine recht präzise Varianzschätzung vorgenommen werden, während für diese Frist die erwartete Rendite nur mit einer hohen Ungenauigkeit geschätzt werden kann. Die bisher gewonnenen Ergebnisse scheinen damit zu implizieren, dass ein Anleger bei gegebener Schätzperiode eine möglichst hohe Datenfrequenz wählen sollte, da er hierdurch gemäß (5) den Schätzfehler in der Varianz verringert und den Schätzfehler in der erwarteten Rendite unbeeinflußt läßt. Dieser Aussage ist allerdings nicht uneingeschränkt zuzustimmen. Eine sehr hohe Datenfrequenz bringt in der Praxis nämlich das Problem mit sich, dass die empirisch beobachteten Renditen nicht mehr unabhängig, identisch und normalverteilt sind. So findet man beispielsweise, dass Aktienrenditen bei einer hohen Datenfrequenz (bspw. Tagesdaten) Autokorrelation aufweisen und ihre Verteilung zu viel Masse in den Enden aufweist.\nZusammenfassend kann man damit festhalten: Die Schätzung der erwarteten Renditen verursacht wesentlich größere Probleme als die Schätzung der Renditevarianz. Die Schätzung der erwarteten Renditen kann nämlich nicht durch eine Erhohung der Datenfrequenz verbessert werden, während eine höhere Datenfrequenz zu besseren Schätzungen der Renditevarianz führt. Da außerdem die Portfoliozusammensetzung wesentlich sensitiver auf Fehlschätzungen in den erwarteten Renditen als in den Varianzen reagiert, muss konstatiert werden, dass Schätzfehler in erwarteten Renditen das zentrale Problem bei der Implementierung des Markowitz-Modells darstellen. Deshalb konzentrieren wir uns im folgenden ausschließlich auf Schätzfehler in den erwarteten Renditen und unterstellen, dass die zweiten Momente der Verteilung (Varianzen, Korrelationen) dem Anleger bekannt sind.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html#lösungsansätze-für-das-schätzproblem",
    "href": "kapitel3a.html#lösungsansätze-für-das-schätzproblem",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "4.4 Lösungsansätze für das Schätzproblem",
    "text": "4.4 Lösungsansätze für das Schätzproblem\nIn den bisherigen Abschnitten haben wir herausgearbeitet, warum die traditionelle Umsetzung der Portfoliotheorie Probleme aufwirft. Erwartete Renditen lassen sich mit dem traditionellen Schätzansatz des arithmetischen Mittels nur sehr ungenau schätzen. Dies führt typischerweise zu extremen und suboptimalen Portfoliogewichten.\nGrundsätzlich bieten sich mehrere Möglichkeiten an, dieses Problems Herr zu werden. Eine erste Möglichkeit besteht darin, ein ökonomisch fundiertes Modell zu entwickeln, aus dem sich endogen die optimalen Portfoliogewichte ergeben und das es erlaubt, auf leichter zu ermittelnde Größen anstelle der erwarteten Renditen zurückzugreifen. Ein Beispiel hierfür stellt das CAPM dar, bei dem die optimalen Portfoliogewichte den anteiligen Marktkapitalisierungen entsprechen.\nEine zweite Möglichkeit, den Einfluss von Schätzfehlern und die daraus resultierenden extremen Portfoliogewichte zu reduzieren, besteht darin, exogene Schranken (Constraints) für die erwarteten Renditen bzw. die Portfoliogewichte vorzugeben. Den ersten Ansatz wählt Merton (1980), der unterstellt, dass die wahren erwarteten Renditen in einer Welt mit risikoaversen Anlegern nicht negativ sein können und gleichzeitig einen bestimmten Höchstwert nicht überschreiten sollten. Ein einfaches Beispiel für exogene Schranken bezüglich der Portfoliogewichte - diese sind bereits Bestandteil der Originalarbeit von Markowitz - besteht im Verbot von Leerverkaufen. Hierdurch werden die Portfoliogewichte in jeder Aktie auf den Bereich [0%; 100%] restringiert. Die optimale Strategie besteht hierbei häufig aus Randlösungen, d.h., in den meisten Fällen konzentriert sich das Anlagevolumen auf wenige Aktien, die sich in der jüngsten Vergangenheit besonders gut entwickelt haben (Winner-Strategie). Hierdurch geht Diverifikationspotential innerhalb des Portfolios verloren. Um diesem Mißstand abzuhelfen, werden z.B. im Rahmen der relativen (Index- oder Benchmark-basierten) Optimierung die Abweichungen der Portfolioanteile von den Gewichten eines Index- oder Benchmarkportfolios begrenzt. Als Folge der erzwungenen, aber nicht optimalen Diversifikation reduziert sich zwar das Portfoliorisiko, doch leidet gleichzeitig die Wertentwicklung dieses Portfolios.\nDie dritte Möglichkeit besteht darin, gänzlich auf die Schätzung von erwarteten Renditen zu verzichten. So könnte ein Anleger beispielsweise das global varianzminimale Aktienportfolio oder ein gleichgewichtetes Portfolio wählen. Diese Portfoliozusammensetzung muss als heuristisch bezeichnet werden, da sie sich nicht aus einem allgemeinen Markowitz-Ansatz ergibt. Trotzdem haben verschiedene empirische Studien (z.B. DeMiguel et al., 2009) ergeben, dass mit diesen Strategien bessere Ergebnisse erzielt werden können als mit der traditionellen Umsetzung der Portfoliotheorie.\nNeben diesen klassischen heuristischen Ansätzen haben sich seit der Finanzkrise 2008-2009 zunehmend risikogesteuerte Ansätze etabliert. Die Portfoliobildung basiert auch hier allein auf Volatilitäts- und Korrelationsannahmen und die Diversifikation wird in den Mittelpunkt gestellt. Prognosen erwarteter Renditen spielen keine Rolle und werden nicht benötigt. Drei Methoden einer risikogesteuerten Portfoliokonstruktion werden unterschieden: Equal-Risk-Budget (ERB), Equal-Risk-Contribution (ERC) und Maximum-Diversification (MD), wobei die ersten Beiden als sogenannte Risk Parity Ansätze bezeichnet werden. Alle drei Ansätze sind methodisch eng verwandt. Im Grundsatz soll jederzeit mit vergleichbarem Risiko in alle Assetklassen investiert werden. Das Gewicht einer Assetklasse wird dabei reduziert, wenn ihre Volatilität oder ihre Korrelation zu einer anderen Assetklasse steigt.\nDie vierte Möglichkeit zur Reduzierung des Einflusses von Schätzrisiken in den erwarteten Renditen besteht darin, den Schätzer für erwartete Renditen zu verbessern und diesen verbesserten Schätzwert dann als Inputvariable für die Portfoliooptimierung zu verwenden. Eine beliebte Klasse solcher verbesserter Schätzer sowohl für \\(\\mu\\) als auch \\(\\Sigma\\) stellen die sogenannten geschrumpften Schätzer dar.\nDie fünfte Möglichkeit besteht schließlich darin, (wie bei der vierten Möglichkeit) einen verbesserten Schätzer für die erwarteten Renditen zu verwenden, aber zusätzlich noch bei der Portfoliooptimierung die Existenz des verbleibenden Schätzrisikos zu berücksichtigen. In diesem Ansatz wird also explizit berücksichtigt, dass der Anleger zwei Arten von Risiken ausgesetzt ist, dem Renditeänderungsrisiko und dem Schätzrisiko. Zwei bekannte Vertreter dieses Ansatzes sind die Portfolio-Resampling Methode von Michaud und Michaud (2008), und das Black/Litterman (BL) Modell (siehe Black und Litterman, 1992).\nDie folgende Abbildung untergliedert noch einmal die oben skizzierten Lösungsansätze nach den zugrundeliegenden Ansatzpunkten.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html#lernvideos",
    "href": "kapitel3a.html#lernvideos",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "4.5 Lernvideos",
    "text": "4.5 Lernvideos\n\n4.5.1 Video Teil 1\n\n\n\n4.5.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel3a.html#literatur",
    "href": "kapitel3a.html#literatur",
    "title": "4  Schätzrisiken in der Portfoliotheorie",
    "section": "4.6 Literatur",
    "text": "4.6 Literatur\nBlack, F., Litterman R. (1992). Global Portfolio Optimization. Financial Analysts Journal (September-October), 28-43.\nDeMiguel, V., Garlappi, L., Uppa, R. (2009). Optimal Versus Naive Diversification: How Inefficient is the 1/N Portfolio Strategy? Review of Financial Studies 22, 1915-1953.\nMarkowitz, H.M. (1952). Portfolio Selection. Journal of Finance 7, 77-91.\nMerton, R.C. (1980). On Estimating the Expected Return on the Market: An Exploratory Investigation. Journal of Financial Economics 8, 323-361.\nMichaud, R.O, Michaud, R.O., (2008). Efficient Asset Management: A Practical Guide to Stock Portfolio Optimization and Asset Allocation, 2nd Edition, Oxford University Press.\nTobin, J. (1958). Liquidity Preference as Behaviour Towards Risk. Review of Economic Studies 25, 65-86.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Schätzrisiken in der Portfoliotheorie</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html",
    "href": "kapitel4a.html",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "",
    "text": "5.1 Einleitung\nEine naheliegende Herangehensweise zur Adressierung der Schätzfehlerproblematik befasst sich mit dem in der ursprünglichen Studie von Markowitz unberücksichtigten Schritt der Bestimmung von verbesserten Schätzern für die Inputparameter \\(\\mu\\) und \\(\\Sigma\\). Dabei besteht die grundlegende Problematik darin, dass es sich bei den Annahmen über die zukünftigen Werte dieser Parameter stets um Schätzungen handelt und diese folglich mit Unsicherheit behaftet sind. Das Ziel bei der Entwicklung optimierter Schätzverfahren ist es folglich, die Auswirkungen der Schätzfehlerproblematiken durch eine verbesserte Schätzung der Parameter zu reduzieren.\nAuf den ersten Blick erscheint es überraschend, dass es möglich ist, einen besseren Schätzer für \\(\\mu\\) als das arithmetische Mittel zu finden, da letzteres doch bei normalverteilten Renditen den besten unverzerrten Schätzer darstellt. Trotzdem bietet sich Verbesserungspotential, indem man - anders als beim arithmetischen Mittel - für die Schätzung der erwarteten Rendite von Aktie i nicht nur Zeitreiheninformationen bezüglich der Aktie i verwendet, sondern auch Informationen aus sonstigen Aktien. Ökonomisch ist dieses Verbesserungspotential nicht überraschend: Das arithmetische Mittel schätzt beispielsweise die erwartete Rendite von BASF lediglich aus den vergangenen Renditen von BASF, während z.B. die sogenannten geschrumpften Schätzer zusätzlich noch Informationen aus der Zeitreihe der Bayer-Aktie verwenden. Im Ergebnis erhält man hierdurch einen Vektor für erwartete Renditen, der sich als gewogenes Mittel der arithmetischen Mittelwerte und einem exogenen Schätzwert (sog. Prior) berechnet. Im Kern werden so die ursprünglich mit Unsicherheit behafteten einfachen historisch basierten Schätzwerte an einen vordefinierten Prior angepasst.\nDie folgenden Abschnitte stellen die drei bekanntesten geschrumpften Schätzer im Rahmen der Portfoliooptimerung vor: den James-Stein Schätzer und den Bayes-Stein Schätzer für den Vektor der zukünftigen erwarteten Renditen \\(\\mu\\), und den Ledoit-Wolf Schätzer für die zukünftige Varianz-Kovarianzmatrix \\(\\Sigma\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#james-stein-schätzer-für-mu",
    "href": "kapitel4a.html#james-stein-schätzer-für-mu",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.2 James-Stein Schätzer für \\(\\mu\\)",
    "text": "5.2 James-Stein Schätzer für \\(\\mu\\)\nBei der Schätzung des Erwartungswerts nach der Methode von James und Stein (1961) wird dabei als Prior der durchschnittliche Renditemittelwert aller Wertpapiere in der Stichprobe herangezogen (dieser wird im Englischen auch als “Grand-Mean” bezeichnet). Die einzelnen Mittelwerte werden im Ausmass des eruierten Schrumpfungsfaktors \\(\\hat{w}\\) in die Richtung dieses Grand-Mean angepasst, respektive geschrumpft. Je weiter die individuellen Stichprobenmittelwerte vom durchschnittlichen Mittelwert entfernt sind, desto grösser ist das Ausmass der Schrumpfung. Durch diesen Prozess kann der Einfluss von Extremwerten in der Stichprobe reduziert werden, wodurch die Robustheit des Schätzers optimiert und folglich auch die Sensitivität des Portfolios reduziert werden kann. Die Darstellung der mathematischen Konzeption des Schätzers erfolgt im Wesentlichen anhand von Jorion (1986, S. 283 ff.).\nDie Formel für den James-Stein Schätzer definiert sich wie folgt:\n\\[ (1) \\quad \\hat{\\mu}_{JS}=(1-\\hat{w})Y+\\hat{w}Y_0\\iota .\\]\nDabei stellt \\(\\iota\\) den Einheitsvektor der Dimension \\(Nx1\\) dar und \\(Y^T=(\\bar{r}_1, ..., \\bar{r}_N)\\) den Zeilenvektor der \\(N\\) historischen Renditemittelwerte. \\(\\bar{r}_i\\) bezeichnet den Mittelwert (im Zeitpunkt \\(t\\)) der Renditen von Wertpapier \\(i\\) auf Basis einer Zeitreihe mit \\(k\\) Beobachtungen:\n\\[ (2) \\quad \\bar{r}_i=\\frac{1}{k}\\sum_{j=t-k}^{t}r_{i,j}  .\\]\nDer als Prior festgelegte Wert in der Form des Grand-Mean ergibt sich aus:\n\\[ (3) \\quad Y_0=\\frac{1}{N}\\sum_{i}^{N}\\bar{r}_{i} . \\]\nDer Schrumpfungsfaktor \\(\\hat{w}\\) lässt sich wie folgt berechnen:\n\\[ (4) \\quad \\hat{w}=\\min(1, \\frac{N-2}{k(Y-Y_0\\iota)^T\\Sigma^{-1}(Y-Y_0\\iota)}). \\]\nDer Schrumpfungsfaktor umfasst einen Bereich von null bis eins. Es gilt: Je mehr sich der Wert des Gewichts \\(\\hat{w}\\) an den Wert 1 annähert, umso mehr werden die Stichprobenmittelwerte in Richtung der durchschnittlichen Rendite aller Wertpapiere geschrumpft. Gleichung (4) macht deutlich, dass der Schrumpfungsfaktor von der gesamten Anzahl (\\(k\\)) an Beobachtungen im Schätzzeitraum, der Anzahl (\\(N\\)) der Wertpapiere, der Varianz-Kovarianzmatrix \\(\\Sigma\\) sowie dem Abstand zwischen den individuellen durchschnittlichen historischen Renditen der Wertpapiere und der durchschnittlichen Rendite aller Wertpapiere abhängt.\nDer Gewichtungsfaktor \\(\\hat{w}\\) bestimmt, wie stark Zeitreiheninformationen und eine exogene Information die Schätzung für die erwarteten Renditen beeinflussen. Bei einem langen Beobachtungszeitraum (\\(k\\) groß) werden die Informationen aus der Zeitreihe hoch gewichtet, d.h. \\(\\hat{w}\\) ist klein. Dagegen steigt der Einfluss des Vorwissens, falls die wahren erwarteten Renditen eng um den (einheitlichen) Schätzwert \\(Y_0\\) liegen. Aus (1) wird klar, dass die Verbesserung der Schätzung aus der Berücksichtigung des Priors resultiert. Der Ansatz von James und Stein verhindert somit extreme Schätzwerte für erwartete Renditen durch eine implizite Glättung mittels des Prior.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#bayes-stein-schätzer-für-mu",
    "href": "kapitel4a.html#bayes-stein-schätzer-für-mu",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.3 Bayes-Stein Schätzer für \\(\\mu\\)",
    "text": "5.3 Bayes-Stein Schätzer für \\(\\mu\\)\nAls eine weitere Methode im Bereich der geschrumpften Schätzer entwickelte Jorion (1986) den Bayes-Stein Schätzer, welcher ebenfalls die Schrumpfung der einzelnen Stichprobenmittelwerte in Richtung eines globalen Mittelwerts anstrebt. Im Unterschied zum James-Stein Schätzer wird hier allerdings die erwartete Rendite des Minimum Varianz Portfolios (MVP) als globaler Mittelwert angenommen, wohingegen der Prozess der Schrumpfung mit demjenigen des James-Stein Schätzers kongruent ist. Begründet werden kann die Wahl des MVP damit, dass bei der Bestimmung der Gewichte des MVP keine Annahmen bezüglich der erwarteten Renditen in die Berechnung einfliessen und diese somit nur von den Werten der Varianz-Kovarianzmatrix abhängig sind. Falls nur die Budgetrestriktion als Nebenbedingung bei der Optimierung Berücksichtigung findet, läßt sich der Gewichtsvektor des MVP analytisch bestimmen (vgl. z.B. Franzen und Schäfer, 2018, S. 188 f.):\n\\[ (5) \\quad w_{MVP}=\\frac{\\iota^T\\Sigma^{-1}}{\\iota^T\\Sigma^{-1}\\iota}. \\]\nUnter der Annahme, dass Schätzfehler in Bezug auf die Risikoterme (Varianzen und Kovarianzen) vernachlässigt werden können, wird das MVP somit weniger stark von Schätzfehlern beeinflusst. Für die erwartete Rendite des MVP als Prior folgt somit (mit \\(Y\\) als \\(Nx1\\) Spaltenvektor der empirischen Renditemittelwerte):\n\\[ (6) \\quad \\hat{\\mu}_{MVP}=w_{MVP}Y=\\frac{\\iota^T\\Sigma^{-1}Y}{\\iota^T\\Sigma^{-1}\\iota}. \\]\nDer Bayes-Stein Schätzer ergibt sich aus:\n\\[ (7) \\quad \\hat{\\mu}_{BS}=(1-\\hat{w})Y+\\hat{w}\\hat{\\mu}_{MVP}\\iota . \\]\nDer Schrumpfungsfaktor, mit welchem die einzelnen empirischen Renditen in Richtung der Rendite des MVP angepasst werden, ist definiert durch:\n\\[ (8) \\quad \\hat{w}=\\frac{N+2}{(N+2)+k(Y-\\hat{\\mu}_{MVP}\\iota)^T\\Sigma^{-1}(Y-\\hat{\\mu}_{MVP}\\iota)}, \\]\nmit \\(N\\) als Zahl der im Portfolio enthaltenen Wertpapiere sowie \\(k\\) als Anzahl Perioden in der Stichprobe. Zusätzlich zur Anpassung der erwarteten Renditen wird aufgrund des Umstands, dass das wahre \\(\\Sigma\\) unbekannt ist, eine Anpassung der Schätzung der Varianz-Kovarianzmatrix nach Zellner und Chetty (1965) vorgeschlagen, mit \\(\\hat{\\Sigma}\\) als die empirisch geschätzte Varianz-Kovarianzmatrix (Jorion, 1986, S. 286):\n\\[ (9) \\quad \\hat{\\Sigma}_{ZC}=\\frac{k-1}{k-N-2}\\hat{\\Sigma} . \\]\nMit der Absicht, die Auswirkungen der Schätzfehlerproblematik im Rahmen der Portfolioauswahl zu untersuchen, stellte Jorion (1985) in einer früheren Studie bereits fest, dass die geschrumpften Schätzer die konventionellen empirischen Mittelwerte in Bezug auf die out-of-sample Performance dominieren. In der Folge konnte Jorion (1986) zusätzlich die Überlegenheit des Bayes-Stein Schätzers, verglichen mit dem klassischen Ansatz, belegen.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#ledoit-wolf-schätzer-für-sigma",
    "href": "kapitel4a.html#ledoit-wolf-schätzer-für-sigma",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.4 Ledoit-Wolf Schätzer für \\(\\Sigma\\)",
    "text": "5.4 Ledoit-Wolf Schätzer für \\(\\Sigma\\)\nLedoit und Wolf (2003) greifen die Problematik der Schätzung von Varianz-Kovarianzmatrizen aus einer Stichprobe auf und schlagen eine Schrumpfung der empirischen Varianz-Kovarianzmatrix in Richtung einer Matrix mit einer festen Struktur vor. Da die Anzahl der zu schätzenden Kovarianzen quadratisch mit der Anzahl \\(N\\) der Wertpapiere steigt (es gilt: Anzahl Kovarianzen \\(=0,5\\cdot N(N-1)\\)), gewinnt die Schätzfehlerproblematik bei der Bestimmung der Varianz-Kovarianzmatrix für große Portfolios an Bedeutung.\nDas grundlegende Prinzip bei der Schrumpfung der Varianz-Kovarianzmatrix umfasst die Kombination der folgenden Elemente:\n\nempirische Varianz-Kovarianzmatrix \\(\\hat{\\Sigma}\\) aus der Stichprobe ohne feste Struktur\nSchrumpfungsfaktor \\(\\hat{w}\\)\nVarianz-Kovarianzmatrix mit einer festen Struktur \\(\\hat{\\Sigma}_{cc}\\)\n\nDurch eine konvex-lineare Kombination (über den Schrumpfungsfaktor) der beiden Matrizen entsteht ein Kompromiss zwischen der Varianz-Kovarianzmatrix aus der Stichprobe \\(\\hat{\\Sigma}\\) und einer vorgegebenen festen Struktur \\(\\hat{\\Sigma}_{cc}\\), dem Schrumpfungsziel. Dabei sollte das Schrumpfungsziel zwei wesentliche Kriterien gleichermaßen erfüllen: Einerseits sollte es nur eine geringe Anzahl an freien Parametern besitzen, so dass eine feste Struktur des Schätzers entsteht, und andererseits sollte es wichtige Merkmale der unbekannten zu schätzenden Parameter berücksichtigen. Ledoit und Wolf (2003) schlagen bei der Festlegung der Varianz-Kovarianzmatrix \\(\\hat{\\Sigma}_{cc}\\) entweder die Ermittlung von Renditekorrelationen auf Basis des Einfaktormodells von Sharpe (1963) oder die Annahme konstanter paarweiser Korrelationen vor. Da der letztgenannte Vorschlag bei in der Regel vergleichbaren Ergebnissen einfacher zu implementieren ist, soll er auch im Folgenden zur Bestimmung von \\(\\hat{\\Sigma}_{cc}\\) verwendet werden.\nDie zuvor angesprochene konvex-lineare Kombination der beiden Matrizen ergibt sich wie folgt:\n\\[ (10) \\quad \\hat{\\Sigma}_{LW}=\\hat{w}\\hat{\\Sigma}_{cc}+(1-\\hat{w})\\hat{\\Sigma},\\]\nwobei \\(\\hat{\\Sigma}\\) die Varianz-Kovarianzmatrix der Stichprobe darstellt und \\(\\hat{\\Sigma}_{cc}\\) die Varianz-Kovarianzmatrix der Stichprobe unter der Annahme einer konstanten Korrelation (constant correlation - cc).\nDie Berechnung der zuletzt genannten Varianz-Kovarianzmatrix erfolgt stufenweise. Da sich die Kovarianz \\(Cov(X,Y)\\) zweier Zufallsvariablen \\(X\\) und \\(Y\\) als Produkt der Volatilitäten (\\(\\sigma_X, \\sigma_Y\\)) und dem Korrelationskoeffizienten \\(Corr(X,Y)\\) schreiben lässt (d.h., \\(Cov(X,Y)=\\sigma_X \\cdot \\sigma_Y \\cdot Corr(X,Y)\\)), gilt für die empirische Varianz-Kovarianzmatrix:\n\\[ (11) \\quad \\hat{\\Sigma}=\\Lambda C \\Lambda^T, \\]\nwobei \\(\\Lambda\\) eine Diagonalmatrix der Renditevolatilitäten und \\(C\\) die Korrelationsmatrix der Stichprobe verkörpert. Mit \\(\\hat{\\rho}_{ij}\\) als empirischen Korrelationskoeffizienten zwischen den Renditen von Wertpapier \\(i\\) und \\(j\\), lässt sich \\(C\\) darstellen als:\n\\[ (12)\\quad C=\\left( \\begin{array}{rrrr}\n1 & \\hat{\\rho}_{12} & \\dots & \\hat{\\rho}_{1N} \\\\\n\\hat{\\rho}_{21} & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\ddots & \\hat{\\rho}_{N-1N} \\\\\n\\hat{\\rho}_{N1} & \\dots & \\hat{\\rho}_{NN-1} & 1 \\\\\n\\end{array}\\right) .\\]\nZur Berechnung von \\(\\hat{\\Sigma}_{cc}\\) wird einfach die Korrelationsmatrix aus der Stichprobe durch eine mit konstanten Korrelationen ersetzt\n\\[ (13)\\quad C_{cc}=\\left( \\begin{array}{rrrr}\n1 & \\hat{\\rho} & \\dots & \\hat{\\rho} \\\\\n\\hat{\\rho} & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\ddots & \\hat{\\rho} \\\\\n\\hat{\\rho} & \\dots & \\hat{\\rho} & 1 \\\\\n\\end{array}\\right) ,\\]\nwobei \\(\\hat{\\rho}\\) den Durchschnitt aller (\\(0,5 \\cdot N(N-1)\\)) Korrelationen aus der Stichprobe umfasst. Es gilt:\n\\[ (14) \\quad \\hat{\\rho}=\\frac{2}{(N-1)N}\\sum_{i=1}^N \\sum_{j=i+1}^N \\hat{\\rho}_{ij} . \\]\nFür das Schrumpfungsziel folgt damit: \\(\\hat{\\Sigma}_{cc}=\\Lambda C_{cc} \\Lambda^T\\)\nDie Wahl eines optimalen Schrumpfungsfaktors fällt nach Ledoit und Wolf (2003) auf diejenige Konstante, die den erwarteten Abstand zwischen dem geschrumpften Schätzer und der wahren Varianz-Kovarianzmatrix minimiert. Es kann gezeigt werden, dass sich die optimale Intensität der Schrumpfung proportional zu einer Konstanten \\(\\hat{g}\\) dividiert durch den Stichprobenumfang \\(k\\) verhält. Der optimale Schrumpfungsfaktor ergibt sich demnach wie folgt:\n\\[ (15) \\quad \\hat{w}= max \\left \\{0, min \\left \\{\\frac{\\hat{g}}{k},1\\right \\} \\right \\}. \\]\nDie Berechnung der drei geschrumpften Schätzer und ihre Auswirkungen auf die Zusammensetzung optimaler Portfolios werden im Rahmen der folgenden Fallstudie veranschaulicht.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#beginn-der-fallstudie",
    "href": "kapitel4a.html#beginn-der-fallstudie",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.5 Beginn der Fallstudie",
    "text": "5.5 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nimport numpy.linalg as la\n\n\n\n5.5.1 Laden und Beschreiben der Datenbasis\nDer verwendete Datensatz enthält Kurshistorien (Monatsanfangskurse) der folgenden zehn Unternehmen: Abbott Laboratories (ABT), Boeing Industries (BA), Costco Wholesale (COST), Cisco Systems (CSCO), IBM (IBM), Intel (INTC), Merk (MRK), Microsoft (MSFT), AT&T (T), und Exxon Mobil Corporation (XOM). Die Kurshistorien beziehen sich auf den Zeitraum 12.2004-12.2009 (61 Monate).\n\n\nCode\n# hier den Dateipfad einfügen!\n# cd \"...\"\n\n\n\n\nCode\nframe = pd.read_excel('Kapitel A1.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe.tail(6)\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n2009-07-01\n44.99\n42.91\n49.50\n22.01\n117.93\n19.25\n30.01\n23.52\n26.23\n70.39\n\n\n2009-08-03\n45.23\n49.67\n50.98\n21.60\n118.05\n20.32\n32.43\n24.65\n26.05\n69.15\n\n\n2009-09-01\n49.47\n54.15\n56.38\n23.54\n119.61\n19.57\n31.63\n25.72\n27.01\n68.61\n\n\n2009-10-01\n50.57\n47.80\n56.85\n22.81\n120.61\n19.11\n30.93\n27.73\n25.67\n71.67\n\n\n2009-11-02\n54.49\n52.41\n59.91\n23.40\n126.35\n19.20\n36.21\n29.41\n26.94\n75.07\n\n\n2009-12-01\n54.48\n53.72\n60.73\n23.92\n127.94\n19.66\n36.88\n30.01\n27.18\n76.04\n\n\n\n\n\n\n\nAuf Basis von stetigen (log) Renditen werden die historischen Mittelwerte und die Varianz-Kovarianzmatrix der Renditen berechnet und jeweils annualisiert.\n\n\nCode\n# using log returns\nlog_returns = np.log1p(frame.pct_change().dropna()) \nmeans = log_returns.mean().values*12 # annualised\nSigma = log_returns.cov().values*12 # annualised\n\n\n\n\n5.5.2 James-Stein Schätzer\nDie Berechnung des Grand-Mean \\(Y_0\\), des Schrumpfungsfaktors \\(\\hat{w}\\), und der James-Stein geschätzten erwarteten Renditen \\(\\hat{\\mu}_{JS}\\) erfolgt nun anhand der oben präsentierten Formeln (1), (3) und (4).\n\n\nCode\n# overall average return = return prior for James-Stein\ngrand_mean=np.mean(means)\n\n# James-Stein shrinkage factor\nphi_js = np.min([1,(len(means)-2)/(len(log_returns)*(np.matrix(means-grand_mean)*\\\n        la.inv(Sigma)*np.matrix(means-grand_mean).T)[0,0])])\n\n# James-Stein expected returns\njs_means = (1-phi_js)*means + phi_js*grand_mean\n\n\n\n\nCode\nphi_js\n\n\n0.4475110828261736\n\n\nAus der vorliegenden Datengrundlage ergab sich entsprechend Formel (4) ein Schrumpfungsfaktor in Höhe von \\(\\hat{w}=0,44\\). Auf Basis des ermittelten Schrumpfungsfaktors konnten anschließend die erwarteten Renditen der einzelnen Wertpapiere mit Hilfe des James-Stein Schätzers bestimmt werden. Ein Vergleich mit den herkömmlich geschätzten erwarteten Renditen ergibt:\n\n\nCode\npd.DataFrame({'JS-Means (%)': np.round(js_means, 4)*100,\\\n              'Hist. Means (%)': np.round(means,4)*100,\\\n             'Abs. Difference (%)': np.round(js_means-means, 4)*100},\\\n             index=frame.columns)\n\n\n\n\n\n\n\n\n\nJS-Means (%)\nHist. Means (%)\nAbs. Difference (%)\n\n\n\n\nABT\n2.99\n3.10\n-0.12\n\n\nBA\n1.68\n0.74\n0.94\n\n\nCOST\n3.78\n4.53\n-0.76\n\n\nCSCO\n3.63\n4.27\n-0.64\n\n\nIBM\n4.15\n5.21\n-1.06\n\n\nINTC\n-0.65\n-3.47\n2.83\n\n\nMRK\n2.79\n2.75\n0.04\n\n\nMSFT\n2.55\n2.32\n0.23\n\n\nT\n1.86\n1.07\n0.79\n\n\nXOM\n5.63\n7.89\n-2.26\n\n\n\n\n\n\n\nOder in Form eines Balkendiagramms visualisiert:\n\n\nCode\npd.DataFrame({'JS-Means': js_means, 'Hist. Means': means},index=frame.columns). \\\nplot.bar(stacked=False, alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\nEs zeigt sich, dass zwischen der herkömmlichen Schätzung der erwarteten Renditen und der Prognosen mit Hilfe des James-Stein Schätzers nur geringfügige Unterschiede bestehen. Zieht man jedoch in Betracht, dass die klassische Portfoliooptimierung bereits auf geringe Abweichungen in den erwarteten Renditen sehr sensitiv reagiert, sollte der Einfluss des James-Stein Schätzers im Kontext der Portfoliooptimierung nicht unterschätzt werden.\n\n\n5.5.3 Bayes-Stein Schätzer\nZunächst wird der adjustierte Schätzer \\(\\hat{\\Sigma}\\) der Varianz-Kovarianzmatrix nach Zellner und Chetty (1965) berechnet. Der Adjustierungsfaktor lautet: \\(\\frac{k-1}{k-N-2}\\) (siehe Formel (9) oben).\n\n\nCode\nadj_Sigma = ((len(log_returns)-1)/(len(log_returns)-len(means)-2))*Sigma\n\n\nMit der Budgetrestriktion als einzige Nebenbedingung ergeben sich die Gewichte des MVP gemäß: \\[ (5) \\quad w_{MVP}=\\frac{\\iota^T\\Sigma^{-1}}{\\iota^T\\Sigma^{-1}\\iota}. \\]\n\n\nCode\niota = np.ones(Sigma.shape[0]) # identity vector of dimension 10\ninv_adj_Sigma = la.inv(adj_Sigma)\nWeight_GMV = inv_adj_Sigma @ iota / (iota @ inv_adj_Sigma @ iota)\npd.DataFrame([round(x,4) for x in Weight_GMV],index=frame.columns).T\n\n\n\n\n\n\n\n\n\nABT\nBA\nCOST\nCSCO\nIBM\nINTC\nMRK\nMSFT\nT\nXOM\n\n\n\n\n0\n0.4359\n-0.0418\n0.2083\n-0.0125\n0.141\n0.0902\n-0.1451\n-0.0239\n0.0445\n0.3035\n\n\n\n\n\n\n\nFür die erwartete Rendite des MVP gilt nach Gleichung (6): \\(\\hat{\\mu}_{MVP}=w_{MVP}Y\\).\n\n\nCode\n# expected return of MVP (= return prior for James-Stein)\neret_GMV = (np.matrix(Weight_GMV)* np.matrix(means).T)[0,0]\neret_GMV\n\n\n0.0462098479530484\n\n\nBerechnung des BS-Schrumpfungsfaktors gemäß Gleichung (8):\n\\[ (8) \\quad \\hat{w}=\\frac{N+2}{(N+2)+k(Y-\\hat{\\mu}_{MVP}\\iota)^T\\Sigma^{-1}(Y-\\hat{\\mu}_{MVP}\\iota)}. \\]\n\n\nCode\n# calculation of Bayes-Stein shrinkage factor phi_bs:\nphi_bs = (len(means)+2)/((len(means)+2) + len(log_returns)*(np.matrix(means-eret_GMV)\\\n        * inv_adj_Sigma * np.matrix(means-eret_GMV).T)[0,0])\nphi_bs\n\n\n0.4777796219708953\n\n\nEs resultiert ein Schrumpfungsfaktor in Höhe von \\(\\hat{w}=0,48\\). Nun läßt sich der Bayes-Stein Schätzer der erwarteten Renditen berechnen:\n\\[ \\quad \\hat{\\mu}_{BS}=(1-\\hat{w})Y+\\hat{w}\\hat{\\mu}_{MVP}\\iota . \\]\n\n\nCode\n# Bayes-Stein expected returns\nbs_means = (1-phi_bs)*means + phi_bs*eret_GMV\n\n\nEin Vergleich der drei Schätzer (JS, BS, Historisch) für \\(\\mu\\) in Tabellenform:\n\n\nCode\npd.DataFrame({'JS-Means': np.round(js_means,4),\\\n              'BS-Means': np.round(bs_means,4),\\\n              'Hist. Means': np.round(means,4)},\\\n             index=frame.columns)\n\n\n\n\n\n\n\n\n\nJS-Means\nBS-Means\nHist. Means\n\n\n\n\nABT\n0.0299\n0.0383\n0.0310\n\n\nBA\n0.0168\n0.0259\n0.0074\n\n\nCOST\n0.0378\n0.0458\n0.0453\n\n\nCSCO\n0.0363\n0.0444\n0.0427\n\n\nIBM\n0.0415\n0.0493\n0.0521\n\n\nINTC\n-0.0065\n0.0039\n-0.0347\n\n\nMRK\n0.0279\n0.0364\n0.0275\n\n\nMSFT\n0.0255\n0.0342\n0.0232\n\n\nT\n0.0186\n0.0276\n0.0107\n\n\nXOM\n0.0563\n0.0633\n0.0789\n\n\n\n\n\n\n\noder als Balkendiagramm:\n\n\nCode\npd.DataFrame({'BS-Means': bs_means, 'JS-Means': js_means, 'Hist. Means': means},index=frame.columns). \\\nplot.bar(stacked=False, alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\n\n\n5.5.4 Ledoit-Wolf Schätzer der Varianz-Kovarianzmatrix\nÜber log_returns.corr().values wird die empirische Korrelationsmatrix \\(C\\) auf Basis stetiger Renditen berechnet und in das Array corr überführt. Die durchschnittliche Korrelation \\(\\hat{\\rho}\\) wird mit mean(corr[corr!=1]) ermittelt, wobei die Diagonalelemente \\(\\hat{\\rho}_{ii}\\) von \\(C\\) durch die Bedingung corr!=1 ausgeschlossen werden.\n\n\nCode\ncorr = log_returns.corr().values\nSigma = log_returns.cov().values*12\n\n# average of pairwise correlation (without diagonal elements)\navg_corr = np.mean(corr[corr!=1])\n\n\nKonstruktion der Korrelationsmatrix \\(C_{cc}\\) mit konstanter Korrelation\nnp.eye(len(corr)) erzeugt eine Diagonalmatrix der Dimension \\(NxN\\) mit nullen off-diagonal und einsen auf der Hauptdiagonalen und np.ones((len(corr), len(corr))) eine “Einser”-Matrix der Dimension \\(NxN\\). Werden beide Matrizen mit (1-avg_corr) bzw. avg_corr multipliziert und dann addiert, resultiert \\(C_{cc}\\).\n\n\nCode\n# generating a corr matrix with constant correlations as off diagonal\nconstant_corr = \\\n(1-avg_corr)*np.eye(len(corr)) + avg_corr*np.ones((len(corr), len(corr)))\n\n\nKonstruktion der Varianz-Kovarianzmatrix \\(\\hat{\\Sigma}_{cc}\\) unter Annahme konstanter Korrelation\nEs gilt: \\(\\hat{\\Sigma}_{cc}=\\Lambda C_{cc} \\Lambda^T\\).\nÜber np.sqrt(np.diagonal(Sigma)) werden die Diagonalelemente (Varianzen) der empirischen Varianz-Kovarianzmatrix \\(\\hat{\\Sigma}\\) extrahiert und in ein Array von Volatilitäten überführt. Dieses Array wird dann mit np.diag() in die Diagonalmatrix \\(\\Lambda\\) transformiert.\n\n\nCode\n# calculation of covariance matrix using a constant correlation assumption \n# the first part is diagonal matrix containing the volatilities p.a.\nconst_Sigma =\\\n(np.diag(np.sqrt(np.diagonal(Sigma))).dot(constant_corr)).dot(  \\\n np.diag(np.sqrt(np.diagonal(Sigma))))\n\n\nUnter Annahme eines Schrumpfungsfaktors in Höhe von \\(\\hat{w}=0,45\\), lässt sich nun gemäß Gleichung (10) der Ledoit-Wolf Schätzer der Varianz-Kovarianzmatrix ermitteln:\n\\[ (10) \\quad \\hat{\\Sigma}_{LW}=\\hat{w}\\hat{\\Sigma}_{cc}+(1-\\hat{w})\\hat{\\Sigma}.\\]\n\n\nCode\n# assuming a given shrinkage constant phi_lw\nphi_lw = 0.45\n\n# calculating the Ledoit-Wolf covariance matrix\nlw_Sigma = phi_lw * const_Sigma + (1-phi_lw)*Sigma\n\n\n\n\nCode\nlw_Sigma.shape\n\n\n(10, 10)\n\n\n\n\n5.5.5 Vergleich der Effizienzkurven und Portfolioallokationen\n\n5.5.5.1 Allgemeines\nNachdem die erwarteten Renditen (und die Varianz-Kovarianzmatrix) ermittelt wurden, können diese als Inputparameter in die Portfoliooptimierung einfließen. Im Folgenden betrachten wir den Fall mit Leerverkaufsverbot (implementiert über positive Bestandsgrenzen).\nZunächst definieren wir die Zielfunktionen der Optimierung (\\(\\sigma_P^2 \\rightarrow \\min_{w}!\\) bzw. für das MEP: \\(\\mu_P \\rightarrow \\max_{w}!\\)) und bestimmen die Gewichte des Minimum Varianz Portfolios (MVP) und des Maximum Ertrag Portfolios (MEP). Die Struktur des MVP ist unabhängig von der Schätzung des Vektors der erwarteten Renditen. Wird dann die Portfoliooptimierung für verschiedene Zielrenditen zwischen der erwarteten Rendite des MVP und der des MEP durchgeführt, ergibt sich die entsprechende Effizienzkurve.\n\n\nCode\n# definition of target function for MVP to be minimized\ndef calculate_portfolio_var(w,Sigma):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    return (w*Sigma*w.T)[0,0]\n\n# definition of target function for MEP to be maximized\ndef calculate_negative_portfolio_ret(w,means):\n    # function that calculates -1 times the portfolio expected return\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return -(w*means.T)[0,0]\n\ndef calculate_portfolio_ret(w,means):\n    # function that calculates portfolio expected return\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return (w*means.T)[0,0]\n\n\nGewichte des MVP und des MEP (unter Verwendung der historischen Varianz-Kovarianzmatrix Sigma, und Leerverkaufsverbot; naives Portfolio als Startgewichte).\n\n\nCode\n# use equal weights \"Weight_1N\" as starting values \nWeight_1N = np.tile(1.0/means.shape[0], means.shape[0])\n\n# positive weight portfolio\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\n# MVP\nres2= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MV2 = res2.x\n\n# MEP\nres4= minimize(calculate_negative_portfolio_ret, Weight_1N, args=means, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MRP = res4.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.012112846573987465\n            Iterations: 21\n            Function evaluations: 231\n            Gradient evaluations: 21\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -0.07886975933686077\n            Iterations: 11\n            Function evaluations: 121\n            Gradient evaluations: 11\n\n\n\n\n5.5.5.2 James-Stein versus historische Mittelwerte\nZunächst erfolgt die Bestimmung des Intervals der Zielrenditen, separat auf Basis der JS und der historisch geschätzten erwarteten Renditen.\n\n\nCode\n# calculation of min and max target return\n# min: expected return of MVP, max: expected return of MEP\n\n# for historic means\nmin = calculate_portfolio_ret(Weight_MV2, means)\nmax = calculate_portfolio_ret(Weight_MRP, means)\n\n# for JS means\nmin_js = calculate_portfolio_ret(Weight_MV2, js_means)\nmax_js = calculate_portfolio_ret(Weight_MRP, js_means)\n\n\nBerechnung der Effizienzkurven. Zunächst für die historischen Mittelwerte:\n\n\nCode\n# efficient frontier with hist. mean returns\nV_Target = np.linspace(min, max, num=45)\nV_Risk = np.zeros(V_Target.shape)\nV_Return = np.zeros(V_Target.shape)\nV_Weight = np.zeros((V_Target.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight[idx, :] = res.x.T\n    V_Return[idx] = calculate_portfolio_ret(res.x,means)\n    V_Risk[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\nUnd nun für die JS erwarteten Renditen:\n\n\nCode\n# efficient frontier with JS mean returns\nV_Target_js = np.linspace(min_js, max_js, num=45)\nV_Risk_js = np.zeros(V_Target.shape)\nV_Return_js = np.zeros(V_Target.shape)\nV_Weight_js = np.zeros((V_Target.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target_js):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,js_means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight_js[idx, :] = res.x.T\n    V_Return_js[idx] = calculate_portfolio_ret(res.x,js_means)\n    V_Risk_js[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\nGraphische Darstellung der Effizienzkurven:\n\n\nCode\nfig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig1.add_subplot(111)\nplt.plot(V_Risk, V_Target, 'g:', label='Hist.-efficient frontier without short selling')\nplt.plot(V_Risk_js, V_Target_js, 'g-', label='JS-efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nfor i, txt in enumerate(frame.columns):\n   ax.annotate(txt, (np.sqrt(np.diagonal(Sigma))[i],means[i]))\nplt.legend(loc=3,  frameon=True)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return')\nplt.title('Comparing efficient frontiers')\nplt.show()\n\n\n\n\n\n\n\n\n\nEs wird deutlich, dass die Effizienzkurve auf Basis der James-Stein erwarteten Renditen deutlich unter der herkömmlichen Effizienzkurve liegt, obwohl die absoluten Abweichungen der dargestellten Schätzverfahren nur geringfügig waren.\nWerden jedoch die einzelnen Portfoliogewichte entlang der gesamten Effizienzkurve gemeinsam in einem Flächendiagramm dargestellt, erscheint auf den ersten Blick auffällig, dass die Portfoliogewichte beim Vergleich offensichtlich nur minimal abweichen. Bei genauerer Betrachtung stellt man jedoch fest, dass sich die Portfoliogewichte auf der horizontalen Achse verschoben haben. Man erkennt auch, dass sich die Zuordnung der erwarteten Renditen entsprechend verändert hat.\nPortfoliogewichte auf Grundlage historisch geschätzter erwarteter Renditen:\n\n\nCode\nfig2 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target, V_Weight.T*100)\nplt.axis([min, max, 0.0, 100.0])\nplt.legend(list(frame.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return (%)')\nplt.ylabel('Allocation weight (%)')\nplt.title('Portfolioweights based on historic mean returns')\nplt.show()\n\n\n\n\n\n\n\n\n\nPortfoliogewichte auf Grundlage des JS Schätzers der erwarteten Renditen:\n\n\nCode\nfig3 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target_js, V_Weight_js.T*100)\nplt.axis([min_js, max_js, 0.0, 100.0])\nplt.legend(list(frame.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return') \nplt.title('Portfolioweights based on JS mean return estimates')\nplt.ylabel('Allocation weight (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n5.5.5.3 Bayes-Stein versus historische Mittelwerte\nBestimmung des Intervals der Zielrenditen für die Effizienzkurve auf Basis des BS Schätzers der erwarteten Renditen.\n\n\nCode\n# calculation of min and max target return\n# min: expected return of MVP, max: expected return of MEP\n\nmin_bs = calculate_portfolio_ret(Weight_MV2, bs_means)\nmax_bs = calculate_portfolio_ret(Weight_MRP, bs_means)\n\n\nBerechnung der Effizienzkurve:\n\n\nCode\nV_Target_bs = np.linspace(min_bs, max_bs, num=45)\nV_Risk_bs = np.zeros(V_Target.shape)\nV_Return_bs = np.zeros(V_Target.shape)\nV_Weight_bs = np.zeros((V_Target.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target_bs):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,bs_means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight_bs[idx, :] = res.x.T\n    V_Return_bs[idx] = calculate_portfolio_ret(res.x,bs_means)\n    V_Risk_bs[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\nGraphische Darstellung:\n\n\nCode\nfig4 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig4.add_subplot(111)\nplt.plot(V_Risk, V_Target, 'g:', label='Hist.-efficient frontier without short selling')\nplt.plot(V_Risk_bs, V_Target_bs, 'g--', label='BS-efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nfor i, txt in enumerate(frame.columns):\n   ax.annotate(txt, (np.sqrt(np.diagonal(Sigma))[i],means[i]))\nplt.legend(loc=3,  frameon=True)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return')\nplt.title('Comparing efficient frontiers')\nplt.show();\n\n\n\n\n\n\n\n\n\nEs wird deutlich, dass die Effizienzkurve des Bayes-Stein Schätzers unter der herkömmlichen Effizienzkurve liegt. Werden jedoch die einzelnen Portfoliogewichte entlang der gesamten Effizienzkurve gemeinsam in einem Flächendiagramm dargestellt, erscheint es ähnlich den Ergebnissen des James-Stein Schätzers auf den ersten Blick eher auffällig, dass die Portfoliogewichte beim Vergleich offensichtlich nur geringfügig abweichen. Bei genauerer Betrachtung stellt man jedoch fest, dass sich die Portfoliogewichte tatsächlich auf der horizontalen Achse verschoben haben. In diesem Zusammenhang hat sich auch die Zuordnung der erwarteten Renditen verändert.\nPortfoliogewichte auf Grundlage des BS Schätzers der erwarteten Renditen:\n\n\nCode\nfig5 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target_bs, V_Weight_bs.T*100)\nplt.axis([min_bs, max_bs, 0.0, 100.0])\nplt.legend(list(frame.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return') \nplt.title('Portfolioweights based on BS mean return estimates')\nplt.ylabel('Allocation weight (%)')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n5.5.5.4 Ledoit-Wolf versus historisch geschätzte Varianz-Kovarianzmatrix\nBerechnung der Gewichte des Minimum Varianz Portfolios auf Basis der Ledoit-Wolf Schätzung der Varianz-Kovarianzmatrix.\n\n\nCode\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\nres2= minimize(calculate_portfolio_var, Weight_1N, args=lw_Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MV2_lw = res2.x\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.014806352991309255\n            Iterations: 22\n            Function evaluations: 242\n            Gradient evaluations: 22\n\n\nErmittlung des Intervalls der Zielrenditen (unter Verwendung der historischen Mittelwerte als Schätzer für \\(\\mu\\)).\n\n\nCode\n# calculation of min and max target return\n# min: expected return of MVP, max: expected return of MRP\n\nmin_lw = calculate_portfolio_ret(Weight_MV2_lw, means)\nmax_lw = calculate_portfolio_ret(Weight_MRP, means) # no change here!\n\n\nBerechnung der Effizienzkurve.\n\n\nCode\nV_Target_lw = np.linspace(min_lw, max_lw, num=45)\nV_Risk_lw = np.zeros(V_Target.shape)\nV_Return_lw = np.zeros(V_Target.shape)\nV_Weight_lw = np.zeros((V_Target.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target_lw):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=lw_Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight_lw[idx, :] = res.x.T\n    V_Return_lw[idx] = calculate_portfolio_ret(res.x,means)\n    V_Risk_lw[idx] = np.sqrt(calculate_portfolio_var(res.x, lw_Sigma))\n\n\nGraphische Darstellung der Effizienzkurve auf Basis der Ledoit-Wolf Varianz-Kovarianzmatrix und der historisch geschätzten.\n\n\nCode\nfig6 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig6.add_subplot(111)\nplt.plot(V_Risk, V_Target, 'g:', label='Hist.-efficient frontier without short selling')\nplt.plot(V_Risk_lw, V_Target_lw, 'g-', label='LW-efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nfor i, txt in enumerate(frame.columns):\n   ax.annotate(txt, (np.sqrt(np.diagonal(Sigma))[i],means[i]))\nplt.legend(loc='best',  frameon=True)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return')\nplt.title('Comparison of efficient frontiers')\nplt.show()\n\n\n\n\n\n\n\n\n\nPortfoliogewichte auf Grundlage des Ledoit-Wolf Schätzers der erwarteten Varianz-Kovarianzmatrix:\n\n\nCode\nfig7 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target_lw, V_Weight_lw.T*100)\nplt.axis([min_lw, max_lw, 0.0, 100.0])\nplt.legend(list(frame.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return') \nplt.title('Portfolioweights based on LW covariance estimates')\nplt.ylabel('Allocation weight (%)')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#lernvideos",
    "href": "kapitel4a.html#lernvideos",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.6 Lernvideos",
    "text": "5.6 Lernvideos\n\n5.6.1 Video Teil 1\n\n\n\n5.6.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel4a.html#literatur",
    "href": "kapitel4a.html#literatur",
    "title": "5  Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer",
    "section": "5.7 Literatur",
    "text": "5.7 Literatur\nFranzen, D., Schäfer, K. (2018). Assetmanagement. Schäffer-Poeschel, Stuttgart.\nJames, W., Stein, C. (1961). Estimation with quadratic loss. In Proceedings of the fourth Berkeley symposium on mathematical statistics and probability.\nJorion, P. (1985). International portfolio diversification with estimation risk. Journal of Business 58, S. 259-278.\nJorion, P. (1986). Bayes-Stein estimation for portfolio analysis. Journal of Financial and Quantitative Analysis 21, S. 279-292.\nLedoit, O., Wolf, M. (2003). Improved estimation of the covariance matrix of stock returns with an application to portfolio selection. Journal of Empirical Finance 10, S. 603-621.\nSharpe, W. (1963). A simplified model for portfolio analysis. Management Science 9, S. 277-293.\nZellner, A., Chetty, V. K. (1965). Prediction and decision problems in regression models from the Bayesian point of view. Journal of the American Statistical Association 60, S. 608-616.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Verbesserte Schätzung der Inputparameter: Geschrumpfte Schätzer</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html",
    "href": "kapitel5a.html",
    "title": "6  Das Black-Litterman Modell",
    "section": "",
    "text": "6.1 Defizite der Portfoliooptimierung nach Markowitz\nDie im Kapitel 2 “Absolute Portfoliooptimierung” dargestellte Portfolio-Selection-Theorie von Markowitz stellt eine quantitativ generell anerkannte Methode dar, um den Trade-off zwischen den zwei Grundzielen der Renditemaximierung und der Risikominimierung bei Investitionen zu erklären. Dieser Ansatz bildet nach wie vor das akademische Grundgerüst der Portfoliotheorie. In der Praxis konnte sich der Markowitz’sche Ansatz aufgrund diverser schwerwiegender Probleme allerdings nur eingeschränkt durchsetzen. Die vier Hauptprobleme bei der Anwendung des klassischen Ansatzes sind (vgl. Drobetz, 2002, S. 4 ff.):\nHäufig beinhalten optimierte Portfolios sowohl auf der Long-Seite als auch auf der Short-Seite extreme Portfoliogewichte. Diese Gewichte könnten in der Praxis bereits aus institutionellen und rechtlichen Gründen nicht umgesetzt werden. Die Mittelwert-Varianz-Optimierung tendiert auch bei Portfolios mit Restriktionen, wie zum Beispiel der Ausschluss von Leerverkäufen, zu extremen Portfoliogewichten.\nEin weiteres Problem stellt die starke Sensitivität der Portfoliogewichte gegenüber Veränderungen der Inputfaktoren dar. Besonders Veränderungen der erwarteten Renditen führen zu unrealistisch großen Umschichtungen im Portfolio. Dies verursacht zum einen hohe Transaktionskosten, zum anderen steht eine zu hohe Umschichtungsfrequenz für inkonsistentes Portfolio-Management und ist nach außen nur schwer kommunizierbar.\nDer Markowitz’sche Ansatz erfordert die Spezifikation der Renditeerwartungen sämtlicher Wertpapiere sowie die dazugehörige Varianz-Kovarianz-Matrix. Die Schwierigkeit, qualitativ gute Renditeprognosen zu erstellen, und die Tatsache, dass Portfoliomanager in der Regel nur in ausgewählten Wertpapierklassen über verlässliche Renditeerwartungen verfügen, stellt die Portfoliomanager bei der Zusammenstellung der Eingabematrizen für die Mittelwert-Varianz-Optimierung vor eine große Herausforderung.\nPortfoliomanager haben durch den Einsatz verschiedener Analyseinstrumente bezüglich ihrer Prognosen häufig verschiedene Konfidenzen. Derartige Unterschiede in der Güte der Prognosen können in dem Markowitz-Formalismus nicht berücksichtigt werden.\nDiese Probleme, die durch den praktischen Einsatz der klassischen Portfoliotheorie aufkommen, führen dazu, dass das Modell in der Praxis nur bedingt umgesetzt weren kann. Der Versuch, das Modell durch verschiedene Restriktionen realistischer zu machen, ist oft mit einem unverhältnismäßigen Aufwand verbunden. Für Black und Litterman war dies der Anstoß, ein Portfolio-Management Modell zu entwickeln, das die oben angesprochenen Defizite des klassischen Ansatzes besser löst.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#defizite-der-portfoliooptimierung-nach-markowitz",
    "href": "kapitel5a.html#defizite-der-portfoliooptimierung-nach-markowitz",
    "title": "6  Das Black-Litterman Modell",
    "section": "",
    "text": "Extreme Portfolioallokationen\n\n\n\nSensitivität der Portfoliogewichte\n\n\n\nInformationsaggregation\n\n\n\nKeine Möglichkeit, Aussagen über die Prognosegüte zu treffen",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#der-ansatz-des-black-litterman-verfahrens",
    "href": "kapitel5a.html#der-ansatz-des-black-litterman-verfahrens",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.2 Der Ansatz des Black-Litterman Verfahrens",
    "text": "6.2 Der Ansatz des Black-Litterman Verfahrens\nIn diesem Abschnitt wird die grundsätzliche Vorgehensweise des Black-Litterman Verfahrens beschrieben, in den folgenden Abschnitten kann dann die Vorgehensweise formalisiert werden. Die Ausführungen hier beziehen sich auf die Originalquelle Black und Litterman (1992). Eine sehr anschauliche Darstellung der praktischen Umsetzung des Verfahrens findet sich bei Idzorek (2004).\nDas Black-Litterman Verfahren orientiert sich ständig an einem vom Portfoliomanager a-priori vorgegebenen Referenzportfolio. Dieses Portfolio soll dem langfristigen Anlageverhalten des Investors entsprechen. Hat der Portfoliomanager keine eigenen Erwartungen bezüglich der künftigen Renditeentwicklung von Wertpapieren in seinem Portfolio, stimmt er indirekt den impliziten Renditeerwartungen (abgeleitet aus den Referenzportfoliogewichten) zu. Dies führt dazu, dass die Gewichtungen der Wertpapiere in seinem Portfolio denen des Referenzportfolios entsprechen. Das Black-Litterman Verfahren erlaubt, eine beliebige Anzahl von Renditeprognosen unter Berücksichtigung der Prognosequalität in die Portfoliooptimierung zu integrieren. Es können sowohl absolute Prognosen über erwartete Renditeniveaus von einem Wertpapier als auch relative Prognosen über stärker und schwächer performende Wertpapiere in das Verfahren integriert werden.\nDas Ergebnis des Prozesses ist ein revidierter Renditevektor, der von dem Vektor der impliziten Renditen in Richtung der subjektiven Renditeerwartungen abweicht. Dieser revidierte Renditevektor kann schließlich einer Mittelwert-Varianz-Optimierungsroutine überführt werden. Als Ergebnis des Black-Litterman Verfahrens erhält man intuitive Veränderungen in den Portfoliogewichten, die konsistent mit den subjektiven Prognosen sind, und deshalb in der Praxis leichter umgesetzt werden können.\nFestzuhalten bleibt, dass es sich bei dem Black-Litterman Ansatz nicht um eine alternative Optimierungstechnik handelt. Das Black-Litterman Verfahren ist eine Methode, um ausgehend von einem neutralen Referenzportfolio die Renditeprognosen den eigenen Renditeerwartungen in einer sehr flexiblen Art anzupassen.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#referenzportfolios-und-implizite-renditen-als-ausgangspunkt-des-black-litterman-verfahrens",
    "href": "kapitel5a.html#referenzportfolios-und-implizite-renditen-als-ausgangspunkt-des-black-litterman-verfahrens",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.3 Referenzportfolios und implizite Renditen als Ausgangspunkt des Black-Litterman Verfahrens",
    "text": "6.3 Referenzportfolios und implizite Renditen als Ausgangspunkt des Black-Litterman Verfahrens\nDer innovative Ansatz des Black-Litterman Verfahrens (1992) hat die Zielsetzung, die oben aufgeführten Schwächen der Portfoliooptimierung nach Markowitz zu verhindern, und somit ein Modell zu schaffen, das für den Einsatz in der Praxis besser geeignet ist. Die wichtigste Eigenschaft des Black-Litterman Modells ist die Möglichkeit, implizite Renditen, welche im Folgenden erklärt werden, mit subjektiven Erwartungen über Kursentwicklungen von Wertpapieren im Portfolio konsistent zu verbinden.\nDie impliziten Renditen, welche den Ausgangspunkt des Black-Litterman Verfahrens bilden, werden durch eine Umkehroptimierung abgeleitet. Im ersten Schritt muss der Portfoliomanager die mittel- bis langfristigen Portfoliogewichte der Wertpapiere seines Portfolios festlegen. Diese Referenzgewichte können den Gleichgewichtsgewichten (auf Basis der relativen Marktkapitalisierung), wie sie dem CAPM-Modell zugrunde liegen, entsprechen oder aber auch Gegenstand strategischer Überlegungen des Portfoliomanagers sein. Black und Litterman (1991, S.3) schlagen vor, die aus den Marktkapitalisierungen resultierenden impliziten Gleichgewichtsrenditen als Ausgangspunkt für das Black-Litterman Verfahren zu verwenden:\n“Our model does not assume that the world is always at the CAPM equilibrium, but rather that when expected returns move away from their equilibrium values, imbalances in markets will tend to push them back. Thus, we think it is reasonable to assume that expected returns are not likely to deviate too far from equilibrium values. This intuitive idea suggests that the investor may profit by combining his views about returns in different markets with the information contained in the equilibrium.”\nEin nutzenmaximierender Portfoliomanager mit einer Nutzenfunktion \\(U(w)=\\mu_P-\\frac{\\lambda}{2} \\sigma^2_P\\) erhöht in dem Markowitz-Verfahren seinen Nutzen durch die optimale Aufteilung seines Budgets auf die Wertpapiere im Portfolio, bei gegebenem Vektor der erwarteten Renditen \\(\\mu\\) und bei gegebener Varianz-Kovarianz-Matrix \\(\\Sigma\\) der Renditen. Ohne Restriktionen hat die Maximierungsaufgabe folgende Form:\n\\[ (1) \\quad U(w) =w^{T}\\mu-\\frac{\\lambda}{2}w^{T}\\Sigma w \\rightarrow \\max_{w}! \\]\nmit der Lösung\n\\[ (2) \\quad w^*=(\\lambda \\Sigma)^{-1}\\mu . \\]\nIm Black-Litterman Verfahren ist aber vorerst \\(w^*\\) schon bekannt, sei es durch das CAPM-Gleichgewicht (d.h., die marktkapitalisierungsgerechten Gewichte) oder die strategisch festgelegten Gewichte. Die Umkehroptimierung legt die benötigten erwarteten Renditen fest, um in dem Markowitz-Verfahren genau die Referenzgewichte \\(w_{REF}\\) zu erhalten. Diese Renditen werden im Folgenden als implizite Renditen \\(\\Pi\\), oder, im Fall des Marktportfolios als Referenzportfolio, als Gleichgewichtsrenditen bezeichnet. Die Umkehroptimierung stellt eine Umformung der Formel (2) dar, und lässt sich folgendermaßen darstellen:\n\\[ (3) \\quad \\Pi=\\lambda \\Sigma w_{REF} . \\]\nUm die Unsicherheit bezüglich der zukünftigen Erwartungswerte der Renditen \\(\\mu\\) explizit zu berücksichtigen, werden diese als stochastische Größen angesehen. Unter der Annahme, dass Erwartungswerte eine geringere Varianz als die zugrunde liegenden Zufallsvariablen selbst haben, lässt sich die a-priori Verteilung von \\(\\mu\\) im Black-Litterman Modell schreiben als\n\\[ (4) \\quad \\mu_{a-priori} \\sim N(\\Pi, \\tau \\Sigma) , \\]\nwobei \\(N(.)\\) die Normalverteilungsfunktion bezeichnet. Die Dimensionen sind dabei wie folgt: \\(\\mu\\) und \\(\\Pi\\) sind \\(N×1\\) Vektoren und die Varianz-Kovarianz-Matrix \\(\\Sigma\\) ist eine \\(N×N\\) Matrix, wobei \\(N\\) die Anzahl der Wertpapiere ist. Der Parameter \\(\\tau\\) misst den Proportionalitätsfaktor der historischen Renditevolatilität zur Volatilität der erwarteten Rendite. Je größer das Vertrauen des Portfoliomanagers in das eigene Referenzportfolio ist, umso kleiner sollte der Parameter \\(\\tau\\) gewählt werden. Die impliziten (oder Gleichgewichts-) Renditen \\(\\Pi\\) stellen somit den a-priori Schätzer für die erwarteten Renditen \\(\\mu\\) dar. Für \\(\\tau=0\\) würde unterstellt, dass es keine Unsicherheit bezüglich der Erwartungswerte der zukünftigen Renditen gäbe und das diese den historischen Werten entsprächen.\nIm nächsten Schritt muss die a-priori Verteilung von \\(\\mu\\) mit den individuellen Renditeprognosen des Portfoliomanagers kombiniert werden um die a-posteriori Verteilung zu erhalten.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#die-verbindung-des-referenzportfolios-mit-renditeprognosen",
    "href": "kapitel5a.html#die-verbindung-des-referenzportfolios-mit-renditeprognosen",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.4 Die Verbindung des Referenzportfolios mit Renditeprognosen",
    "text": "6.4 Die Verbindung des Referenzportfolios mit Renditeprognosen\n\n6.4.1 Spezifikation von Renditeprognosen im Black-Litterman Modell\nDer entscheidende Schritt bei der Formalisierung des Black-Litterman Verfahrens ist die Spezifikation der subjektiven Renditeerwartungen (Prognosen, Meinungen oder “Views”). Dies erfolgt ebenfalls in Form einer Wahrscheinlichkeitsverteilung.\nIn der Regel werden Portfoliomanager Erwartungen über die Renditeentwicklung einiger Werte in ihrem Portfolio haben, die von den impliziten Renditen abweichen. Das Black-Litterman Modell ermöglicht es, sowohl absolute als auch relative Renditeprognosen in den Prozess der Asset Allocation einzubeziehen. Es ist nicht zwingend, dass für jedes Wertpapier in dem Portfolio eine Renditeerwartung spezifiziert wird.\nDie folgenden Beispiele verdeutlichen, wie absolute (A) und relative (B und C) Renditeerwartungen in dem Black-Litterman Modell ausgedrückt werden können.\n\n\n„Wertpapier A wird eine Rendite von 6 % erwirtschaften (ca. 1,5 % unter der impliziten Rendite).“\n\n\n„Wertpapier E wird eine um 5 % höhere Rendite erwirtschaften als Wertpapier C.“\n\n\n„Die Wertpapiere B und D werden die Wertpapiere A und C um 10 % outperformen.“\n\n\nNachdem der Investor sämtliche von den impliziten Renditen abweichende Erwartungen in Form der obigen Beispiele verbal festgelegt hat, müssen diese Erwartungen in eine Form umgewandelt werden, die es ermöglicht, sie in den Black-Litterman Prozess zu integrieren.\nIn dem Modell wird angenommen, dass die Erwartungen bzw. Prognosen des Portfomanagers gemäß der folgenden Formel als \\(k\\) unterschiedliche Linearkombinationen der \\(N\\) Wertpapiere ausgedrückt werden können. \\(k\\) stellt die Anzahl der formulierten Prognosen dar.\n\\[ (5) \\quad P \\cdot \\mu = V + \\epsilon . \\]\nDer Vektor der Renditeprognosen \\(V\\) hat die Dimension \\(k×1\\). Als \\(k×1\\) Vektor mit den Prognosefehlern wird \\(\\epsilon\\) verwendet. Die ermittelten Renditeprognosen (Meinungen oder “Views”) \\(V\\) werden durch die Matrix \\(P\\) den jeweils richtigen Wertpapieren zugewiesen. Jede einzelne Erwartung kann durch einen \\(1×N\\) Vektor (eine Zeile von \\(P\\)) den Wertpapieren eindeutig zugeordnet werden. Aus diesem Grund handelt es sich bei der Prognosematrix \\(P\\) allgemein um eine \\(k×N\\) Matrix. Jede Zeile von \\(P\\) stellt dabei ein sogenanntes “View Portfolio” dar. Das erste Element des Vektors \\(V\\) zeigt die Höhe der Renditeprognose an, das erste Element des Vektors \\(\\epsilon\\) den damit verbundenen Schätzfehler.\nDie Prognosen (Views) werden mit einem Schätzfehler versehen, da sie in der Praxis nicht mit Sicherheit geäußert werden können. Über den Vektor der Schätzfehler \\(\\epsilon\\) wird angenommen, er sei unabhängig und normal verteilt. Das Maß für die Prognosegüte ist in dem Black-Litterman Verfahren die Varianz-Kovarianz-Matrix der Prognosefehler, \\(\\Omega\\). Wegen der Annahme der Unabhängigkeit der Prognosen untereinander, reduziert sich die \\(k×k\\) Matrix \\(\\Omega\\) zu einer Diagonalmatrix, wobei die Varianzen der Schätzfehler \\(\\epsilon\\) entlang der Diagonalen eingetragen werden. Im Black-Litterman Modell gilt die Annahme der Normalverteilung der Prognosen gemäß\n\\[ (6) \\quad P \\cdot \\mu \\sim N(V, \\Omega) . \\]\nIn einem Sieben-Wertpapier-Beispiel mit den Wertpapieren \\({A,B,C,D,E,F,G}\\) würden die obigen Prognosen (A), (B) und (C) folgendermaßen formalisiert werden:\n\\[ (7) \\quad P  \\cdot \\left( \\begin{array}{rrrr}\n\\mu_A \\\\\n\\mu_B \\\\\n\\mu_C \\\\\n\\mu_D \\\\\n\\mu_E \\\\\n\\mu_F \\\\\n\\mu_G \\\\\n\\end{array}\\right) =\n\\left( \\begin{array}{rrrr}\n0,06 \\\\\n0,05 \\\\\n0,10 \\\\\n\\end{array}\\right) +\n\\left( \\begin{array}{rrrr}\n\\epsilon_{(A)} \\\\\n\\epsilon_{(B)} \\\\\n\\epsilon_{(C)} \\\\\n\\end{array}\\right)\n\\\n\\]\nmit\n\\[ (8) \\quad P=\\left( \\begin{array}{rrrr}\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & -1 & 0 & 1 & 0 & 0 \\\\\n-0,49 & 0,45 & -0,51 & 0,55 & 0 & 0 & 0 \\\\\n\\end{array}\\right) .\\]\nDie erste Reihe der Matrix \\(P\\) stellt die absolute Erwartung (A) dar. Da A das erste Wertpapier im Beispielportfolio ist, und sich die Erwartung ausschließlich auf dieses Wertpapier bezieht, muss der erste Wert der ersten Zeile eins betragen. Sämtliche anderen Elemente der ersten Reihe der Matrix \\(P\\) sind null.\nDie zweite Reihe der Matrix stellt die relative Erwartung (B) dar. Es wird ein gewichtungsneutrales Portfolio gebildet, indem die stärkere Aktie der Prognose die Longposition (Wert: 1), und die schwächere Aktie die Shortposition (Wert: –1) einnimmt. Die Höhe der Überperformance kommt in der zweiten Reihe des Vektors \\(V\\) zum Tragen (Wert: 0,05).\nDie dritte Reihe der Matrix \\(P\\) stellt den kompliziertesten Fall gleichzeitiger relativer Renditeerwartungen für mehr als zwei Wertpapiere dar, in dem Beispiel durch die Erwartung (C) dargestellt. Analog zu einer relativen Erwartung des Typs (B) müssen sich die Werte der Aktien mit der stärkeren erwarteten Performance zu eins addieren, die Werte der outperformten Wertpapiere müssen summiert minus eins ergeben. Die Aufteilung der auf eins bzw. minus eins begrenzten Werte zwischen den beiden Aktienklassen erfolgt proportional zu deren Marktkapitalisierung (hier willkürlich angenommen). Die Berechnung der Werte in der dritten Spalte der Matrix \\(P\\) erfolgte gemäß der Formel (9):\n\\[ (9) \\quad P^T_{3.} =  \\left( \\begin{array}{rrrr}\n\\frac{MCap_A}{MCAP_{A+C}} \\\\\n\\frac{MCap_B}{MCAP_{B+D}} \\\\\n\\frac{MCap_C}{MCAP_{A+C}} \\\\\n\\frac{MCap_D}{MCAP_{B+D}} \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{array}\\right) =\n\\left( \\begin{array}{rrrr}\n-0,49 \\\\\n0,45 \\\\\n-0,51 \\\\\n0,55 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{array}\\right) ,\n\\]\nmit \\[ MCap_i: \\text{Marktkapitalisierung des Wertpapiers i} . \\]\nIst dem Portfoliomanager der Grad an Unsicherheit bzw. die Varianz seiner Erwartungen ex ante nicht bekannt, so kann anstatt dieser die Varianz der Prognoseportfolios (View Portfolios) herangezogen werden:\n\\[ (10) \\quad \\Omega_{kk}=P_{k.} \\tau\\Sigma \\space P^T_{k.}.\\]\nDa in diesem Beispiel die Güte der Prognosen unbekannt ist, wird die Varianz-Kovarianzmatrix der Schätzfehler - \\(\\Omega\\) - gemäß Formel (10) approximiert. Es ergibt sich (mit \\(\\tau=1\\)):\n\\[ (11) \\quad \\Omega=\\left( \\begin{array}{rrrr}\n0.0065 & 0 & 0  \\\\\n0 & 0.0037 & 0  \\\\\n0 & 0 & 0.0016  \\\\\n\\end{array}\\right). \\]\n\n\n6.4.2 Die Black-Litterman Formel\nIm Black-Litterman Modell wird angenommen, dass die unbekannte a-posteriori Verteilung der erwarteten Renditen \\(\\mu\\) eine gemischte Verteilung ist, die auf der a-priori Verteilung unter Verwendung der impliziten (oder der Gleichgewichts-) Renditen \\(\\Pi\\) und der Verteilung der Renditeprognosen \\(V\\) basiert. Die a-priori Verteilung von \\(\\mu\\) ist in der Formel (4) spezifiziert, die Verteilung der Renditeprognosen wird in der Formel (6) dargestellt.\nDer optimale (a-posteriori) Schätzer für den Vektor der erwarteten Renditen entspricht dem Erwartungswert \\(E(\\mu_{a-posteriori})\\) der gemischten (a-posteriori) Verteilung der erwarteten Renditen. Dieser kann durch den folgenden Ausdruck berechnet werden:\n\\[ (12) \\quad E(\\mu_{a-posteriori})=[(\\tau\\cdot\\Sigma)^{-1}+P^T\\Omega^{-1}P]^{-1}[(\\tau\\cdot\\Sigma)^{-1}\\Pi+P^T\\Omega^{-1}V]. \\]\nDie a-posteriori Verteilung der erwarteten Renditen ist wiederum eine Normalverteilung. Sie ist in der folgenden Formel wiedergegeben:\n\\[ (13) \\quad \\mu_{a-posteriori} \\sim N(E(\\mu_{A-posteriori}), [(\\tau\\cdot\\Sigma)^{-1}+P^T\\Omega^{-1}P]^{-1}) . \\]\nDie Formel (12) bildet die Basis des gesamten Black-Litterman Verfahrens. Durch diese Formel werden die impliziten Renditen und die subjektiven Prognosen zu einem neuen, revidierten Vektor erwarteter Renditen zusammengefasst. Durch die Weitergabe dieses Vektors an eine Mittelwert-Varianz-Optimierungsroutine können schließlich die Black-Litterman Portfoliogewichte ermittelt werden.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#fazit",
    "href": "kapitel5a.html#fazit",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.5 Fazit",
    "text": "6.5 Fazit\nDer klassische portfoliotheoretische Ansatz von Markowitz ist theoretisch elegant und stellt in der akademischen Literatur das Gerüst der Portfoliotheorie dar. Es wurde allerdings anhand von Beispielen gezeigt (vgl. insbesondere Kapitel A3.1), dass der Ansatz in der Praxis zu erheblichen Problemen führen kann. Diese Defizite führen dazu, dass der traditionelle Ansatz von Portfoliomanagern kaum oder nur in stark veränderter Form eingesetzt wird.\nAus diesem Grund haben Black und Litterman 1992 ein innovatives Verfahren entwickelt, das Portfoliomanagern erlaubt, ausgehend von stabilen Gleichgewichtsrenditen oder impliziten Renditen, subjektive Renditeprognosen und ein Grad an Vertrauen in diese Prognosen im Asset-Allocation-Prozess zu berücksichtigen. Letztendlich handelt es sich bei dem Black-Litterman Modell um eine Methode, die einen komplexen gewichteten Durchschnitt der impliziten Renditen und der subjektiven Renditeprognosen festlegt.\nDie Portfoliogewichte werden durch den Einsatz des Black-Litterman Verfahrens viel realistischer, da Erwartungen der Portfoliomanager eindeutig widergespiegelt und stark konzentrierte Portfolios vermieden werden. Aus diesen Gründen konnte sich das Black-Litterman Modell seit der Publikation im Jahr 1992 in zahlreichen Finanzunternehmen als Portfolio-Management Modell durchsetzen.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#beginn-der-fallstudie",
    "href": "kapitel5a.html#beginn-der-fallstudie",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.6 Beginn der Fallstudie",
    "text": "6.6 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nimport numpy.linalg as la\n\n\n\n6.6.1 Laden und Beschreiben der Datenbasis\nDer verwendete Datensatz enthält Kurshistorien (Monatsanfangskurse) der folgenden zehn Aktien: Alcoa, IBM, Intel, J.P. Morgan, Microsoft, AT&T, Cisco, Ebay, Costco, Kraft Foods. Die Kurshistorien beziehen sich auf den Zeitraum 12.2004-12.2009 (61 Monate).\n\n\nCode\n# hier den Dateipfad eingeben\n# cd \"...\"\n\n\n\n\nCode\nframe1 = pd.read_excel('Kapitel A3_3.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe1.tail()\n\n\n\n\n\n\n\n\n\nAA\nIBM\nINTC\nJPM\nMSFT\nT\nCSCO\nEBAY\nCOST\nKFT\n\n\n\n\n2009-08-03\n12.05\n118.05\n20.32\n43.46\n24.65\n26.05\n21.60\n22.14\n50.98\n28.35\n\n\n2009-09-01\n13.12\n119.61\n19.57\n43.82\n25.72\n27.01\n23.54\n23.60\n56.38\n26.27\n\n\n2009-10-01\n12.42\n120.61\n19.11\n41.77\n27.73\n25.67\n22.81\n22.27\n56.85\n27.52\n\n\n2009-11-02\n12.52\n126.35\n19.20\n42.49\n29.41\n26.94\n23.40\n24.47\n59.91\n26.58\n\n\n2009-12-01\n16.30\n132.57\n20.59\n41.53\n30.96\n28.32\n24.18\n23.80\n60.05\n27.49\n\n\n\n\n\n\n\nAuf Basis von stetigen (log) Renditen werden die historischen Mittelwerte und die Varianz-Kovarianzmatrix der Renditen berechnet und jeweils annualisiert.\n\n\nCode\n# using log returns\nreturns = np.log1p(frame1.pct_change().dropna())\n\nmeans = returns.mean().values*12 # annualised\nSigma = returns.cov().values*12 # annualised\n\n\nDie Marktkapitalisierung der einzelnen Aktien wurde zum Stichtag 01.09.2012 ermittelt. Die relative Marktkapitalisierung der zehn Aktien ist im Array cap_weights gespeichert. Dieses stellt zugleich die Referenzgewichte \\(w_{REF}\\) dar.\n\n\nCode\n# current market cap of stocks and calculation of cap weights\nmarket_cap = pd.read_excel('Market Cap.xlsx', 'Tabelle1')\ncap_weights = np.asarray(market_cap)/np.sum(np.asarray(market_cap))\n\n\n\n\n6.6.2 Ermittlung der impliziten Renditen\nAusgehend vom Maximierungsproblem bei der Portfoliooptimierung nach Markowitz ohne Restriktionen ergeben sich die impliziten Renditen, die das Referenzportfolio zu einem effizienten Portfolio machen, durch die oben dargestellte Umkehroptimierung gemäß folgender Formel: \\(\\Pi=\\lambda\\Sigma w_{REF}\\). Für den Risikoaversionskoeffizienten \\(\\lambda\\) wird beispielhaft der Wert 2,0 gewählt.\n\n\nCode\n# calculation of market cap implied expected returns; lambda=gamma\ngamma = 2\nimplied = 2*(cap_weights.dot(Sigma))\n\n\nWie oben dargestellt, resultieren die Gewichte des Referenzportfolios als Ergebnis der Optimierung falls der Vektor der impliziten Renditen für \\(\\mu\\) eingesetzt wird.\n\\[ (2) \\quad w_{REF}=(\\lambda \\Sigma)^{-1}\\Pi. \\]\n\n\nCode\n# optimal weights implied by implied expected returns\n# analytical solution w = inv(gamma * Sigma1)* implied\n# analytical solution possible because of no constraints\n# Of course, impl_weights must equal cap_weights\nimpl_weights = implied.dot(la.inv(gamma * Sigma))\n\n# optimal Markowitz weights based on hist. returns\nmarko_weights = means.dot(la.inv(gamma * Sigma))\n\n\nEs muss also gelten: cap_weights=impl_weights. Wird \\(\\mu\\) auf Basis der einfachen historischen Mittelwerte (means) geschätzt, resultieren die klassischen Markowitz-Gewichte (marko_weights).\nVergleichen wir nun die historischen Mittelwerte mit den implizit erwarteten Renditen.\nDas Balkendiagramm zeigt einen Vergleich der historischen Renditemittelwerte mit den impliziten Gleichgewichtsrenditen auf Basis des marktkapitalisierungsgewichteten Referenzportfolios. Im Gegensatz zu den historischen Mittelwerten besitzen die impliziten erwarteten Renditen dabei stets positive Vorzeichen und wirken insgesamt weitaus ausgeglichener und stabiler.\n\n\nCode\npd.DataFrame({'historical mean': means,'implied mean': implied[0,:]}, \\\n             index=frame1.columns).plot.bar(stacked=False, \\\n            alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\nDas folgende Balkendiagramm veranschaulicht den Unterschied zwischen den Markowitz-Gewichtungen (ohne Restriktionen) auf der Basis historischer Renditen und den Referenzgewichtungen auf der Basis der impliziten Renditen. Es ist ersichtlich, dass das optimale Portfolio auf der Grundlage der impliziten Renditen (entspricht dem Referenzportfolio) grundsätzlich positive Gewichte und somit keine Leerverkaufspositionen aufweist. Im Gegensatz zum Portfolio, welches auf Grundlage historischer Renditemittelwerte optimiert wurde, besitzt das optimale Portfolio der Gleichgewichtsrenditen keinerlei extreme Portfolio-Gewichte. Dieses Portfolio entspricht viel eher der gängigen Anlagepraxis.\n\n\nCode\npd.DataFrame({'Markowitz weights': marko_weights,'implied weights': impl_weights[0,:]}, \\\n             index=frame1.columns).plot.bar(stacked=False, \\\n            alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\n\n\n6.6.3 Formulierung und Implementierung von Prognosemeinungen (Views)\nNach der Berechnung der impliziten Renditen sind nun die subjektiven Views des Portfolio-Managers zu implementieren. Die impliziten Renditen fungieren dabei als Ausgangspunkt für die weiteren Berechnungen und stabilisieren zugleich als zentraler “Anker” die Allokation des Portfolios. Die Ankerfunktion der impliziten Renditen trägt zur Vermeidung einer extremen Portfolioallokation und einer hohen Sensitivität des Portfolios bei, die bei der Portfoliooptimierung nach Markowitz oftmals auftritt. Hier zeigt sich bereits einer der genannten Vorteile des Black-Litterman Modells gegenüber dem Erwartungswert-Varianz-Ansatz. Da die Portfolio-Manager häufig eine von den impliziten Renditen abweichende Meinung über die zukünftige Renditeentwicklung besitzen, ist es notwendig die subjektiven Einschätzungen der jeweiligen Portfolio-Manager zu integrieren.\nIm Rahmen der Fallstudie wird von folgenden Wertpapierentwicklungen ausgegangen:\n\nView 1 Für das Unternehmen Ebay rechnet das Portfolio-Management im nächsten Jahr mit einer Rendite in Höhe von 12,0 %.\nView 2 Es wird angenommen, dass die Wertpapierrendite von AT&T eine um 2,0 % höhere Rendite als Microsoft erzielen wird.\nView 3 Die Wertpapierrenditen von Cisco und IBM werden die Wertpapierrenditen von Costco und Kraft Foods in Höhe von 3,0 % übertreffen.\n\nAls Vektor \\(V\\) ergibt sich aufgrund der festgelegten Views der Portfolio-Manager:\n\\[ \\quad V=\\left( \\begin{array}{rrrr}\n12\\% \\\\\n2\\% \\\\\n3\\% \\\\\n\\end{array}\\right). \\]\nDie relativen und absoluten Views führen zu folgenden Prognosematrix \\(P\\):\n\\[ \\quad P=\\left( \\begin{array}{rrrr}\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 0 & -1 & 1 & 0 & 0 & 0 & 0\\\\\n0 & 0,69 & 0 & 0 & 0 & 0 & 0,31 & 0 & -0,36 & -0,64\\\\\n\\end{array}\\right). \\]\nDer absolute View 1 wird in der ersten Spalte der Matrix festgelegt. Zeile zwei repräsentiert View 2, der eine einfache relative Renditemeinung darstellt. View 3 stellt einen mehrfachen relativen View dar und ist dementsprechend in Zeile drei der Matrix \\(P\\) vorzufinden. Die Wertpapiere der Outperformer und Underperformer (des dritten Views) sind mit ihren relativen Marktwertgewichten im Long- bzw. Short-Portfolio berücksichtigt.\n\n\nCode\n# implementing the portfolio manager's view\nP = np.zeros((3,10))\nP[0,7]=1\nP[1,4]=-1\nP[1,5]=1\nP[2,1]=0.69\nP[2,6]=0.31\nP[2,8]=-0.36\nP[2,9]=-0.64\n\nV = np.matrix([0.12, 0.02, 0.03])\n\n\nIm weiteren Verlauf sind die Black-Litterman Renditen zu berechnen. Da jedoch der Eintritt der einzelnen Views mit Unsicherheit behaftet ist, ist noch der individuelle Schätzfehler jedes Views zu quantifizieren. Hierbei wird der Methode, die Diagonalmatrix der Schätzfehler \\(\\Omega\\) proportional zur historischen Varianz-Kovarianzmatrix zu berechnen, gefolgt. Daraus ergibt sich für \\(\\Omega\\) folgende Matrix:\n\\[\\Omega=\\left( \\begin{array}{rrrr}\n(P_1\\Sigma P^T_1)\\cdot \\tau & 0 & 0 \\\\\n0 & \\ddots & 0 \\\\\n0 & 0 & (P_k\\Sigma P^T_k)\\cdot \\tau \\\\\n\\end{array}\\right) =\n\\left( \\begin{array}{rrrr}\n0,0526 & 0 & 0 \\\\\n0 & 0,0117 & 0 \\\\\n0 & 0 & 0,0064 \\\\\n\\end{array}\\right).\n\\]\nFür den Proportionalitätsfaktor \\(\\tau\\) (umso kleiner je größer das Vertrauen des Portfolio-Managers in das eigene Referenzportfolio ist) werden in der Literatur niedrige Werte empfohlen. Hier wird \\(\\tau=0,2\\) gesetzt.\nHinweis: Durch np.diag(np.diag(x)) werden zunächst die Diagonalelemente der Matrix \\(x\\) extrahiert und daraus wird dann eine Diagonalmatrix konstruiert.\n\n\nCode\n# calculation of omega: diagonal matrix containing variances of manager's\n# forcasting errors\n\ntau = 0.2\nOmega = np.diag(np.diag((P.dot(tau*Sigma)).dot(P.T)))\n\n\nNun sind die implementierten Views der Portfolio-Manager mit den impliziten Renditen analog der oben vorgestellten zentralen Black-Litterman Gleichung (12) zu mischen:\n\\[ (12) \\quad E(\\mu_{a-posteriori})=[(\\tau\\cdot\\Sigma)^{-1}+P^T\\Omega^{-1}P]^{-1}[(\\tau\\cdot\\Sigma)^{-1}\\Pi+P^T\\Omega^{-1}V]. \\]\nAls Ergebnis resultieren die Black-Litterman Renditen. Inwieweit die impliziten Renditen durch die Views der Portfolio-Manager abweichen, ist anhand des Balkendiagramms unten ersichtlich.\n\n\nCode\n# calculation of Black-Litterman expected returns\n# imputs: tau, Omega, Sigma, P, implied, V\n\nbl_means = la.inv(la.inv(tau*Sigma) + (P.T.dot(la.inv(Omega))).dot(P)).dot(\\\n    la.inv(tau*Sigma).dot(implied.T) + (P.T.dot(la.inv(Omega))).dot(V.T))\n\n\n\n\nCode\npd.DataFrame({'BL means': np.asarray(bl_means).T[0,:],'implied means': implied[0,:]}, \\\n             index=frame1.columns).plot.bar(stacked=False, \\\n            alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\n\n\nCode\npd.DataFrame({'implied means': implied[0,:], 'BL means': np.asarray(bl_means).T[0,:],\\\n             'Difference (%)': np.round((np.asarray(bl_means).T[0,:]-implied[0,:]),4)*100}, \\\n             index=frame1.columns)\n\n\n\n\n\n\n\n\n\nimplied means\nBL means\nDifference (%)\n\n\n\n\nAA\n0.117003\n0.114132\n-0.29\n\n\nIBM\n0.055150\n0.054665\n-0.05\n\n\nINTC\n0.074694\n0.071138\n-0.36\n\n\nJPM\n0.070246\n0.063142\n-0.71\n\n\nMSFT\n0.068769\n0.053442\n-1.53\n\n\nT\n0.044703\n0.051446\n0.67\n\n\nCSCO\n0.075445\n0.074396\n-0.10\n\n\nEBAY\n0.130241\n0.122653\n-0.76\n\n\nCOST\n0.047745\n0.044003\n-0.37\n\n\nKFT\n0.030642\n0.028216\n-0.24\n\n\n\n\n\n\n\nAuffällig ist zunächst, dass sich prinzipiell die erwarteten Renditen aller Wertapiere verändern, obwohl lediglich für bestimmte Wertpapiere Views formuliert wurden. Der Grund für diese Veränderung aller Wertpapierrenditen liegt maßgeblich in der Korrelation der einzelnen Renditen untereinander, berücksichtigt in der Matrix \\(\\Sigma\\).\nDie erwartete Rendite für Ebay wurde durch den abgegebenen View von ca. 13,0 % auf ca. 12,3 % reduziert. Der zweite View des Portfolio Managements führte zu einer Reduzierung der Renditeerwartung für Microsoft um absolut 1,53 %, wobei sich die Renditeerwartung für AT&T um absolut 0,67 % erhöhte. Dieses Ergebnis ist auch intuitiv nachvollziehbar, da der vom Portfolio Management prognostizierte Renditeunterschied (AT&T - Microsoft) mit 2,0 % positiv ausfiel während der Unterschied in den impliziten Renditen mit -2,41 % (4,47 % - 6,88 %) negativ ist. Dieser Umstand wirkte sich unvorteilhaft auf die Black-Litterman Rendite von Microsoft und vorteilhaft auf die Rendite von AT&T aus.\nDie Beurteilung der Auswirkungen des mehrfachen relativen dritten Views erfordert im Gegensatz zu den beiden bisher betrachteten Views die Betrachtung der Long- (Cisco und IBM) und Short-Portfolios (Costco und Kraft Foods). Hierbei wird die Differenz (+2,47 %) der gewichteten impliziten Renditen des Long- (\\(0,31\\cdot7,54 +0,69\\cdot5,52 = 6,15\\)) und des Short-Portfolios (\\(0,36\\cdot4,77+0,64\\cdot3,06=3,68\\)) mit dem View (+3,0 %) verglichen. Auch in diesem Fall ist die Richtung der Renditeveränderung intuitiv nachvollziehbar. Da die erwartete Renditedifferenz zwischen Long- und Short-Portfolio geringer als der View ist, wird eine Erhöhung der Differenz erwartet. Im Ergebnis werden die Renditeerwartungen so verändert, dass sich die Renditedifferenz der Long- und Short-Portfolios vergrößert. Konkret schlägt sich dies nahezu unverändert auf die erwartete Rendite des Long-Portfolios nieder (IBM reduziert sich um absolut 0,05 %, Cisco um absolut 0,1 %). Die erwartete Rendite des Short-Portfolios erfährt hingegen eine deutliche Reduzierung. Die Black-Litterman Rendite für Costco ist absolut um 0,37 % (relativ: 7,75 %) geringer. Die Reduzierung für Kraft Foods fällt ähnlich aus (relativ um 7,84 %). Wie eingangs erwähnt, haben sich die Renditeerwartungen über alle Wertpapiere hinweg verändert. Die erwarteten Renditen der nicht in den Views angesprochenen Wertpapiere Alcoa, Intel und J.P. Morgan haben sich jeweils absolut um 0,29 %, 0,36 % und 0,71 % reduziert.\nEs kann also festgehalten werden, dass jeder View für ein Wertpapier implizit auch eine Prognose für jedes andere Wertpapier enthält. Dieser Effekt erklärt sich vorrangig durch die Multiplikation der einzelnen Matrizen \\(P\\), \\(\\tau\\Omega\\) und \\(\\Sigma\\) in der Black-Litterman Formel (12).\n\n\n6.6.4 Portfoliooptimierung nach Black-Litterman\nDie Portfoliooptimierung, basierend auf den zuvor ermittelten impliziten bzw. den Black-Litterman Renditen, resultiert in folgender Portfolioallokation.\n\n\nCode\n# calculation of optimal portfolio weights using BL returns \n# and analytic formula\nbl_weights = la.inv(gamma * Sigma).dot(bl_means)\n\n\n\n\nCode\npd.DataFrame({'BL weights': np.asarray(bl_weights)[:,0],'implied weights': impl_weights[0,:]}, \\\n             index=frame1.columns).plot.bar(stacked=False, \\\n            alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\n\n\nCode\npd.DataFrame({'implied weights': impl_weights[0,:], 'BL weights': np.asarray(bl_weights)[:,0], \\\n              'Difference (%)': np.round((np.asarray(bl_weights)[:,0]-impl_weights[0,:]), 3)*100}, \\\n             index=frame1.columns)\n\n\n\n\n\n\n\n\n\nimplied weights\nBL weights\nDifference (%)\n\n\n\n\nAA\n0.007369\n0.007369\n0.0\n\n\nIBM\n0.180836\n0.214646\n3.4\n\n\nINTC\n0.099716\n0.099716\n-0.0\n\n\nJPM\n0.113287\n0.113287\n0.0\n\n\nMSFT\n0.205001\n0.016633\n-18.8\n\n\nT\n0.170562\n0.358930\n18.8\n\n\nCSCO\n0.081912\n0.097102\n1.5\n\n\nEBAY\n0.048570\n0.043521\n-0.5\n\n\nCOST\n0.033295\n0.015655\n-1.8\n\n\nKFT\n0.059452\n0.028093\n-3.1\n\n\n\n\n\n\n\nWie erwartet wurden lediglich die Portfoliogewichte der in den Views angesprochenen Wertpapiere verändert. Die Wertpapiere Alcoa, Intel und J.P. Morgan, für die keine subjektiven Renditeschätzungen abgegeben wurden, gehen unverändert entsprechend der Höhe ihrer jeweiligen relativen Marktkapitalisierungen im Ausgangsportfolio in die Portfolioallokation ein. Bei den Wertpapieren IBM, Microsoft, AT&T, Cisco, Ebay, Costco, und Kraft Foods, für die Prognosen abgegeben wurden, sind sichtbare Abweichungen zu beobachten. Der Anteil von Microsoft am Referenzportfolio mit 20,5 % reduzierte sich auf 1,66 % um absolut 18,8 %. Der Portfolioanteil von AT&T erhöhte sich um absolut 18,8 % und beträgt nun 35,89 % im BL-Portfolio. Dieser Zusammenhang wird im Rahmen des mehrfachen relativen Views (View 3) noch deutlicher. Auch hier gleichen sich das Long-Portfolio (IBM + Cisco) mit absolut +4,9 % (= 3,4 % + 1,5 %) und das Short-Portfolio (Costco + Kraft Foods) mit absolut -4,9 % (= -1,8 % - 3,1 %) aus.\n\n\n6.6.5 Portfoliooptimierung nach Black-Litterman und Markowitz im Vergleich\nDas nachfolgende Balkendiagramm vergleicht die Allokation des Black-Litterman Portfolios und des Portfolios nach Markowitz.\n\n\nCode\npd.DataFrame({'BL weights': np.asarray(bl_weights)[:,0],'Markowitz weights': marko_weights}, \\\n             index=frame1.columns).plot.bar(stacked=False, \\\n            alpha=0.5, figsize=(10,5));\n\n\n\n\n\n\n\n\n\nZunächst fällt auf, dass die Portfoliogewichte nach dem Black-Litterman Verfahren im Vergleich zur Zusammensetzung des Portfolios nach Markowitz weitaus ausgewogener sind. Hierbei zeigt sich der bereits angesprochene Vorteil des Black-Litterman Ansatzes gegenüber der Portfoliooptimierung nach Markowitz. Das Black-Litterman Portfolio orientiert sich in seiner Allokation an der dem Portfolio Manager vorschwebenden Diversifikation (gemäß Referenzportfolio). Das Black-Litterman Portfolio erfüllt damit die Forderungen der Praxis, ein hinreichend diversifiziertes Portfolio zu bilden, keine extremen Portfoliogewichtungen oder gar Short-Positionen zu enthalten und sich (eventuell) an einer Benchmark zu orientieren.\n\n6.6.5.1 Markowitz-Portfoliooptimierung mit Restriktionen: Corner-Portfolios\nDie oben dargestellte Portfolioallokation nach Markowitz stellt in der Praxis eine oft nicht realisierbare Portfoliokonstruktion dar - im Gegensatz zur Portfolioallokation nach Black und Litterman. Für den Fall einer Portfoliooptimierung nach Markowitz stellt die Einführung von Nebenbedingungen einen denkbaren Lösungsansatz dar. Einerseits könnten für Wertpapiere individuelle Ober- und Untergrenzen gesetzt werden. Andererseits könnte grundsätzlich ein Leerverkaufsverbot aus firmenpolitischen Gründen oder externen Restriktionen in den Nebenbedingungen festgelegt werden.\nAus diesem Grund wird im Folgenden eine Leerverkaufsrestriktion eingeführt. Dieses Leerverkaufsverbot hat in der Fallstudie allerdings nur Auswirkungen auf die Portfoliokonstruktion nach Markowitz, da die Gewichte im Black-Litterman Portfolio ohnehin positiv sind. Wie zuvor bei den Schwächen des Markowitz-Ansatzes genannt, resultieren aber aus einer Leerverkaufsrestriktion häufig die so genannten Corner-Portfolios. Dieses Problem wird auch in der Fallstudie klar ersichtlich.\nZunächst berechnen wir die Effizienzkurven unter Verwendung der Black-Litterman erwarteten Renditen und der klassischen, historisch geschätzten Renditeerwartungswerte.\n\n\n6.6.5.2 Berechnung der Effizienzkurven für BL und historisch geschätzte erwartete Renditen\n\n\nCode\n# use equal weights \"Weight_1N\" as starting values \nWeight_1N = np.tile(1.0/means.shape[0], means.shape[0])\n\n\nDefinition der beiden Zielfunktionen für das Globale Minimum Varianz Portfolio (GMVP) und das Maximum Ertrags Portfolio (MRP).\n\n\nCode\n# definition of target function for GMVP to be minimized\ndef calculate_portfolio_var(w,Sigma):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    return (w*Sigma*w.T)[0,0]\n\n# definition of target function for MRP to be maximized\ndef calculate_negative_portfolio_ret(w,means):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return -(w*means.T)[0,0]\n\n\n\n\nCode\n# calculation of GMVP and MRP portfolio weights\n# GMVP without short-sales\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1),(0, 1),\n     (0, 1),(0, 1),(0, 1),(0, 1),(0, 1)] # only positive weights\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\n\nres2= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_GMV = res2.x\n\n# MRP portfolio\n# for historic mean returns\nres4= minimize(calculate_negative_portfolio_ret, Weight_1N, args=means, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MRP_hist = res4.x\n\n# for BL mean returns\nres4= minimize(calculate_negative_portfolio_ret, Weight_1N, args=bl_means.T, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10, \n               options={'disp': True})\nWeight_MRP_bl = res4.x\n\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.01798288803981981\n            Iterations: 20\n            Function evaluations: 220\n            Gradient evaluations: 20\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -0.059248481306705396\n            Iterations: 13\n            Function evaluations: 143\n            Gradient evaluations: 13\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -0.12265320544211984\n            Iterations: 10\n            Function evaluations: 110\n            Gradient evaluations: 10\n\n\n\n\nCode\n# calculation of min and max target return\ndef calculate_portfolio_ret(w,means):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return (w*means.T)[0,0]\n\n\n# historic\nmin_hist = calculate_portfolio_ret(Weight_GMV, means)\nmax_hist = calculate_portfolio_ret(Weight_MRP_hist, means)\n\n# BL\nmin_bl = calculate_portfolio_ret(Weight_GMV, bl_means.T)\nmax_bl = calculate_portfolio_ret(Weight_MRP_bl, bl_means.T)\n\n\nBerechnung der Effizienzkurven (Code analog zum Kapitel 2 Absolute Portfoliooptimierung).\n\n\nCode\n# efficient frontier with hist. mean returns\nV_Target_hist = np.linspace(min_hist, max_hist, num=45)\nV_Risk_hist = np.zeros(V_Target_hist.shape)\nV_Return_hist = np.zeros(V_Target_hist.shape)\nV_Weight_hist = np.zeros((V_Target_hist.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target_hist):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,means)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight_hist[idx, :] = res.x.T\n    V_Return_hist[idx] = calculate_portfolio_ret(res.x,means)\n    V_Risk_hist[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\n\n\nCode\n# efficient frontier with hist. mean returns\nV_Target_bl = np.linspace(min_bl, max_bl, num=45)\nV_Risk_bl = np.zeros(V_Target_bl.shape)\nV_Return_bl = np.zeros(V_Target_bl.shape)\nV_Weight_bl = np.zeros((V_Target_bl.shape[0], means.shape[0]))\nfor idx, Target_Return in enumerate(V_Target_bl):\n    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n            {'type': 'eq', 'fun': lambda x:  calculate_portfolio_ret(x,bl_means.T)-Target_Return})\n    res= minimize(calculate_portfolio_var, Weight_1N, args=Sigma, \n               bounds = bnd, method='SLSQP',constraints=cons,tol=1e-10)\n    V_Weight_bl[idx, :] = res.x.T\n    V_Return_bl[idx] = calculate_portfolio_ret(res.x,bl_means.T)\n    V_Risk_bl[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n\n\nGraphische Darstellung der Kurven (Code analog zum Kapitel 2 Absolute Portfoliooptimierung)\n\n\nCode\nfig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig1.add_subplot(111)\nplt.plot(V_Risk_hist, V_Target_hist, 'g:', label='Hist.-Efficient frontier without short selling')\nplt.plot(V_Risk_bl, V_Target_bl, 'g-', label='BL-Efficient frontier without short selling')\nplt.plot(np.sqrt(np.diagonal(Sigma)), means, 'rx', label='Asset')\nfor i, txt in enumerate(frame1.columns):\n   ax.annotate(txt, (np.sqrt(np.diagonal(Sigma))[i],means[i]))\nplt.legend(loc='best',  frameon=True)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return')\nplt.show()\n\n\n\n\n\n\n\n\n\nEs ist erkennbar, dass die Effizienzkurve der Portfolios nach Markowitz wesentlich steiler verläuft als die der Black-Litterman Portfolios. Die Black-Litterman Portfolios sind breiter diversifiziert und dominieren in der Fallstudie die Portfolios nach Markowitz in jedem Punkt, wodurch sie stets ein besseres Rendite-Risiko-Verhältnis liefern.\nDie nachfolgende Abbildung zeigt wie sich die Portfoliogewichte unzureichend diversifizierter Corner-Portfolios (entlang der Effizienzkurve) bei der Markowitz Optimierung mit Leerverkaufsrestriktion (d.h., positive Bestandsgrenzen) zusammensetzen.\nDie optimalen Portfolios setzen sich maximal aus fünf Wertpapieren (mit einem jeweils sehr geringen Anteil für Microsoft) zusammen und schon bei einer Zielrendite von etwas mehr als 5 % besteht das Portfolio faktisch nur noch aus IBM.\n\n\nCode\nfig2 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target_hist, V_Weight_hist.T*100)\nplt.axis([min_hist, max_hist, 0.0, 100.0])\nplt.legend(list(frame1.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return')\nplt.ylabel('Allocation weight (%)')\nplt.title('Markowitz Allocations')\nplt.show()\n\n\n\n\n\n\n\n\n\nIm Gegensatz dazu verhalten sich die Gewichte der Black-Litterman Portfolios entlang der Effizienzkurve deutlich ausgewogener und bilden jeweils wesentlich breiter diversifizierte Portfolios.\n\n\nCode\nfig2 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target_bl, V_Weight_bl.T*100)\nplt.axis([min_bl, max_bl, 0.0, 100.0])\nplt.legend(list(frame1.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return')\nplt.ylabel('Allocation weight (%)')\nplt.title('Black-Litterman Allocations')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#lernvideos",
    "href": "kapitel5a.html#lernvideos",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.7 Lernvideos",
    "text": "6.7 Lernvideos\n\n6.7.1 Video Teil 1\n\n\n\n6.7.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel5a.html#literatur",
    "href": "kapitel5a.html#literatur",
    "title": "6  Das Black-Litterman Modell",
    "section": "6.8 Literatur",
    "text": "6.8 Literatur\nBlack, F./ Litterman, R. (1991): Global Asset Allocation with Equities, Bonds and Currencies. “Fixed Income Research”, Goldman, Sachs & Company, Oktober.\nBlack, F./ Litterman, R. (1992): Global Portfolio Optimization. In: Financial Analysts Journal, September-Oktober, S. 28-43.\nDrobetz, W. (2002): Einsatz des Black-Litterman Verfahrens in der Asset Allocation. In: Dichtl, H./Kleeberg, J. M./Schlenger, C (Hrsg.). Handbuch Asset Allocation: Innovative Konzepte zur systematischen Portfolioplanung, S. 204-239, Bad Soden: Uhlenbruch Verlag.\nIdzorek, T.M. (2004): A Step-by-Step Guide to the Black-Litterman Model, incorporating user-specified confidence levels. Arbeitspapier, Zephyr Associates, Inc.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Das Black-Litterman Modell</span>"
    ]
  },
  {
    "objectID": "kapitel6a.html",
    "href": "kapitel6a.html",
    "title": "7  Berücksichtigung des Schätzrisikos: Portfolio-Resampling",
    "section": "",
    "text": "7.1 Grundlagen\nDie Motivation der Resampling-Methode beruht auf der Erkenntnis, dass jede ermittelte Effizienzkurve mit Unsicherheit behaftet ist. Die Effizienzkurve wird auf Basis der Eingangsparameter (\\(\\mu\\) und \\(\\Sigma\\)) berechnet. Da die wahren Werte dieser Parameter ex ante unbekannt sind und nur geschätzt werden können, ist die wahre Effizienzkurve auch unbekannt und die ermittelte Kurve ist lediglich ein unsicherer Schätzer der wahren Effizienzkurve. Unsicherheit in den Eingangsparametern führt also zu Unsicherheit in der ermittelten Effizienzkurve.\nWie kann die Unsicherheit (das Schätzrisiko) in der Effizienzkurve quantifiziert werden? Und kann dadurch ein neuer Schätzer konstruiert werden, der dass Schätzrisiko reduziert (und damit stabilere Portfoliogewichte erzeugt, die weniger sensitiv auf Veränderungen der Eingabeparameter - dem Schätzrisiko in \\(\\mu\\) und \\(\\Sigma\\) - reagieren)? Die Resampling-Methode adressiert diese Fragen.\nDie Methode gliedert sich grundsätzlich in die folgenden Schritte (vgl. ausführlicher Michaud und Michaud, 2008):\nIm Rahmen der folgenden Fallstudie wird die Resampling-Methode beispielhaft veranschaulicht.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Berücksichtigung des Schätzrisikos: Portfolio-Resampling</span>"
    ]
  },
  {
    "objectID": "kapitel6a.html#grundlagen",
    "href": "kapitel6a.html#grundlagen",
    "title": "7  Berücksichtigung des Schätzrisikos: Portfolio-Resampling",
    "section": "",
    "text": "Zunächst müssen die Eingabeparameter \\(\\mu\\) und \\(\\Sigma\\) geschätzt werden, z.B. auf Basis einer einfachen historischen Schätzung. Bezeichnen wir die Menge der geschätzten Parameter mit \\(\\theta\\), und nehmen an, dass es \\(m\\) Wertpapiere gibt.\nDanach werden die Gewichte des Globalen Minimum Varianz Portfolios (MVP) und des Maximum Ertrags Portfolios (MEP) bestimmt. Wir bezeichnen die erwartete Rendite des MVP mit \\(L\\), und die des MEP mit \\(H\\).\nWir diskretisieren die stetige Effizienzkurve indem wir die Anzahl \\(K\\) an erwarteten Renditen festlegen, für die wir die Effizienzkurve (das jeweils zur Zielrendite gehörende MVP) bestimmen wollen. Ist z.B. \\(L=0,05\\) und \\(H=0,20\\) und wir wählen eine Menge von \\(K=16\\) Punkten, dann bestimmen wir die Effizienzkurve für die Zielrenditen \\(\\{0,05; 0,06; ...; 0,19; 0,20\\}\\). Dies ergibt \\(16\\) unterschiedliche Punkte auf der Effizienzkurve.\nIm Folgenden werden wir die diskretisierte Effizienzkurve in Form einer Matrix \\(a_K\\) schreiben. Jedes Element der Matrix stellt dabei ein Portfoliogewicht dar. Die Matrix hat somit die Dimension \\(Kxm\\) (die Zeilen repräsentieren die Zielrenditen, und die Spalten die Wertpapiere). Das Paar \\((a_K, \\theta)\\) beschreibt folglich die Effizienzkurve ermittelt auf Basis der (z.B. historisch) geschätzten Parameter. In unserem Beispiel gibt es 16 Zeilen (Zielrenditen, gleichmäßig verteilt zwischen \\(L\\) und \\(H\\)).\nWir beginnen mit der Monte Carlo Simulation indem wir eine Realisation \\(\\theta_i\\) aus der Wahrscheinlichkeitsverteilung von \\(\\theta\\) ziehen. \\(\\theta_i\\) und \\(\\theta\\) nennt man “statistisch äquivalent”. Dies beinhaltet die folgenden Schritte: Nehmen wir z.B. an unser Anlageuniversum besteht aus \\(m=5\\) Wertpapieren und unsere historische Renditezeitreihe hat eine Länge von \\(k=200\\) Beobachtungen. Wir verwenden einen Zufallszahlengenerator, \\(\\theta\\) (d.h., den historisch geschätzten Vektor der erwarteten Renditen \\(\\mu\\) und die historische Varianz-Kovarianzmatrix \\(\\Sigma\\)), unterstellen eine multivariate Normalverteilung für den Zufallsvektor \\(R_m\\) der \\(m\\) Renditen (d.h., \\(R_m \\sim N_m(\\mu,\\Sigma)\\)), und ziehen 200 Mal jeweils fünf Renditen (d.h., eine Realisation von \\(R_m\\)) aus der unterstellten multivariaten Verteilung (muss nicht notwendigerweise die Normalverteilung sein). Auf Basis der simulierten Renditezeitreihen berechnen wir die simulierten \\(\\mu_i\\) und \\(\\Sigma_i\\), d.h. \\(\\theta_i\\).\nAuf Basis von \\(\\theta_i\\), Neuberechnung des MVP (erwartete Rendite \\(L_i\\)) und des MEP (erwartete Rendite \\(H_i\\)). Aufteilung des Intervals \\([L_i,H_i]\\) in \\(K\\) gleichmäßig verteilte Zielrenditen. In Anlehnung an das obige Beispiel mit \\(K=16\\), für \\(L_i=0,03\\) und \\(H_i=0,25\\) ergeben sich die folgenden Zielrenditen: \\(\\{0,030; 0,044; 0,058; ...; 0,236; 0,250\\}\\).\nBestimmung der effizienten Portfoliogewichte für jeden der \\(K\\) Punkte (Ermittlung der MVP Gewichte für eine Zielrendite von 0,030; 0,044; … usw.). Daraus resultiert eine neue \\(K x m\\) Matrix \\(a_{K,i}\\).\nWiederholung der Simulationen, so dass wir 1,000 \\(a_{K,i}\\)’s erhalten.\nDurchschnittsbildung über die 1,000 \\(a_{K,i}\\)’s. Für jeden der \\(K\\) Punkte und \\(m\\) Wertpapiere resultieren damit durchschnittliche Portfoliogewichte. \\(a^*_{K}\\) bezeichnet die \\(Kxm\\) Matrix dieser durchschnittlichen Gewichte.\nBestimmung der Resampled-Effizienzkurve durch Kombination der originalen Parameterschätzungen (z.B. historisch) \\(\\theta=\\{\\mu,\\Sigma\\}\\) mit den Durchschnittsgewichten \\(a^*_{K}\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Berücksichtigung des Schätzrisikos: Portfolio-Resampling</span>"
    ]
  },
  {
    "objectID": "kapitel6a.html#beginn-der-fallstudie",
    "href": "kapitel6a.html#beginn-der-fallstudie",
    "title": "7  Berücksichtigung des Schätzrisikos: Portfolio-Resampling",
    "section": "7.2 Beginn der Fallstudie",
    "text": "7.2 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nimport numpy.linalg as la\n\n\n\n7.2.1 Laden und Beschreiben der Datenbasis\nDer verwendete Datensatz enthält Kurshistorien der folgenden zehn Aktien: Danone, Siemens, BASF, L’Oreal, Allianz, Telecom Italia, Banco Santander, Total, BMW, Vivendi. Zudem ist als elfte Spalte die Indexhistorie des Euro Stoxx 50 im Datensatz enthalten (diese wird nicht benötigt).\nDie Zeitreihen umfassen 111 Monatsschlusskurse (“Adjusted Close”) über den Zeitraum vom 31.12.2002 bis zum 29.2.2012.\n\n\nCode\n# hier den Pfad zur Datei einfügen\n# cd \"...\"\n\n\n\n\nCode\n# load stock returns\n# sample of 10 European stocks\nframe1 = pd.read_excel('Kapitel A3_4.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\nframe1.drop('EuroStoxx 50', axis=1, inplace=True)\n\n\n\n\nCode\nframe1.head()\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\n\n\n\n\n2002-12-31\n30.2427\n40.50\n18.040\n72.55\n82.025\n2.0558\n5.8537\n33.5794\n28.92\n15.39\n\n\n2003-01-31\n27.6478\n38.15\n17.260\n64.30\n66.860\n2.0199\n5.1466\n30.9888\n27.26\n15.64\n\n\n2003-02-28\n25.9021\n36.78\n16.910\n59.90\n60.137\n1.8927\n5.3256\n30.2486\n26.00\n13.02\n\n\n2003-03-31\n27.2939\n37.80\n17.055\n55.50\n41.080\n2.0074\n5.2361\n28.6202\n25.44\n12.18\n\n\n2003-04-30\n29.9125\n44.67\n19.985\n64.05\n63.350\n2.1609\n6.3012\n28.9903\n29.87\n14.60\n\n\n\n\n\n\n\nAuf Basis von stetigen (log) Renditen werden die historischen Mittelwerte und die Varianz-Kovarianzmatrix der Renditen berechnet.\n\n\nCode\n# calculation of returns, and historical means and Sigma\n# using log returns\n\nreturns = np.log1p(frame1.pct_change().dropna())\n\n# historical means and covariances\nmeans_hist = returns.mean().values\nSigma_hist = returns.cov().values\n\n\n\n\n7.2.2 Portfoliooptimierung mit Leerverkaufsverbot\nIm Folgenden betrachten wir ausschießlich den Fall der Portfoliooptimierung mit Leerverkaufsverbot (implementiert über positive Bestandsgrenzen). Die Portfoliogewichte können also nur numerisch bestimmt werden.\nWir beginnen mit der Definition der Zielfunktionen der Optimierung: \\(\\sigma_P^2 \\rightarrow \\min_{w}!\\) für das GMVP bzw. für das MEP: \\(\\mu_P \\rightarrow \\max_{w}!\\). Die dritte Funktion berechnet die erwartete Portfoliorendite.\n\n\nCode\n# necessary functions for calculating the: GMVP, MRP, min and max target\n# returns\n\n# specification of target function for MRP:\ndef calculate_negative_portfolio_ret(w,means):\n    # function that calculates negative of portfolio return\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return -(w*means.T)[0,0]\n\n# specification of target function for GMVP:\ndef calculate_portfolio_var(w,Sigma):\n    # function that calculates portfolio risk\n    w = np.matrix(w) # w is a row (not column!) vector\n    return (w*Sigma*w.T)[0,0]\n\ndef calculate_portfolio_ret(w,means):\n    # function that calculates portfolio return\n    w = np.matrix(w) # w is a row (not column!) vector\n    means = np.matrix(means)\n    return (w*means.T)[0,0]\n\n\nWir implementieren die Bestimmung der optimalen Portfoliogewichte elegant und kompakt über die Funktionen gmvp und mrp.\n\n\nCode\n# functions that return the optimal portfolio weights\n# 1. GMVP\n# positive weights only\ndef gmvp(Sigma):\n    num_assets = len(Sigma)\n    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0.0,1.0)\n    bounds = tuple(bound for asset in range(num_assets))   \n    res= minimize(calculate_portfolio_var, num_assets*[1./num_assets,],\n                args=Sigma, bounds = bounds, method='SLSQP',\n                constraints=cons,tol=1e-10)\n    return res.x\n\n# 2. MRP\n# positive weights only\ndef mrp(means):\n    num_assets = len(means)\n    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0.0,1.0)\n    bounds = tuple(bound for asset in range(num_assets))   \n    res= minimize(calculate_negative_portfolio_ret, \n                  num_assets*[1./num_assets,],\n                  args=means, bounds = bounds, method='SLSQP',\n                  constraints=cons,tol=1e-10)\n    return res.x\n\n\nWird dann die Portfoliooptimierung für \\(K\\) verschiedene Zielrenditen zwischen der erwarteten Rendite des MVP (Objekt min) und der des MEP (Objekt max) durchgeführt, ergibt sich die entsprechende diskretisierte Effizienzkurve. Die Anzahl Punkte \\(K\\) wird über das Argument K eingestellt.\n\n\nCode\n# calculation of efficient frontier, i.e. a (Kxm)-matrix of m stock \n# weights for K different target returns\n# efficient frontier with hist. mean returns\n\ndef ef_front(means, Sigma, K=30):\n    # calculation of min and max target return\n    # min: expected return of GMVP, max: expected return of MRP\n    min = calculate_portfolio_ret(gmvp(Sigma), means)\n    max = calculate_portfolio_ret(mrp(means), means)\n    \n    V_Target = np.linspace(min, max, num=K) # use K=30 points of the ef!\n    V_Risk = np.zeros(V_Target.shape)\n    V_Weight = np.zeros((V_Target.shape[0], means.shape[0]))\n    for idx, Target_Return in enumerate(V_Target):\n        num_assets = len(means)\n        bound = (0.0,1.0)\n        bounds = tuple(bound for asset in range(num_assets)) \n        cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0},\n                {'type': 'eq', 'fun': lambda x:  \\\n                 calculate_portfolio_ret(x,means)-Target_Return})\n        res= minimize(calculate_portfolio_var,num_assets*[1./num_assets,],\n                      args=Sigma,bounds = bounds, method='SLSQP',\n                      constraints=cons,tol=1e-10)\n        V_Weight[idx, :] = res.x.T\n        V_Risk[idx] = np.sqrt(calculate_portfolio_var(res.x, Sigma))\n    return V_Weight, V_Risk, V_Target\n\n\nDie folgende Funktion resampled_weights implementiert die Monte Carlo Simulation. Es wird im Ergebnis die “Durchschnittsmatrix” \\(a^*_K\\) der \\(M\\) simulierten Portfoliogewichtsmatrizen \\(a_{K,i}\\) zurückgegeben.\nIn jedem Simulationsschritt \\(i=1, ..., M\\) werden zunächst über random.multivariate_normal(Mu, Sigma, size=k) \\(k\\) Realisationen aus der angegebenen multivariaten Normalverteilung gezogen und in das DataFrame df überführt. Auf Basis dieser simulierten Daten berechnen sich \\(\\mu_i\\) und \\(\\Sigma_i\\), die wiederum eingesetzt in die oben definierte Funktion ef_front die simulierte Effizienzkurve \\(a_{K,i}\\) ergeben. Diese Gewichtsmatrix wird dann als zweidimensionales (2-D) Array (Matrix) der Liste liste hinzugefügt. Final werden die \\(M\\) 2-D Arrays in der Liste gemittelt.\n\n\nCode\ndef resampled_weights(M, means_hist, Sigma_hist):\n# M: number of Monte Carlo runs   \n    np.random.seed(42)\n    liste = []\n    for i in range(M):\n        df = pd.DataFrame(np.asarray(np.random.multivariate_normal(means_hist,\\\n                Sigma_hist, size = 110)), columns=frame1.columns)\n        means = df.mean().values\n        Sigma = df.cov().values\n        weight, _, _ = ef_front(means, Sigma)\n        # weight is the (Kxm) matrix for each i=1,..M simulation\n        liste.append(weight) \n    return np.average(liste, axis=0) \n\n\nDie finale Funktion sim_ef berechnet die Resampled-Effizienzkurve durch Kombination der originalen (historischen) Parameterschätzungen means_hist und Sigma_hist mit den Durchschnittsgewichten sim_weights (\\(a^*_{K}\\)).\nHierbei gibt sim_weights.shape[0] die Anzahl der Punkte \\(K\\) (hier 30, Anzahl Zeilen der Gewichtsmatrix) der diskretisierten Effizienzkurve an.\nÜber eine for-Schleife werden zunächst das Portfoliorisiko \\(\\sigma^{2*}_P\\) und die erwartete Portfoliorendite \\(\\mu^*_P\\) für jeden der \\(K=30\\) simulierten Durchschnittsgewichtsvektoren \\(a^*_{k}\\) (mit \\(k=1, ..., K\\)) berechnet und in den 1-D Arrays (Vektoren) V-Risk und V_Return gespeichert.\n\n\nCode\n# function for drawing the efficient frontier based on simulated\n# Kxm weight matrix\n\n# efficient frontier on the basis of simulated weights \ndef sim_ef(M, means_hist, Sigma_hist):\n    sim_weights = resampled_weights(M, means_hist, Sigma_hist)\n    V_Risk = np.zeros(sim_weights.shape[0])\n    V_Return = np.zeros(sim_weights.shape[0])\n    for i in range(sim_weights.shape[0]):\n        V_Risk[i] = np.sqrt(calculate_portfolio_var(sim_weights[i,:], Sigma_hist))\n        V_Return[i] = calculate_portfolio_ret(sim_weights[i,:],means_hist)\n    return V_Risk, V_Return, sim_weights\n\n\nWir rufen die oben definierten Funktionen für die simulierte (sim_ef) und die “klassische” (ef_front) Effizienzkurve nun auf. Die beiden \\(Kxm\\) Gewichtsmatrizen werden in den 2-D Arrays S_Weight und V_Weight gespeichert. Portfoliorisiko und erwarte Rendite sind in entsprechend bezeichneten 1-D Arrays (Vektoren) enthalten: S_Risk (für \\(\\sigma^{2*}_P\\)), S_Return (für \\(\\mu^*_P\\)), V_Risk (für \\(\\sigma^2_P\\)) und V_Target (für \\(\\mu_P\\)).\n\n\nCode\n# simulated efficient frontier based on average simulated weights\nS_Risk, S_Return, S_Weight = sim_ef(100, means_hist, Sigma_hist)\n\n# classic efficient frontier based on historical data\nV_Weight, V_Risk, V_Target = ef_front(means_hist, Sigma_hist)\n\n\nNun plotten wir die beiden Effizienzkurven zusammen mit den Positionen der einzelnen zehn Wertpapiere.\n\n\nCode\nfig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\nax = fig1.add_subplot(111)\nplt.plot(V_Risk, V_Target, 'g:', label='Historical frontier')\nplt.plot(S_Risk, S_Return, 'g-', label='Resampled frontier')\nplt.plot(np.sqrt(np.diagonal(Sigma_hist)), means_hist, 'rx', label='Asset')\nfor i, txt in enumerate(frame1.columns):\n   ax.annotate(txt, (np.sqrt(np.diagonal(Sigma_hist))[i],means_hist[i]))\nplt.legend(loc=4,  frameon=True)\nplt.xlabel('Standard deviation')\nplt.ylabel('Expected return')\nplt.title('Comparison of efficient frontiers')\nplt.show()\n\n\n\n\n\n\n\n\n\nOffensichtlich liegt die simulierte Effizienzkurve unterhalb der klassischen Effizienzkurve. Warum?\nWenn wir uns eine bestimmte Monte Carlo Ziehung ansehen, sagen wir \\(\\theta_i\\), und die dazugehörige Kurve zeichnen, kann diese rechts oder links von der ursprünglichen Kurve liegen. Wir verfolgen die Portfoliogewichte an diskreten Punkten. Wir mitteln diese Gewichte (nicht die Kurven) - und wenden diese Durchschnittsgewichte dann auf das Original \\(\\theta\\) an.\nWir wissen, dass die optimalen (effizienten) Portfoliogewichte, gegeben \\(\\theta\\), durch \\(a_K\\) repräsentiert werden. Wenn wir \\(a^*_K\\) auf \\(\\theta\\) anwenden muss folglich die resultierende Kurve rechts von der Originalkurve liegen. Mit anderen Worten, wenn \\(a_K\\) effizient für \\(\\theta\\) ist, kann \\(a^*_K\\) nicht auch effizient für \\(\\theta\\) sein. Jede einzelne simulierte Effizienzkurve ist zwar effizient gegenüber den jeweils dazugehörigen simulierten \\(\\mu_i\\) und \\(\\Sigma_i\\), jedoch ineffizient gegenüber der ursprünglichen historischen Schätzung \\(\\mu\\) und \\(\\Sigma\\). Ein auf der Grundlage des Portfolio-Resamplings ermitteltes Portfolio ist daher per Definition nicht mehr effizient für \\(\\theta\\), es berücksichtigt aber das Schätzrisiko bezogen auf das wahre \\(\\theta\\).\nWir plotten nun in Form eines Balkendiagramms die zu den Effizienzkurven gehörenden Portfoliogewichte:\n\nResampled-Effizienzkurve\n\n\n\nCode\nfig2 = plt.figure(num=2, facecolor='w', figsize=(10, 5))\nplt.stackplot(S_Return*12, S_Weight.T*100) # annualised returns\nplt.axis([np.min(S_Return*12), np.max(S_Return*12), 0.0, 100.0])\nplt.legend(list(frame1.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return')\nplt.ylabel('Allocation weight (%)')\nplt.title('Portfolioweights for the resampled efficient frontier')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nKlassische Effizienzkurve auf Basis einfacher historisch basierter Schätzung\n\n\n\nCode\nfig3 = plt.figure(num=3, facecolor='w', figsize=(10, 5))\nplt.stackplot(V_Target*12, V_Weight.T*100)\nplt.axis([np.min(V_Target*12), np.max(V_Target*12), 0.0, 100.0]) # annualised return\nplt.legend(list(frame1.columns),\n           loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\nplt.xlabel('Target expected return')\nplt.ylabel('Allocation weight (%)')\nplt.title('Portfolioweights for the historic efficient frontier')\nplt.show()\n\n\n\n\n\n\n\n\n\nEin Vergleich der Diagramme zeigt, dass im Rahmen des Portfolio-Resamplings eindeutig eine höhere Anzahl an Wertpapieren in die Portfoliokonstruktion aufgenommen wird. Dadurch lässt sich eine höhere Diversifiktion der Portfolios erreichen. Zudem zeigen sich weniger plötzliche Verschiebungen in der Portfoliostruktur der einzelnen Wertpapiere. Die Portfoliozusammensetzung ist insgesamt diversifizierter und weniger volatil. Die stabilen Portfolioallokationen ergeben sich als Folge der Bildung durchschnittlicher Portfoliogewichte, so dass geringe Veränderungen in den Eingangsgrößen nunmehr lediglich zu geringen Veränderungen der optimierten Portfolios führen können.\n\n\n7.2.3 Exkurs: Vergleich simulierter vs. historischer Mittelwerte und Varianzen/Kovarianzen\nWir simulieren eine (d.h., ziehen zufällige Realisationen aus einer) multivariaten Normalverteilung. Durch Erhöhung der Anzahl size an Ziehungen nähern sich die simulierten Momente den wahren Momenten \\(\\mu\\) und \\(\\Sigma\\) der Verteilung an.\n\n\nCode\nnp.random.seed(32)\ndf = pd.DataFrame(np.asarray(np.random.multivariate_normal(means_hist,\\\n                Sigma_hist, size = 50000)), columns=frame1.columns)\npd.DataFrame({'sim': df.mean().values, 'hist.': means_hist,\\\n             'difference':df.mean().values-means_hist}, \\\n             index=frame1.columns)\n\n\n\n\n\n\n\n\n\nsim\nhist.\ndifference\n\n\n\n\nDanone\n0.004407\n0.004711\n-0.000304\n\n\nSiemens\n0.004495\n0.005585\n-0.001090\n\n\nBASF\n0.010784\n0.011778\n-0.000994\n\n\nL'Oreal\n0.000882\n0.001505\n-0.000623\n\n\nAllianz\n-0.000273\n0.000947\n-0.001220\n\n\nTelecom Italia\n-0.007887\n-0.007870\n-0.000017\n\n\nBanco Santander\n-0.000349\n0.000191\n-0.000540\n\n\nTotal\n0.001659\n0.002032\n-0.000373\n\n\nBMW\n0.006899\n0.007962\n-0.001063\n\n\nVivendi\n-0.000316\n0.000421\n-0.000737\n\n\n\n\n\n\n\n\n\n7.2.4 Graphische Darstellung der historischen und der \\(M\\) simulierten Effizienzkurven\nAbschließend plotten wir die originale Effizienzkurve zusammen mit den \\(M\\) simulierten Effizienzkurven.\nDazu generieren wir zwei Listen-Okjekte: liste_Risk für die Portfoliovarianz und liste_Target für die erwartete Portfoliorendite. Beide Listen sollen final \\((1+M)\\) Elemente (jeweils 1-D Arrays der Dimension \\(K\\)) enthalten. Jede Effizienzkurve besteht dabei aus \\(K\\) Punkten.\nZunächst berechnen wir die historische Effizienzkurve über ef_front und weisen die 1-D (Dimension=K) Arrays Risk (für \\(\\sigma^2_P\\)) und Target (für \\(\\mu_P\\)) den beiden Listen zu. Danach simulieren wir für \\(i=1,..., M\\) auf Basis der Annahme einer multivariaten Normalverteilung für den Renditevektor die Werte der Eingabeparameter \\(\\theta_i=\\{\\mu_i, \\Sigma_i\\}\\) und berechnen jeweils die \\(M\\) Effizienzkurven. Die beiden Arrays mit den Charakteristiken der Effizienzkurven (\\(\\mu_{P,i}\\) und \\(\\sigma^2_{P,i}\\)) werden wiederum den Listen zugewiesen.\nAbschließend werden beide Listen in Arrays (d.h. \\((M+1)xK\\))-Matrizen transformiert und von der Funktion zurückgegeben.\n\n\nCode\n# function returns two lists with (1+M) elements; \n# each element is a 1-D array of dimension K;\n# K is the number of points on the ef: K different target \n# expected portfolio returns and portfolio return std's\ndef resampled_frontiers(M, means_hist, Sigma_hist):\n# M: number of Monte Carlo runs   \n    np.random.seed(42)\n    liste_Risk = []\n    liste_Target = []\n    # first, calculate the historical ef \n    _, Risk, Target = ef_front(means_hist, Sigma_hist)\n    # and append to the two lists\n    liste_Risk.append(Risk)\n    liste_Target.append(Target)\n    # now, calculate the M simulated ef's\n    for i in range(M):\n        df = pd.DataFrame(np.asarray(np.random.multivariate_normal(means_hist,\\\n                Sigma_hist, size = 110)), columns=frame1.columns)\n        means = df.mean().values\n        Sigma = df.cov().values\n        # ef_front returns: weights, risk, target return! \n        _, Risk, Target = ef_front(means, Sigma)\n        # and append to the lists\n        liste_Risk.append(Risk)\n        liste_Target.append(Target)\n    liste_Risk = np.array(liste_Risk)\n    liste_Target = np.array(liste_Target)\n    return liste_Risk, liste_Target \n\n\nDie folgende Funktion draw_efs zeichnet nun die historische zusammen mit den \\(M\\) simulierten Effizienzkurven. Hierfür werden die beiden Arrays der Funktion resampled_frontiers verwendet.\n\n\nCode\ndef draw_efs(M, means_hist, Sigma_hist):\n    Risk, Target = resampled_frontiers(M, means_hist, Sigma_hist)\n\n    fig1 = plt.figure(num=1, facecolor='w', figsize=(10, 5))\n    ax = fig1.add_subplot(111)\n    plt.plot(Risk[0,:], Target[0,:], 'g:', label='Historical frontier')\n    plt.plot(Risk[1,:], Target[1,:], 'b-', label='Resampled frontiers')\n    for i in range(2,M+1):\n        plt.plot(Risk[i,:], Target[i,:], 'b-')\n    plt.plot(np.sqrt(np.diagonal(Sigma_hist)), means_hist, 'rx', label='Asset')\n    for i, txt in enumerate(frame1.columns):\n        ax.annotate(txt, (np.sqrt(np.diagonal(Sigma_hist))[i],means_hist[i]))\n    plt.legend(loc=4,  frameon=True)\n    plt.xlabel('Standard deviation')\n    plt.ylabel('Expected return')\n    plt.title('Historical and M simulated efficient frontiers')\n    return plt.show()\n\n\nLassen Sie uns zum Abschluss zehn simulierte und die historische Effizienzkurve graphisch darstellen.\n\n\nCode\ndraw_efs(10, means_hist, Sigma_hist)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Berücksichtigung des Schätzrisikos: Portfolio-Resampling</span>"
    ]
  },
  {
    "objectID": "kapitel6a.html#lernvideos",
    "href": "kapitel6a.html#lernvideos",
    "title": "7  Berücksichtigung des Schätzrisikos: Portfolio-Resampling",
    "section": "7.3 Lernvideos",
    "text": "7.3 Lernvideos",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Berücksichtigung des Schätzrisikos: Portfolio-Resampling</span>"
    ]
  },
  {
    "objectID": "kapitel6a.html#literatur",
    "href": "kapitel6a.html#literatur",
    "title": "7  Berücksichtigung des Schätzrisikos: Portfolio-Resampling",
    "section": "7.4 Literatur",
    "text": "7.4 Literatur\nMichaud, R.O, Michaud, R.O., (2008). Efficient Asset Management: A Practical Guide to Stock Portfolio Optimization and Asset Allocation, 2nd Edition, Oxford University Press.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Berücksichtigung des Schätzrisikos: Portfolio-Resampling</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html",
    "href": "kapitel7a.html",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "",
    "text": "8.1 Einleitung\nWir haben gesehen, dass sich erwartete Renditen mit dem traditionellen Schätzansatz des arithmetischen Mittels nur sehr ungenau schätzen lassen. Zudem führen insbesondere Schätzfehler in den erwarteten Renditen typischerweise zu extremen und suboptimalen Portfoliogewichten. Daneben produziert die reine Anwendung des klassischen Mittelwert-Varianz Ansatzes häufig Portfolios mit extremen Gewichten. Eine Möglichkeit diese Problematik zu mildern besteht darin, ganz auf die Schätzung erwarteter Renditen bei der Portfoliokonstruktion zu verzichten. Dies führt uns zu den sogenannten risikogesteuerten (oder Riskbalancing basierten) Ansätzen der Assetallokation. Eine risikogesteuerte Portfoliokonstruktion fokusiert auf den Ausgleich der Risikoallokation zwischen den Assets im Portfolio, nicht auf den optimalen Trade-off zwischen Zielrendite und Risiko des Portfolios.\nZusätzlich zur Adressierung der Schätzfehlerproblematik scheint eine Assetklassen-Gewichtung entsprechend des eingegangenen Risikos auch vor dem Hintergrund der Erfahrungen aus der Finanzmarktkrise 2008-2009 sinnvoll zu sein. In der Finanzmarktkrise konnten auch bei gut diversifizierten Portfolios z.T. hohe Verluste und Wertschwankungen beobachtet werden. Infolgedessen wird auch die Wirkung der Diversifikation kritischer gesehen, die in Krisenzeiten aufgrund der dann steigenden Korrelationen geringer ausfällt. Ferner erscheint der Diversifikationseffekt bei zunehmender Anzahl an Assetklassen in den Portfolios begrenzt, sofern diese zusätzlichen Assetklassen eine geringe Liquidität und Transparenz aufweisen, denn hierdurch können zusätzliche, unerwünschte Risiken entstehen.\nVor diesem Hintergrund (und aufgrund der zudem zu beobachtenden unzureichenden Verlässlichkeit langfristiger Renditeprognosen) wurden Steuerungskonzepte entwickelt, die nicht auf der Prognose von erwarteten Renditen, sondern nur auf Volatilitäts- und Korrelationsannahmen basieren. Grundsätzlich orientiert sich dabei die Assetallokation am Risiko. Beispielsweise kann eine Reduzierung des Gewichts einer Assetklasse in den Fällen vorgenommen werden, in denen ihre Volatilität bzw. ihre Korrelation zu einer anderen Assetklasse steigt.\nAls Konzept zum Risikoausgleich wurde u.a. der sogenannte Risk Parity-Ansatz entwickelt. Das Ziel besteht dabei, das Risiko der jeweiligen Assetklassen möglichst auszugleichen, so dass nicht eine einzelne Assetklasse (z.B. Aktien) einen Verlust bei einem gesamten Portfolio verursacht. Innerhalb des Risk Parity-Ansatzes lassen sich die beiden Ausprägungen Equal-Risk-Budget- (ERB-) Strategie und Equal-Risk-Contribution- (ERC-) Strategie unterscheiden. Zu alternativen risikobasierten Assetallokations-Konzepten zählen der Global-Minimum-Varianz-Ansatz und der Maximum-Diversification-Ansatz. Die beiden letzteren Ansätze zielen allerdings nicht direkt auf gleiche Risikobudgets bzw. Risikobeiträge ab. Eine weitere Möglichkeit zum Risikoausgleich besteht darin, ein “naives” Portfolio zu bilden, bei dem die Assetklassen gleich gewichtet sind (Equally-Weighted-Ansatz).\nNach der Einleitung wird im nächsten Kapitel zunächst auf die Grundlagen des Risk Parity-Ansatzes eingegangen, bevor anschließend die Equal-Risk-Budget- (ERB-) Strategie und die Equal-Risk-Contribution- (ERC-) Strategie vorgestellt werden. Daran schließt sich die Darstellung der alternativen Riskbalancing-Konzepte Equally-Weighted-, Global-Minimum-Varianz- und Maximum-Diversification-Ansatz an. Nach einer Darstellung der jeweiligen Konzepte wird abschließend im Rahmen einer Fallstudie eine vergleichende Analyse der fünf Ansätze durchgeführt.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html#der-risk-parity-ansatz",
    "href": "kapitel7a.html#der-risk-parity-ansatz",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "8.2 Der Risk Parity-Ansatz",
    "text": "8.2 Der Risk Parity-Ansatz\n\n8.2.1 Grundlagen\nEine traditionelle, kapitalbasierte Aufteilung von z.B. 50% Aktienanteil und 50% Anleihenanteil im Portfolio kann dazu führen, dass die Rendite und das Risiko des Portfolios maßgeblich von der Aktienrendite beeinflusst werden, während die Anleihen keinen besonderen Einfluss haben. Somit liegt tatsächlich keine wirkliche Diversifizierung des Portfolios vor. Beim Risk Parity-Ansatz wird dagegen im Vergleich zur traditionellen Assetallokation deutlich weniger in Aktien und mehr in andere Assetklassen investiert. Sollen bei einem Aktien-/Anleihenportfolio beide Assetklassen gleichermaßen zum Gesamtrisiko beitragen (Balanced Risk Portfolio), so müssten Aktien entsprechend einen geringeren Anteil zugunsten der Anleihen im Portfolio enthalten. Somit kann das Risikobudget des Portfolios breiter über andere Anlagen gestreut werden. Entsprechend können Portfoliorenditen erwartet werden, die geringere Volatilitäten aufweisen.\nAnders als z.B. die Assetallokation gemäß Portfoliotheorie benötigt der Risk Parity-Ansatz grundsätzlich keine Prognosen bezüglich der erwarteten Renditen. Allerdings müssen ebenfalls Risikokennzahlen und - je nach gewähltem Ansatz - Korrelationen geschätzt werden. Letzteres gilt nicht für die Equal-Risk-Budget- (ERB-) Strategie als erste Ausprägung des Risk Parity-Ansatzes, da die Gewichtung der einzelnen Anlagen im Portfolio in Abhängigkeit von ihrer inversen Volatilität vorgenommen wird. Dagegen sind Korrelationsschätzungen im Rahmen der zweiten Ausprägung erforderlich. Hierbei handelt es sich um die Equal-Risk-Contribution- (ERC-) Strategie.\nWir starten mit der folgenden Definition.\nDefinition: Ein Portfolio das die Bedingung\n\\[\\begin{equation*}\nw_1\\partial_1\\sigma_p = \\cdots = w_N\\partial_N\\sigma_p,\\quad\n\\sigma_p=\\sqrt{w\\Sigma w^{T}},\\quad\n\\partial_n\\sigma_p = \\frac{\\partial\\sigma_p}{\\partial w_n},\n\\end{equation*}\\] erfüllt, wird als Risk Parity Portfolio bezeichnet.\nDie zugrundeliegende Idee besteht darin, eine gleiche (oder allgemeiner: eine spezifische Ziel-) Risikobudgetierung über alle Portfolioanlagen hinweg zu erreichen. Es können verschiedene Risikomaße verwendet werden, wir beschränken uns hier auf die Standardabweichung \\(\\sigma\\). Bei der Risikoparität geht es darum, dass jeder Vermögenswert in gleicher Weise zur Gesamtvolatilität des Portfolios beiträgt. Dies wird erreicht, indem eine Identität des Risikobeitrags (RB) aller Assets gefordert wird. Der Ausdruck \\(\\frac{\\partial\\sigma_p}{\\partial w_n}\\) bezeichnet dabei den marginalen Risikobeitrag (MRB) des n-ten Assets. Der MRB kennzeichnet das zusätzliche Portfoliorisiko, das durch eine infinitesimal kleine Erhöhung des Anteils des n-ten Assets im Portfolio entsteht und ist formal definiert als die Ableitung der Standardabweichung der Portfoliorendite \\(\\sigma_p\\) nach dem Anteil \\(w_n\\). Der RB wiederum ergibt sich als das Produkt von Anteilsgewicht und MRB. Es gelten somit die folgenden Beziehungen:\nDie Standardabweichung der Portfoliorendite \\(r_p\\) ist bekanntermaßen gegeben durch (Beachten Sie: \\(w\\) ist ein Zeilenvektor):\n\\[ \\sigma_p=\\sqrt{w \\Sigma w^{T}} \\]\nDer Risikobeitrag des n-ten Assets errechnet sich als:\n\\[ (1) \\quad RB_n= w_n \\cdot MRB_n \\\n= w_n \\cdot \\partial_{n}\\sigma_p\\]\nFür den MRB gilt:\n\\[  MRB_n= \\frac{(\\Sigma w^{T})_{n}}{\\sigma_p} \\]\nD.h., der MRB berechnet sich indem die Varianz-Kovarianzmatrix der Assetrenditen mit dem Anteilsvektor zeilenweise multipliziert und aufsummiert wird. Das n-te Element des (Nx1)-Vektors \\(\\Sigma w^{T}\\) skaliert mit der Portfoliostandardabweichung ergibt dann den marginalen Risikobeitag des n-ten Assets.\n\\[ (2) \\quad MRB_n=\\frac{\\Sigma^N_{j=1}w_j \\cdot Cov(r_n,r_j)}{\\sigma_p}=\\frac{Cov(r_n,r_p)}{\\sigma_p} \\]\nEs lässt sich zeigen, dass die Summe der N Risikobeiträge der Portfoliostandardabweichung entspricht:\n\\[ \\sigma_p=\\sum_{n=1}^{N} RB_{n} \\]\nBezieht man den (absoluten) Risikobeitrag RB auf das Gesamtrisiko dess Portfolios \\((\\sigma_p)\\), so erhält man den relativen Beitrag zum Gesamtrisiko (rRB):\n\\[ (3) \\quad rRB_n =\\frac{RB_n}{\\sigma_p}=w_n \\cdot \\frac{Cov(r_n,r_p)}{\\sigma^2_p}=w_n \\cdot \\beta_n, \\]\nmit \\(\\beta_n=\\) Betafaktor des n-ten Assets bezogen auf die Portfoliorendite.\n\n\n8.2.2 Equal-Risk-Budget- (ERB-) Strategie\nDas Ziel dieser Strategie ist, dass die Risikobudgets für alle Anlagen im Portfolio identisch sind. Es handelt sich hierbei um eine Vereinfachung der oben eingeführten allgemeinen Definition einer Risk Parity Strategie. Unter der Annahme, dass die Standardabweichung das Risikomaß darstellt, werden Risikobudgets der jeweiligen Anlagen als Produkt aus Standardabweichung und Portfolioanteil definiert. Anders als bei den Risikobeiträgen werden somit die Korrelationen zwischen den einzelnen Anlagen nicht mit einbezogen, bzw. es wird angenommen, dass die Korrelationen sämtlicher Assetrenditen mit der Portfoliorendite identisch sind. Für den ERB-Ansatz gilt somit in leichter Abkehr der oben eingeführten Definition die folgende Zielsetzung für alle Anlagen 1 bis N in einem Portfolio (Beachten Sie: das Risikobudget - das Produkt aus Standardabweichung und Portfolioanteil - kann als Risikobeitrag bei perfekter Korrelation interpretiert werden):\n\\[ w_1\\cdot \\sigma_1=w_2 \\cdot \\sigma_2=...=w_N \\cdot \\sigma_N \\]\nFür ein Asset n ergibt sich der Anteil \\(w_n\\) im ERB-Portfolio in allgemeiner Form:\n\\[ w^{ERB}_n=\\frac{1/\\sigma_n}{\\Sigma^N_{j=1}1/\\sigma_j} \\]\nBei der ERB-Strategie werden die Gewichte der Assets somit umgekehrt proportional zu ihren Volatilitäten verteilt.\n\n\n8.2.3 Equal-Risk-Contribution- (ERC-) Strategie\nZiel der Equal-Risk-Contribution- (ERC-) Strategie ist die Gleichheit der Risikobeiträge der einzelnen Assets zum Gesamtrisiko \\((\\sigma_p)\\) des Portfolios. Dies entspricht genau der im Abschnitt Grundlagen eingeführten Definition einer Risk Parity Strategie. Wie bereits oben gezeigt, lässt sich der absolute Risikobeitrag eines Assets n zum Gesamtrisiko wie folgt bestimmen:\n\\[  MRB_n= \\frac{(\\Sigma w^{T})_{n}}{\\sigma_p} \\]\nDer Vektor der marginalen Risikobeiträge \\(\\partial_{n}\\sigma_p\\) über alle Assets ergibt sich folglich durch:\n\\[ (4) \\quad c(w)=\\frac{\\Sigma w^{T}}{\\sigma_p} \\]\nZudem wurde bereits erwähnt, dass die Summe der RBs dem Gesamtrisiko \\((\\sigma_p)\\) gleicht, und der RB eines Assets n den mit dem Anteil \\(w_n\\) gewichteten MRB entspricht. Sollen daher alle RBs identisch sein, muss folglich gelten:\n\\[ \\frac{\\sigma_p}{N}=w_n \\cdot MRB_n \\quad \\text{für} \\quad n=1, ..., N. \\]\nSomit können die optimalen Anteile \\(w^{ERC}_n\\) im ERC-Portfolio durch die numerische Minimierung der folgenden Zielfunktion bestimmt werden:\n\\[ \\underset{w}{\\operatorname{min}} \\sum_{n=1}^{N} [\\frac{\\sigma_p}{N} −  w_{n}⋅c(w)_{n}]^{2} \\]\n\\[ \\textrm{u. d. Nb.} \\quad \\sum_{n=1}^{N} w_{n} = 1 \\quad \\textrm{und} \\quad 1 \\geq w_{n} \\geq 0, \\]\nwobei \\(c(w)_{n}\\) das n-te Element des Vektors \\(c(w)\\) bezeichnet.\nIm verallgemeinerten Fall einer gewünschten, nicht unbedingt gleichen Zielrisikoallokation \\(w_{target_{n}}\\) lautet die zu minimierende Funktion:\n\\[ (5) \\quad \\underset{w}{\\operatorname{argmin}} \\sum_{n=1}^{N} [w_{target_{n}}\\cdot \\sigma_p - w_{n}⋅c(w)_{n}]^{2} \\]\nDa im ERC-Portfolio die absoluten Risikobeiträge identisch sind, gilt dies natürlich auch für die relativen Risikobeiträge \\((RB/\\sigma_p)\\) der N einzelnen Assets. Es folgt (siehe Gleichung (3) oben):\n\\[ \\textrm{Relativer Risikobeitrag im ERC-Portfolio} = w^{ERC}_n \\cdot \\frac{Cov(r_n,r_p)}{\\sigma^2_p}=w^{ERC}_n \\cdot \\beta^{ERC}_n=\\frac{1}{N},\\]\nmit \\(\\beta^{ERC}_n=\\) Betafaktor des Assets n in Bezug auf das ERC-Portfolio. Das Anteilsgewicht \\(w^{ERC}_n\\) kann dann auch wie folgt ausgedrückt werden:\n\\[ w^{ERC}_n=\\frac{1}{N \\cdot \\beta^{ERC}_n}, \\quad \\text{wobei für ein ERC-Portfolio gilt:} \\quad \\Sigma^N_{n=1}w^{ERC}_n=1. \\]\nSomit ist der Anteil eines Assets umgekehrt proportional zu seinem Betafaktor. Je höher das Beta, desto geringer die Gewichtung im Portfolio und umgekehrt. Entsprechend werden Assets mit einer hohen (geringen) Standardabweichung oder einer hohen (geringen) Korrelation mit der Portfoliorendite geringer (höher) gewichtet.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html#alternative-risikogesteuerte-ansätze",
    "href": "kapitel7a.html#alternative-risikogesteuerte-ansätze",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "8.3 Alternative risikogesteuerte Ansätze",
    "text": "8.3 Alternative risikogesteuerte Ansätze\nAbzugrenzen ist der Risk Parity-Ansatz von weiteren Verfahren, die zur Assetallokation ebenfalls auf die Ermittlung von Renditen verzichten. Dazu zählt insbesondere der Global-Minimum-Varianz-Ansatz, mit dem die risikominimale Kombination der zur Verfügung stehenden Anlagen ermittelt werden kann. Darüber hinaus zählt auch der Maximum-Diversification-Ansatz zu den risikobasierten Assetallokations-Konzepten. Schließlich wird noch die als “naiver” Ansatz zu bezeichnende Equally-Weighted-Strategie als Vergleichsmaßstab herangezogen.\n\n8.3.1 Equally-Weighted- (EW-) Ansatz\nDer Equally-Weighted-Ansatz kann als einfachste Form der Diversifikation eines Portfolios bezeichnet werden, weil die Gewichtung jedes der N Assets in einem Portfolio auf die folgende Weise bestimmt wird:\n\\[ w^{EW}_n=\\frac{1}{N} \\]\nBei diesem Ansatz spielt die Art der Anlage bzw. welche Assetklassen in das Portfolio aufgenommen werden, keine Rolle. Gleiches gilt auch für die Rendite- und Risikokennzahlen der einbezogenen Assets. Daher ist zu empfehlen, diese Strategie allenfalls als Benchmark zur Beurteilung der Performance von Assetallokations-Strategien heranzuziehen. Wie oben bereits erwähnt, würde z.B. der ERC-Ansatz nur in dem Extremfall identischer Korrelationen zwischen den in das Portfolio einbezogenen Assets sowie gleicher Standardabweichungen der Assets zu einer gleichgewichteten Assetallokation führen. Sind die Risiken in einem Portfolio jedoch unterschiedlich verteilt, führt der Equally-Weighted-Ansatz letztlich zu einer Risikokonzentration, denn alle Assets erhalten das gleiche Gewicht, d.h., sowohl das Asset mit dem höchsten als auch das mit dem geringsten Risiko.\n\n\n8.3.2 Global-Minimum-Varianz- (GMV) Ansatz\nDer Global-Minimum-Varianz-Ansatz resultiert aus portfoliotheoretischen Überlegungen, wobei dasjenige effiziente Portfolio gesucht wird, das das minimale Risiko aufweist. Entsprechend kann dieses sog. Global-Minimum-Varianz-Portfolio durch partielle Ableitung der Funktion der Portfoliovarianz nach den Gewichten der einzelnen Assets n im Portfolio \\((w_n)\\) und anschließende Nullsetzung ermittelt werden: \\(\\frac{\\partial{\\sigma^2_p}}{\\partial{w_n}}\\)\n\nFall 1: geschlossene Lösung\n\nDie Gewichte des GMVP lassen sich analytisch bestimmen sofern es keine Nebenbedingungen in Form von Ungleichungen wie dem Leerverkaufsverbot oder Bestandsgrenzen gibt. Die Gewichte des GMVP resultieren dann als Lösung des folgenden Minimierungsproblems:\n\\[\\begin{align*}\n\\min_{w} &\\quad w^{T}\\Sigma w \\\\\n\\text{u. d. Nb.} &\\quad w^{T}\\iota = 1,\n\\end{align*}\\]\nwobei \\(\\iota\\) den Einheitsvektor bezeichnet. Als geschlossene Lösung ergibt sich:\n\\[\\begin{equation*}\n(6) \\quad w^{GMV} = \\frac1{\\iota^{T}\\Sigma^{-1}\\iota}\\Sigma^{-1}\\iota.\n\\end{equation*}\\]\nBeachten Sie, dass \\(w^{GMV}\\) nicht vom Vektor der erwarteten Renditen \\(\\mu\\) abhängt, d.h., das GMVP kann ohne Kenntnis von \\(\\mu\\) ermittelt werden.\n\nFall 2: numerische Lösung\n\nIn der Realität ist es vielen institutionellen Investoren aufgrund von Anlagerestriktionen häufig nicht möglich, Leerverkäufe (Short Positionen) einzugehen. Um diesen Umstand zu berücksichtigen, muss die Nichtnegativitätsbedingung der Gewichte zum Optimierungsproblem hinzugefügt werden. Eine geschlossene Lösung ist dann nicht mehr möglich.\n\\[\\begin{align*}\n\\min_{w} &\\quad w^{T}\\Sigma w \\\\\n\\text{u. d. Nb.} &\\quad w^{T}\\iota = 1 \\quad \\textrm{und} \\quad 1 \\geq w_{n} \\geq 0\n\\end{align*}\\]\nGrafisch kann das GMV-Portfolio wie in der folgenden Abbildung dargestellt bestimmt werden.\n\nDie Grafik zeigt, dass unter Risiko- und Renditegesichtspunkten Portfolios auf der Kapitalmarktlinie effizienter sind als das GMVP. Soll z.B. das gesamte Portfoliorisiko dem des GMVP entsprechen, so lässt sich dieses auch durch eine Kombination des Marktportfolios M mit der risikolosen Anlage \\(r_f\\) erreichen, wobei aber hier die erwartete Rendite höher ausfällt.\n\n\n8.3.3 Maximum-Diversification- (MD-) Ansatz\nZur Maximierung des Diversifikationseffektes in einem Portfolio kann der sogenannte Maximum-Diversification-Ansatz herangezogen werden, der auch als “Most-Diversified-Ansatz” bezeichnet werden kann. Dabei wird der Diversifikationseffekt mit Hilfe der Diversification Ratio (DR) ermittelt (siehe Choueifaty et al., 2013):\n\\[\\begin{equation*}\nDR=\\frac{\\sigma^{T}w}{\\sqrt{w^{T}\\Sigma w}}.\n\\end{equation*}\\]\nIm Zähler der Diversification Ratio steht somit der gewichtete Durchschnitt der Standardabweichungen der einzelnen Assets im Portfolio, während im Nenner die Standardabweichung des Portfolios angegeben wird. Wird ein Portfolio ohne Leerverkaufsmöglichkeiten (“Long-only”) betrachtet und ist für mindestens 1 Anlage im Portfolio \\(\\sigma_n&gt;0\\), so gilt: \\(DR\\geq 1.\\) Falls sämtliche Korrelationen zwischen den Anlagen jeweils 1 betragen, würden sich Zähler und Nenner der Diversification Ratio entsprechen. Andernfalls ergibt sich aufgrund des Diversifikationseffektes im Nenner ein geringerer Wert als im Zähler. Somit misst die Diversification Ratio den Diversifikationserfolg von Anlagen, die nicht perfekt miteinander korreliert sind. Letztlich wird damit der Abstand zwischen zwei Volatilitätsmaßen desselben Portfolios maximiert. Im Zähler wird das Portfoliorisiko für den Fall ohne Diversifikation und im Nenner das (tatsächliche) Risiko mit Diversifikation angegeben.\nDas Maximum-Diversification-Portfolio (MD) stellt dasjenige Portfolio dar, das die Diversification Ratio maximiert:\n\\[\\begin{equation*}\n\\max_{w} \\quad \\frac{\\sigma^{T}w}{\\sqrt{w^{T}\\Sigma w}}.\n\\end{equation*}\\]\nMit der Budgetrestriktion \\((\\Sigma^N_{n=1}w_n=1)\\) als alleinige Nebenbedingung erhält man die geschlossene Lösung:\n\\[\\begin{equation*}\nw^{MD} = \\frac1{\\iota^{T}\\Sigma^{-1}\\sigma}\\Sigma^{-1}\\sigma.\n\\end{equation*}\\]\nHinzufügen weiterer Nebenbedingungen (z.B. Bestandsgrenzen, Leerverkaufsverbot) erfordert eine numerische Optimierung.\nFür das resultierende Portfolio lässt sich zeigen, dass sämtliche Anlagen im Portfolio mit einem Anteil von \\(w_n&gt;0\\) eine identische (positive) Korrelation mit dem MD-Portfolio aufweisen. Grundsätzlich kann in diesem Fall die Korrelation für ein Portfolio P mit dem MD-Portfolio als Quotient der jeweiligen Diversification Ratios ausgedrückt werden (Choueifaty und Coignard, 2008, S. 42):\n\\[ Corr(r_p, r_{MD})=\\frac{DR_p}{DR_{MD}}, \\]\nmit\n\\[DR_p=\\textrm{Diversification Ratio des Portfolios P} \\] \\[DR_{MD}=\\textrm{Diversification Ratio des Maximum-Diversification-Portfolios} \\]\nBesteht ein Portfolio aus nur einer Anlage n, so ergibt sich hierfür eine Diversification Ratio von 1, so dass in diesem Fall für alle Portfolios (bzw. Anlagen n) im Maximum-Diversification-Portfolio jeweils gilt:\n\\[ Corr(r_n,r_{MD})=\\frac{1}{DR_{MD}}, \\quad \\textrm{falls} \\quad w_n&gt;0 \\]\nSofern \\(w_n=0\\), gilt:\n\\[ Corr(r_n,r_{MD})\\geq\\frac{1}{DR_{MD}}. \\]\nWie oben gezeigt wurde, kann die Korrelation zwischen einer Anlage n und einem Portfolio P auch wie folgt ausgdrückt werden:\n\\[ MRB_n=Corr(r_n,r_p)\\cdot \\sigma_n \\iff Corr(r_n,r_p)=\\frac{MRB_n}{\\sigma_n}=\\frac{1}{\\sigma_n}\\cdot \\frac{\\partial{\\sigma_p}}{\\partial w_n}\\]\nSomit gilt für alle Anlagen i und j im MD-Portfolio:\n\\[ \\frac{1}{\\sigma_i}\\cdot \\frac{\\partial{\\sigma_{MD}}}{\\partial w_i}=\n\\frac{1}{\\sigma_j}\\cdot \\frac{\\partial{\\sigma_{MD}}}{\\partial w_j}\\]\nDer Quotient aus \\(MRB_n\\) und \\(\\sigma_n\\) kann als “Relative Marginal Volatility” oder “Scaled Marginal Volatility” interpretiert werden (vgl. Demey et al., 2010, S. 14 sowie Roncalli, 2014, S. 173).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html#beginn-der-fallstudie",
    "href": "kapitel7a.html#beginn-der-fallstudie",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "8.4 Beginn der Fallstudie",
    "text": "8.4 Beginn der Fallstudie\nDie vorgestellten Strategien sollen anhand eines aus den 4 Assets A, B, C und D bestehenden Beispielportfolios näher beleuchtet werden. Für die Standardabweichungen und die Korrelationen zwischen den Renditen der einzelnen Assets werden die folgenden Beispieldaten Stdev und CorrMatrix zugrunde gelegt:\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport numpy.linalg as la\nfrom scipy.optimize import minimize\nTOLERANCE = 1e-15\n\nimport warnings\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")\n\nStdev = np.array([0.18, 0.11, 0.16, 0.24])\nCorrMatrix = np.array([[1.00, 0.40, -0.10, 0.30],\n                       [0.40, 1.00, 0.10, 0.20],\n                       [-0.10, 0.10, 1.00, -0.15],\n                       [0.30, 0.20, -0.15, 1.00]])\n\n\nHieraus lassen sich die folgenden Kovarianzen ableiten.\n\n\nCode\nSigma = np.diag(Stdev) @ CorrMatrix @ np.diag(Stdev)\nSigma\n\n\narray([[ 0.0324 ,  0.00792, -0.00288,  0.01296],\n       [ 0.00792,  0.0121 ,  0.00176,  0.00528],\n       [-0.00288,  0.00176,  0.0256 , -0.00576],\n       [ 0.01296,  0.00528, -0.00576,  0.0576 ]])\n\n\n\n8.4.1 Equal-Risk-Budget-Strategie\nWir beginnen mit der Equal-Risk-Budget-Strategie. Die Anteilsgewichte ergeben sich umgekehrt proportional zu den Asset-Volatilitäten: \\(w^{ERB}_n=\\frac{1/\\sigma_n}{\\Sigma^N_{j=1}1/\\sigma_j}\\) und das Risikobudget ist definiert als Produkt von Assetrendite-Standardabweichung und Anteilsgewicht. Die Bestimmung der jeweiligen Anteile \\(w_n\\) der einzelnen Assets am ERB-Portfolio kann mit Hilfe der nachfolgenden Tabelle gezeigt werden.\n\n\nCode\n(1/Stdev)/np.sum(1/Stdev)\n\n\narray([0.22166247, 0.3627204 , 0.24937028, 0.16624685])\n\n\n\n\nCode\nAssets=['A', 'B', 'C', 'D']\ndf=pd.DataFrame({'Sigma': Stdev, '1/Sigma': 1/Stdev,\\\n              'Anteil': (1/Stdev)/np.sum(1/Stdev), \\\n              'Risikobudget': Stdev*(1/Stdev)/np.sum(1/Stdev)},\\\n             index=Assets) \ndf.loc['Summe',1:]= df.sum(axis=0)\ndf\n\n\n\n\n\n\n\n\n\nSigma\n1/Sigma\nAnteil\nRisikobudget\n\n\n\n\nA\n0.18\n5.555556\n0.221662\n0.039899\n\n\nB\n0.11\n9.090909\n0.362720\n0.039899\n\n\nC\n0.16\n6.250000\n0.249370\n0.039899\n\n\nD\n0.24\n4.166667\n0.166247\n0.039899\n\n\nSumme\nNaN\n25.063131\n1.000000\n0.159597\n\n\n\n\n\n\n\nSomit ergeben sich gemäß ERB-Strategie für die vier Anlagen die folgenden Gewichte im Portfolio:\n\\[ w^{ERB}_A=22,1662\\%, \\quad w^{ERB}_B=36,2720\\%, \\quad w^{ERB}_C=24,9370\\%, \\quad w^{ERB}_D=16,6247\\%.\\]\nErkenbar ist an diesen Werten, dass offensichtlich Assets mit einem höheren (geringeren) Risiko untergewichtet (übergewichtet) werden. Insofern wird eher in risikoärmere Assets investiert, wobei diese Assets gleichzeitig dazu tendieren ein relativ geringes Beta auzuweisen.\nDas Risikobudget als die mit den Portfolioanteilen gewichtete Standardabweichung beträgt somit für jede Anlage 3,9899%. Unter Berücksichtigung dieser Werte lässt sich die gewichtete Varianz-Kovarianz-Matrix (\\(w^{T}\\Sigma w\\)) bestimmen.\n\n\nCode\ngewicht_erb=(1/Stdev)/np.sum(1/Stdev)\nwSigma=pd.DataFrame({'A': (Sigma[:,0]*gewicht_erb[0]*gewicht_erb),\\\n                     'B': (Sigma[:,1]*gewicht_erb[1]*gewicht_erb),\\\n                     'C': (Sigma[:,2]*gewicht_erb[2]*gewicht_erb),\\\n                     'D': (Sigma[:,3]*gewicht_erb[3]*gewicht_erb)},\\\n                    index=Assets, columns=Assets) \nwSigma.columns.name='Gewichtete Kovarianzen' \nwSigma.loc['Summe',:]= wSigma.sum(axis=0)\nwSigma.loc[:,'Summe']= wSigma.sum(axis=1)\nwSigma\n\n\n\n\n\n\n\n\nGewichtete Kovarianzen\nA\nB\nC\nD\nSumme\n\n\n\n\nA\n0.001592\n0.000637\n-0.000159\n0.000478\n0.002547\n\n\nB\n0.000637\n0.001592\n0.000159\n0.000318\n0.002706\n\n\nC\n-0.000159\n0.000159\n0.001592\n-0.000239\n0.001353\n\n\nD\n0.000478\n0.000318\n-0.000239\n0.001592\n0.002149\n\n\nSumme\n0.002547\n0.002706\n0.001353\n0.002149\n0.008756\n\n\n\n\n\n\n\nAus der Tabelle kann die Varianz des ERB-Portfolios abgelesen werden. Sie beträgt in diesem Beispiel 0,0087557. Entsprechend beläuft sich die Standardabweichung des ERB-Portfolios auf 9,3572%:\n\\[ \\sigma_{ERB}=\\sqrt{0,0087557}=9,35720\\%.\\]\nIn der nachfolgenden Tabelle werden die absoluten Risikobeiträge (RB), die relativen Risikobeiträge (rRB), die Kovarianzen der einzelnen Assetrenditen mit der Portfoliorendite, die auf das ERB-Portfolio bezogenen Betafaktoren und die marginalen Risikobeiträge (MRB) dargestellt (die Berechnung erfolgt anhand der Formeln (1)-(3) aus dem Grundlagen Abschnitt):\n\n\nCode\n# Berechnung der absoluten Risikobeitrags: Formel (1) und (2)\nrb=np.zeros(4)\nfor i in range(4):\n    rb[i]=(gewicht_erb[i]*Sigma[i,:]*np.asmatrix(gewicht_erb).T)/0.093572\n\n# Berechnung der relativen Risikobeitrags\nrrb=np.zeros(4)\nfor i in range(4):\n    rrb[i]=rb[i]/np.sum(rb)\n    \n# Berechnung der Kovarianz der Assetrendite mit der Portfoliorendite: Formel (3)\ncov_ri_rp=np.zeros(4)\nfor i in range(4):\n       cov_ri_rp[i]=Sigma[i,:]*np.asmatrix(gewicht_erb).T\n\n# Berechnung des Betas der Assetrendite mit der Portfoliorendite\nbeta_ri=np.zeros(4)\nfor i in range(4):\n        beta_ri[i]=cov_ri_rp[i]/0.093572**2\n\n# und nun noch der marginale Risikobeitrag\nmrb=np.zeros(4)\nfor i in range(4):\n        mrb[i]=rb[i]/gewicht_erb[i]\n        \n# Abschließend stellen wir die Ergebnisse zur ERB-Strategie \n# übersichtlich in einer Tabelle dar\n\nergebnisse_erb=pd.DataFrame({'absoluter RB (%)': np.round(rb*100,4), \\\n                             'relativer RB (%)': np.round(rrb*100,4),\n                             'Cov(r_i,r_p)':np.round(cov_ri_rp,4),\n                             'Beta': np.round(beta_ri,4),\n                             'MRB (%)': np.round(mrb*100,4)},index=Assets) \nergebnisse_erb.loc['Summe',:2]= ergebnisse_erb.sum(axis=0)\nergebnisse_erb\n\n\n\n\n\n\n\n\n\nabsoluter RB (%)\nrelativer RB (%)\nCov(r_i,r_p)\nBeta\nMRB (%)\n\n\n\n\nA\n2.7221\n29.0909\n0.0115\n1.3124\n12.2804\n\n\nB\n2.8922\n30.9091\n0.0075\n0.8521\n7.9737\n\n\nC\n1.4461\n15.4545\n0.0054\n0.6197\n5.7991\n\n\nD\n2.2968\n24.5455\n0.0129\n1.4764\n13.8154\n\n\nSumme\n9.3572\n100.0000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nAus den Ergebnissen der Tabelle ist erkennbar, dass für die einzelnen Assets unterschiedliche Risikobeiträge ermittelt werden können. Diese Unterschiede sind darauf zurückzuführen, dass bei der Ermittlung der Anteile der jeweiligen Assets am Portfolio die Korrelationen zwischen den Renditen der sich im Portfolio befindenden Assets nicht berücksichtigt werden. Somit spielen dabei Diversifikationseffekte offenbar keine Rolle. Dennoch kommen diese Effekte bei den Ergebnissen in der Tabelle zum Tragen.\nDie jeweils gewichteten Betafaktoren ergeben in der Summe den Wert 1:\n\\[ \\beta^{ERB}_p= \\Sigma^N_{n=1} w^{ERB}_n \\cdot \\beta^{ERB}_n \\]\n\\[ = 22,1662\\% \\cdot 1,3124 + 36,2720\\% \\cdot 0,8522 + 24,9370\\% \\cdot 0,6197 + 16,6247\\% \\cdot 1,4765 \\]\n\\[ = 0,2909 + 0,3091 + 0,1546 + 0,2455 = 1,0000 \\]\nDiese Rechnung zeigt, dass die einzelnen gewichteten Betas den relativen Risikobeiträgen entsprechen.\n\n\n8.4.2 Equal-Risk-Contribution-Strategie\nNun implementieren wir die ERC-Strategie für die Beispieldaten. Zur numerischen Bestimmung der optimalen Gewichte des ERC-Portfolios über scipy.optimize definieren wir drei Funktionen: - calulate_portfolio_var berechnet die Varianz der Portfoliorendite \\(\\sigma^2_p\\) - calculate_risk_contribution berechnet den Vektor der Risikobeiträge gemäß \\(w_n\\frac{(\\Sigma w^{T})_n}{\\sigma_p} \\quad \\text{für}\\quad n=1, ..., N\\) - risk_contribution_objective implementiert schließlich die Zielfunktion des allgemein formulierten Minimierungsproblems in Gleichung (5)\nDie berücksichtigten Nebenbedingungen sind die Budget-Restriktion und das Verbot von Leerverkäufen, d.h., die Gewichte müssen zwischen 0 und 1 liegen und sich auf 1 summieren.\n\n\nCode\n# ERC Optimierung: Definition benötigter Funktionen\ndef calculate_portfolio_var(w,Sigma):\n    # Funktion zur Berechnung der Portfoliorenditevarianz\n    w = np.matrix(w) # w ist ein Zeilenvektor! \n    return (w*Sigma*w.T)[0,0]\n\n\ndef calculate_risk_contribution(w,Sigma):\n    # Funktion zur Berechnung des Risikobeitrags\n    w = np.matrix(w)\n    sigma_p = np.sqrt(calculate_portfolio_var(w,Sigma))\n    # Marginaler Risikobeitrag\n    MRB = Sigma*w.T\n    # Risikobeitrag\n    RB = np.multiply(MRB,w.T)/sigma_p\n    return RB\n\ndef risk_contribution_objective(x,pars):\n    # x bezeichnet den Vektor der gesuchten Portfoliogewichte\n    # die Varianz-Kovarianzmarix ist der erste Bestandteil des Arrays der gegebenen Parameter\n    Sigma = pars[0]\n    # der zweite Bestandteil enthält die Zielrisikoallokation\n    x_t = pars[1] \n    \n    sig_p =  np.sqrt(calculate_portfolio_var(x,Sigma)) # Portfoliorisiko\n    risk_target = np.asmatrix(np.multiply(sig_p,x_t))\n    asset_RC = calculate_risk_contribution(x,Sigma)\n    J = sum(np.square(asset_RC-risk_target.T))[0,0] # Summe der quadrierten Fehler\n    return J\n\ndef total_weight_constraint(x):\n    return np.sum(x)-1.0\n\ndef long_only_constraint(x):\n    return x\n\nx_t = [0.25, 0.25, 0.25, 0.25] # Zielrisikoallokation als Prozentsatz des Gesamtrisikos\ngewicht_ew = np.tile(1.0/4, 4) # Gleichgewichtung als Startvektor \n\n# Nebenbedingungen der Optimierung\ncons = ({'type': 'eq', 'fun': total_weight_constraint},\n{'type': 'ineq', 'fun': long_only_constraint})\n\n# Optimierung\nres= minimize(risk_contribution_objective, gewicht_ew, args=[Sigma,x_t], method='SLSQP',tol=TOLERANCE,constraints=cons, options={'disp': False})\ngewicht_erc = np.array(res.x)\n\n\n\n\nCode\ngewicht_erc\n\n\narray([0.20500842, 0.31247095, 0.31024402, 0.17227661])\n\n\nWir können alles auch in eine sehr elegante Funktion “packen”:\n\n\nCode\n#### Eine elegante Funktion für den gesamten Optimierungsprozess:\n\ndef get_risk_parity_weights(covariances, assets_risk_budget, initial_weights):\n\n    # Nebenbedingungen der Optimierung: nur Long-Positionen, die in der\n    # Summe 100% ergeben\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0},\n                   {'type': 'ineq', 'fun': lambda x: x})\n\n    # Optimierung mit scipy\n    optimize_result = minimize(fun=risk_contribution_objective,\n                               x0=initial_weights,\n                               args=[covariances, assets_risk_budget],\n                               method='SLSQP',\n                               constraints=constraints,\n                               tol=TOLERANCE,\n                               options={'disp': False})\n\n    # Extrahieren der Gewichte aus dem Output der Optimierung\n    weights = optimize_result.x\n\n    # die Funktion gibt die gesuchten optimalen Gewichte zurück\n    return weights\n\n\nAls Lösung ergeben sich die folgenden Gewichte im ERC-Portfolio:\n\n\nCode\ngewicht_erc=get_risk_parity_weights(Sigma, x_t, gewicht_ew)\npd.DataFrame({'Gewichte ERC': gewicht_erc}, index=Assets)\n\n\n\n\n\n\n\n\n\nGewichte ERC\n\n\n\n\nA\n0.205008\n\n\nB\n0.312471\n\n\nC\n0.310244\n\n\nD\n0.172277\n\n\n\n\n\n\n\nWir können leicht sehen, dass das Ziel eines einheitlichen Risikobeitrags erreicht wurde!\n\n\nCode\npd.DataFrame(calculate_risk_contribution(gewicht_erc,Sigma), index=Assets).plot.\\\n                bar(title='Risikobeitrag (ERC-Portfolio)',\n                    figsize=(10,5), legend=False);\n\n\n\n\n\n\n\n\n\nErkennbar ist auch am ERC-Portfolio, dass tendenziell Anlagen mit einem höheren (geringeren) Risiko eher untergewichtet (eher übergewichtet) werden (wobei aber zu beachten ist, dass dies nicht generell gilt, weil gleichzeitig auch die Korrelationen untereinander noch zu berücksichtigen sind). Insofern kann davon ausgegangen werden, dass auch bei der ERC-Strategie tendenziell meist eher in risikoärmere Anlagen investiert wird. Für dieses Beispiel ergibt sich die nachfolgende gewichtete Varianz-Kovarianzmatrix.\n\n\nCode\nwSigma=pd.DataFrame({'A': (Sigma[:,0]*gewicht_erc[0]*gewicht_erc),\\\n                     'B': (Sigma[:,1]*gewicht_erc[1]*gewicht_erc),\\\n                     'C': (Sigma[:,2]*gewicht_erc[2]*gewicht_erc),\\\n                     'D': (Sigma[:,3]*gewicht_erc[3]*gewicht_erc)},\\\n                    index=Assets, columns=Assets) \nwSigma.columns.name='Gewichtete Kovarianzen' \nwSigma.loc['Summe',:]= wSigma.sum(axis=0)\nwSigma.loc[:,'Summe']= wSigma.sum(axis=1)\nwSigma\n\n\n\n\n\n\n\n\nGewichtete Kovarianzen\nA\nB\nC\nD\nSumme\n\n\n\n\nA\n0.001362\n0.000507\n-0.000183\n0.000458\n0.002144\n\n\nB\n0.000507\n0.001181\n0.000171\n0.000284\n0.002144\n\n\nC\n-0.000183\n0.000171\n0.002464\n-0.000308\n0.002144\n\n\nD\n0.000458\n0.000284\n-0.000308\n0.001710\n0.002144\n\n\nSumme\n0.002144\n0.002144\n0.002144\n0.002144\n0.008574\n\n\n\n\n\n\n\nDie gewichtete Varianz-Kovarianzmatrix führt somit zu einer Varianz des ERC-Portfolios von 0,0085744, was einer Standardabweichung des Portfolios von 9,25984% entspricht: \\(\\sigma_p=\\sqrt{0,0085744}=9,25984\\%\\).\nWie bei der ERB-Strategie können auch für die ERC-Strategie die absoluten Risikobeiträge (RB), die relativen Risikobeiträge, die Kovarianzen der einzelnen Anlagerenditen mit der Portfoliorendite, die auf das ERC-Portfolio bezogenen Betafaktoren und die marginalen Risikobeiträge in einer Tabelle dargestellt werden:\n\n\nCode\n# Berechnung der absoluten Risikobeitrags: Formel (1) und (2)\nrb=np.zeros(4)\nfor i in range(4):\n    rb[i]=(gewicht_erc[i]*Sigma[i,:]*np.asmatrix(gewicht_erc).T)/0.0925984\n\n# Berechnung der relativen Risikobeitrags\nrrb=np.zeros(4)\nfor i in range(4):\n    rrb[i]=rb[i]/np.sum(rb)\n    \n# Berechnung der Kovarianz der Assetrendite mit der Portfoliorendite: Formel (3)\ncov_ri_rp=np.zeros(4)\nfor i in range(4):\n       cov_ri_rp[i]=Sigma[i,:]*np.asmatrix(gewicht_erc).T\n\n# Berechnung des Betas der Assetrendite mit der Portfoliorendite\nbeta_ri=np.zeros(4)\nfor i in range(4):\n        beta_ri[i]=cov_ri_rp[i]/0.0925984**2\n\n# und nun noch der marginale Risikobeitrag\nmrb=np.zeros(4)\nfor i in range(4):\n        mrb[i]=rb[i]/gewicht_erc[i]\n        \n# Abschließend stellen wir die Ergebnisse zur ERC-Strategie \n# übersichtlich in einer Tabelle dar\n\nergebnisse_erc=pd.DataFrame({'absoluter RB (%)': np.round(rb*100,4), \\\n                             'relativer RB (%)': np.round(rrb*100,4),\n                             'Cov(r_i,r_p)':np.round(cov_ri_rp,4),\n                             'Beta': np.round(beta_ri,4),\n                             'MRB (%)': np.round(mrb*100,4)},index=Assets) \nergebnisse_erc.loc['Summe',:2]= ergebnisse_erc.sum(axis=0)\nergebnisse_erc\n\n\n\n\n\n\n\n\n\nabsoluter RB (%)\nrelativer RB (%)\nCov(r_i,r_p)\nBeta\nMRB (%)\n\n\n\n\nA\n2.315\n25.0\n0.0105\n1.2195\n11.2920\n\n\nB\n2.315\n25.0\n0.0069\n0.8001\n7.4086\n\n\nC\n2.315\n25.0\n0.0069\n0.8058\n7.4617\n\n\nD\n2.315\n25.0\n0.0124\n1.4512\n13.4375\n\n\nSumme\n9.260\n100.0\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nDie Ergebnisse in der Tabelle zeigen, dass für die einzelnen Assets jeweils die gleichen Risikobeiträge ermittelt werden können, was dem Ziel der ERC-Strategie entspricht.\nDie jeweils gewichteten Betafaktoren ergeben in der Summe den Wert 1:\n\\[ \\beta^{ERC}_p= \\Sigma^N_{n=1} w^{ERC}_n \\cdot \\beta^{ERC}_n \\]\n\\[ = 20,5008\\% \\cdot 1,2195 + 31,2471\\% \\cdot 0,8001 + 31,0244\\% \\cdot 0,8058 + 17,2277\\% \\cdot 1,4512 \\]\n\\[ = 0,2500 + 0,2500 + 0,2500 + 0,2500 = 1,0000 \\]\nDieses Ergebnis kann auch direkt aus der Umstellung der obigen Formel abgeleitet werden:\n\\[ w^{ERC}_n=\\frac{1}{N \\cdot \\beta^{ERC}_n} \\iff w^{ERC}_n \\cdot \\beta^{ERC}_n =\\frac{1}{N}.  \\]\nBei dem Beispiel wird deutlich, dass sich die jeweiligen Betafaktoren der einzelnen Anlagen von den Betafaktoren des ERB-Portfolios unterscheiden. Dies ist auf die Unterschiede von ERB- und ERC-Portfolio zurückzuführen, welche sich dadurch ergeben, dass bei der Ermittlung der Gewichtungen der jeweiligen Anlagen im ERB-Portfolio die Korrelationen zwischen den Renditen der sich im Portfolio befindenden Assets nicht berücksichtigt werden.\nDas Beispiel zeigt zudem, dass alle gewichteten Betafaktoren im ERC-Portfolio gleich sind. Somit gilt:\n\\[ w^{ERC}_1 \\cdot \\beta^{ERC}_1=w^{ERC}_2 \\cdot \\beta^{ERC}_2=...=w^{ERC}_N \\cdot \\beta^{ERC}_N \\]\nHieraus resultiert der folgende Zusammenhang:\n\\[ w^{ERC}_n=\\frac{1/\\beta^{ERC}_n}{\\Sigma^N_{n=1}1/\\beta^{ERC}_n}=\\frac{1}{N \\cdot \\beta^{ERC}_n} \\]\nVor diesem Hintergrund kann das ERC-Portfolio auch als Beta Parity-Portfolio bezeichnet werden, während das ERB-Portfolio auch Volatility Parity-Portfolio genannt werden kann.\nBeziehungen zwischen dem ERB und dem ERC Portfolio\n\nIm Fall identischer Korrelationen zwischen allen Asset-Klassen sowie im Fall zweier Asset-Klassen reduziert sich der Equal-Risk-Contribution Ansatz auf den Equal-Risk-Budget Ansatz (vgl. Maillard et al., 2009).\n\nWürde man beispielsweise unterstellen, dass in dem obigen Beispiel sämtliche Korrelationen zwischen den Anlagen den Wert 0,2 annehmen, würde dies zu folgenden Ergebnissen führen:\n\n\nCode\nCorrMatrix_equal = np.array([[1.00, 0.20, 0.20, 0.20],\n                            [0.20, 1.00, 0.20, 0.20],\n                           [0.20, 0.20, 1.00, 0.20],\n                           [0.20, 0.20, 0.20, 1.00]])\nSigma_equal = np.diag(Stdev) @ CorrMatrix_equal @ np.diag(Stdev)\nSigma_equal\n\n\narray([[0.0324 , 0.00396, 0.00576, 0.00864],\n       [0.00396, 0.0121 , 0.00352, 0.00528],\n       [0.00576, 0.00352, 0.0256 , 0.00768],\n       [0.00864, 0.00528, 0.00768, 0.0576 ]])\n\n\n\n\nCode\ngewicht_erc_equal=get_risk_parity_weights(Sigma_equal, x_t, gewicht_ew)\npd.DataFrame({'Gewichte ERC': gewicht_erc_equal}, index=Assets)\n\n\n\n\n\n\n\n\n\nGewichte ERC\n\n\n\n\nA\n0.221662\n\n\nB\n0.362720\n\n\nC\n0.249370\n\n\nD\n0.166247\n\n\n\n\n\n\n\nDiese Gewichtungen entsprechen den Werten des ERB-Ansatzes. Zu beachten ist, dass die veränderten Korrelationen zu einer anderen Standardabweichung der Portfoliorendite (10,0938%) gegenüber dem obigen ERB-Wert im Grundbeispiel führen. Sie ist aber in dem Fall der identischen Korrelationen für beide Portfolios (ERB und ERC) gleich.\n\nWird darüber hinaus unterstellt, dass die Volatilitäten sämtlicher Assets im Portfolio identisch sind, so resultiert daraus für beide Ansätze ein gleichgewichtetes Portfolio.\n\n\n\n8.4.3 Equally-Weighted-Strategie\nIn unserem Beispiel mit vier Assets betragen die Anteile \\(w^{EW}_n\\) jeweils 25%. Für diese Werte ergibt sich die in der folgenden Tabelle dargestellte gewichtete Varianz-Kovarianmatrix.\n\n\nCode\nwSigma=pd.DataFrame({'A': (Sigma[:,0]*gewicht_ew[0]*gewicht_ew),\\\n                     'B': (Sigma[:,1]*gewicht_ew[1]*gewicht_ew),\\\n                     'C': (Sigma[:,2]*gewicht_ew[2]*gewicht_ew),\\\n                     'D': (Sigma[:,3]*gewicht_ew[3]*gewicht_ew)},\\\n                    index=Assets, columns=Assets) \nwSigma.columns.name='Gewichtete Kovarianzen' \nwSigma.loc['Summe',:]= wSigma.sum(axis=0)\nwSigma.loc[:,'Summe']= wSigma.sum(axis=1)\nwSigma\n\n\n\n\n\n\n\n\nGewichtete Kovarianzen\nA\nB\nC\nD\nSumme\n\n\n\n\nA\n0.002025\n0.000495\n-0.00018\n0.00081\n0.003150\n\n\nB\n0.000495\n0.000756\n0.00011\n0.00033\n0.001691\n\n\nC\n-0.000180\n0.000110\n0.00160\n-0.00036\n0.001170\n\n\nD\n0.000810\n0.000330\n-0.00036\n0.00360\n0.004380\n\n\nSumme\n0.003150\n0.001691\n0.00117\n0.00438\n0.010391\n\n\n\n\n\n\n\nDie gewichtete Varianz-Kovarianzmatrix führt somit zu einer Varianz des EW-Portfolios von 0,0103913, was einer Standardabweichung des Portfolios von 10,19375% entspricht: \\(\\sigma_p=\\sqrt{0,01039125}=10,19375\\%.\\)\nIdentische Gewichte sind augenscheinlich nicht gleichbedeutend mit identischen Risikobeiträgen.\n\n\nCode\npd.DataFrame(calculate_risk_contribution(gewicht_ew,Sigma),\\\n             index=Assets).plot.\\\n                bar(title='Risikobeitrag (EW-Portfolio)',\n                    figsize=(10,5), legend=False);\n\n\n\n\n\n\n\n\n\nDie absoluten Risikobeiträge (RB), die relativen Risikobeiträge, die Kovarianzen der einzelnen Anlagerenditen mit der Portfoliorendite, die auf das EW-Portfolio bezogenen Betafaktoren und die marginalen Risikobeiträge sind in der nachfolgenden Tabelle dargestellt:\n\n\nCode\n# Berechnung der absoluten Risikobeitrags: Formel (1) und (2)\nrb=np.zeros(4)\nfor i in range(4):\n    rb[i]=(gewicht_ew[i]*Sigma[i,:]*np.asmatrix(gewicht_ew).T)/0.1019375\n\n# Berechnung der relativen Risikobeitrags\nrrb=np.zeros(4)\nfor i in range(4):\n    rrb[i]=rb[i]/np.sum(rb)\n    \n# Berechnung der Kovarianz der Assetrendite mit der Portfoliorendite: Formel (3)\ncov_ri_rp=np.zeros(4)\nfor i in range(4):\n       cov_ri_rp[i]=Sigma[i,:]*np.asmatrix(gewicht_ew).T\n\n# Berechnung des Betas der Assetrendite mit der Portfoliorendite\nbeta_ri=np.zeros(4)\nfor i in range(4):\n        beta_ri[i]=cov_ri_rp[i]/0.1019375**2\n\n# und nun noch der marginale Risikobeitrag\nmrb=np.zeros(4)\nfor i in range(4):\n        mrb[i]=rb[i]/gewicht_ew[i]\n        \n# Abschließend stellen wir die Ergebnisse zur EW-Strategie \n# übersichtlich in einer Tabelle dar\n\nergebnisse_ew=pd.DataFrame({'absoluter RB (%)': np.round(rb*100,4), \\\n                             'relativer RB (%)': np.round(rrb*100,4),\n                             'Cov(r_i,r_p)':np.round(cov_ri_rp,4),\n                             'Beta': np.round(beta_ri,4),\n                             'MRB (%)': np.round(mrb*100,4)},index=Assets) \nergebnisse_ew.loc['Summe',:2]= ergebnisse_ew.sum(axis=0)\nergebnisse_ew\n\n\n\n\n\n\n\n\n\nabsoluter RB (%)\nrelativer RB (%)\nCov(r_i,r_p)\nBeta\nMRB (%)\n\n\n\n\nA\n3.0901\n30.3140\n0.0126\n1.2126\n12.3605\n\n\nB\n1.6591\n16.2757\n0.0068\n0.6510\n6.6364\n\n\nC\n1.1478\n11.2595\n0.0047\n0.4504\n4.5910\n\n\nD\n4.2968\n42.1508\n0.0175\n1.6860\n17.1870\n\n\nSumme\n10.1938\n100.0000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nSomit tragen die beiden Assets A und D, die auch jeweils das höchste Risiko aufweisen, über 72% zum Gesamtrisiko bei. Insgesamt ergibt sich ein Portoliorisiko, das höher ausfällt als bei den Risk Parity-Ansätzen.\n\n\n8.4.4 Global-Minimum-Varianz-Strategie\nIm obigen Beispiel eines aus den Assets A, B, C und D bestehenden Portfolios lassen sich für den Fall ohne Leerverkaufsverbot (oder andere Ungleichungen als Nebenbedingungen) die folgenden GMVP-Gewichte gemäß Formel (6) ermittelt.\n\n\nCode\niota = np.ones(Sigma.shape[0]) # erzeugt einen Einheitsvektor der Dimension 4\ninv_Sigma = la.inv(Sigma) # Inverse der Varianz-Kovarianzmatrix\ngewicht_gmv = inv_Sigma @ iota / (iota @ inv_Sigma @ iota)\ngewicht_gmv\n\n\narray([0.11072811, 0.48654866, 0.30598742, 0.09673581])\n\n\nÜberprüfung der Lösung durch numerische Optimierung:\n\n\nCode\n# Verwendung eines gleichgewichteten Portfolios \"gewicht_ew\" als Startlösung \n# einzige Nebenbedingung: Budgetrestriktion (sum(w) = 1 )\ncons = ({'type': 'eq', 'fun': lambda x:  np.sum(x)-1.0})\nres= minimize(calculate_portfolio_var, gewicht_ew, args=Sigma, \\\n              tol=TOLERANCE, method='SLSQP',constraints=cons, options={'disp': False})\ngewicht_gmv = res.x\n\n\n\n\nCode\ngewicht_gmv\n\n\narray([0.1107281 , 0.48654867, 0.30598741, 0.09673581])\n\n\nNun die GMVP Gewichte mit der Nichtnegativitätsbedingung (Leerverkausverbot):\n\n\nCode\n# Nichtnegativitätsbedingung\nbnd=[(0, 1),(0, 1),(0, 1),(0, 1)] # nur positive Gewichte\n\nres2= minimize(calculate_portfolio_var, gewicht_ew, args=Sigma,\\\n               bounds = bnd, method='SLSQP',constraints=cons,\\\n               tol=TOLERANCE, options={'disp': False})\ngewicht_gmv_long_only = res2.x\n\n\n\n\nCode\ngewicht_gmv_long_only\n\n\narray([0.1107281 , 0.48654867, 0.30598741, 0.09673581])\n\n\nOffensichtlich ergeben sich für die Beispieldaten keine bedeutsamen Unterschiede zwischen der geschlossenen und der numerischen Lösung. Das Leerverkaufsverbot stellt hier somit keine Einschränkung dar.\nAls weitere Modifikation werden wir nun Bestandsgrenzen für die Assets von [0;0,40] einführen, d.h., kein Asset darf mehr als 40% des Portfolios ausmachen.\n\n\nCode\nbnd=[(0, .4),(0, .4),(0, .4),(0, .4)]\nres3= minimize(calculate_portfolio_var, gewicht_ew, args=Sigma, \\\n               bounds = bnd, method='SLSQP',constraints=cons, \\\n               tol=TOLERANCE, options={'disp': False})\ngewicht_gmv_long_only_max_40= res3.x\n\n\n\n\nCode\ngewicht_gmv_long_only_max_40\n\n\narray([0.14784903, 0.4       , 0.34204197, 0.110109  ])\n\n\nStellen wir nun abschließend die Gewichte der drei Versionen des GMVP grafisch dar.\n\n\nCode\ngmvp_weights =pd.DataFrame({'keine Beschränkung':gewicht_gmv.T, \n                   'Long-only': gewicht_gmv_long_only.T, \n                    'Long-only, max. 40%': gewicht_gmv_long_only_max_40.T},\n                  index= Assets)\n                           \ngmvp_weights.plot.bar(title='Verschiedene Global-Minimum-Varianz-Portfolio Gewichte',\n                            legend=True, figsize=(10, 5));\n\n\n\n\n\n\n\n\n\nIn diesem Beispiel erhalten die Assets mit zunehmenden Risiko abnehmende Anteile im Portfolio. Somit wird - wie auch beim Risk Parity-Ansatz zu erwarten ist - tendenziell eher in risikoärmere Assets investiert (wobei aber zu beachten ist, dass diese Aussage auch hier nicht generell gilt, weil gleichzeitig auch die Korrelationen untereinander noch zu berücksichtigen sind). Für diese Werte ergibt sich die in der folgenden Tabelle dargestellte gewichtete Varianz-Kovarianzmatrix.\n\n\nCode\nwSigma=pd.DataFrame({'A': (Sigma[:,0]*gewicht_gmv[0]*gewicht_gmv),\\\n                     'B': (Sigma[:,1]*gewicht_gmv[1]*gewicht_gmv),\\\n                     'C': (Sigma[:,2]*gewicht_gmv[2]*gewicht_gmv),\\\n                     'D': (Sigma[:,3]*gewicht_gmv[3]*gewicht_gmv)},\\\n                    index=Assets, columns=Assets) \nwSigma.columns.name='Gewichtete Kovarianzen' \nwSigma.loc['Summe',:]= wSigma.sum(axis=0)\nwSigma.loc[:,'Summe']= wSigma.sum(axis=1)\nwSigma\n\n\n\n\n\n\n\n\nGewichtete Kovarianzen\nA\nB\nC\nD\nSumme\n\n\n\n\nA\n0.000397\n0.000427\n-0.000098\n0.000139\n0.000865\n\n\nB\n0.000427\n0.002864\n0.000262\n0.000249\n0.003802\n\n\nC\n-0.000098\n0.000262\n0.002397\n-0.000170\n0.002391\n\n\nD\n0.000139\n0.000249\n-0.000170\n0.000539\n0.000756\n\n\nSumme\n0.000865\n0.003802\n0.002391\n0.000756\n0.007814\n\n\n\n\n\n\n\nMit Hilfe der gewichteten Varianz-Kovarianmatrix kann somit eine Varianz des GMVP von 0,0078135 ermittelt werden, was einer Standardabweichung des Portfolios von 8,83941%\n\\[\\sigma_p=\\sqrt{0,0078135}=8,83941\\%.\\]\nWie beim Risk Parity-Ansatz können auch für das GMVP die absoluten Risikobeiträge (RB), die relativen Risikobeiträge, die Kovarianzen der einzelnen Anlagerenditen mit der Portfoliorendite, die auf das GMV-Portfolio bezogenen Betafaktoren und die marginalen Risikobeiträge in einer Tabelle dargestellt werden:\n\n\nCode\n# Berechnung der absoluten Risikobeitrags: Formel (1) und (2)\nrb=np.zeros(4)\nfor i in range(4):\n    rb[i]=(gewicht_gmv[i]*Sigma[i,:]*np.asmatrix(gewicht_gmv).T)/0.0883941\n\n# Berechnung der relativen Risikobeitrags\nrrb=np.zeros(4)\nfor i in range(4):\n    rrb[i]=rb[i]/np.sum(rb)\n    \n# Berechnung der Kovarianz der Assetrendite mit der Portfoliorendite: Formel (3)\ncov_ri_rp=np.zeros(4)\nfor i in range(4):\n       cov_ri_rp[i]=Sigma[i,:]*np.asmatrix(gewicht_gmv).T\n\n# Berechnung des Betas der Assetrendite mit der Portfoliorendite\nbeta_ri=np.zeros(4)\nfor i in range(4):\n        beta_ri[i]=cov_ri_rp[i]/0.0883941**2\n\n# und nun noch der marginale Risikobeitrag\nmrb=np.zeros(4)\nfor i in range(4):\n        mrb[i]=rb[i]/gewicht_gmv[i]\n        \n# Abschließend stellen wir die Ergebnisse zur GMV-Strategie \n# übersichtlich in einer Tabelle dar\n\nergebnisse_gmv=pd.DataFrame({'absoluter RB (%)': np.round(rb*100,4), \\\n                             'relativer RB (%)': np.round(rrb*100,4),\n                             'Cov(r_i,r_p)':np.round(cov_ri_rp,4),\n                             'Beta': np.round(beta_ri,4),\n                             'MRB (%)': np.round(mrb*100,4)},index=Assets) \nergebnisse_gmv.loc['Summe',:2]= ergebnisse_gmv.sum(axis=0)\nergebnisse_gmv\n\n\n\n\n\n\n\n\n\nabsoluter RB (%)\nrelativer RB (%)\nCov(r_i,r_p)\nBeta\nMRB (%)\n\n\n\n\nA\n0.9788\n11.0728\n0.0078\n1.0\n8.8394\n\n\nB\n4.3008\n48.6549\n0.0078\n1.0\n8.8394\n\n\nC\n2.7047\n30.5987\n0.0078\n1.0\n8.8394\n\n\nD\n0.8551\n9.6736\n0.0078\n1.0\n8.8394\n\n\nSumme\n8.8394\n100.0000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nAuffällig ist in der Tabelle zunächst, dass die Kovarianzen der Renditen sämtlicher Assets mit den Renditen des GMVP identisch sind. Dies lässt sich auch analytisch zeigen. Für eine beliebige Anlage Z ergibt sich die Varianz des aus dem GMVP und Z bestehenden Portfolios wie folgt:\n\\[ \\sigma^2_p=w^2_{GMV} \\cdot \\sigma^2_{GMV}+(1-w_{GMV})^2 \\cdot \\sigma^2_Z + 2 \\cdot w_{GMV} \\cdot (1-w_{GMV})\\cdot Cov(r_{GMV},r_Z) \\]\nZur Bestimmung des sich hieraus ergebenden Portfolios mit der minimalen Varianz wird diese Gleichung nach \\(w_{GMV}\\) abgeleitet und die Ableitung anschließend mit Null gleichgesetzt:\n\\[ \\frac{\\partial{\\sigma^2_p}}{\\partial{w_{GMV}}}=2 \\cdot \\sigma^2_{GMV}\\cdot w_{GMV}-2 \\cdot (1-w_{GMV})\\cdot \\sigma^2_Z+ (2-4\\cdot w_{GMV}) \\cdot Cov(r_{GMV},r_Z)=0 \\]\nDa die Veränderung der Gewichte \\(w_n\\) zu einer höheren Varianz des Portfolios führen würde als die Varianz des GMV-Portfolios, ergibt sich direkt, dass \\(w_{GMV}=100\\%\\) und \\(w_Z=0\\%\\). Dies wiederum führt zu der folgenden Gleichung (siehe Kleeberg, 1995, S. 17ff.):\n\\[ \\frac{\\partial{\\sigma^2_p}}{\\partial{w_{GMV}}}=2 \\cdot \\sigma^2_{GMV}-2 \\cdot Cov(r_{GMV},r_Z)=0 \\iff \\sigma^2_{GMV}=Cov(r_{GMV},r_Z) \\]\nSomit entspricht die Kovarianz des GMVP mit einer beliebigen Anlage Z seiner Varianz. Sofern allerdings weitere Nebenbedingungen zur GMVP-Bestimmung gelten, wie z.B. eine maximale Gewichtung einzelner Anlagen im Portfolio (siehe oben) oder ein Verbot von Leerverkäufen, kann es möglicherweise vorkommen, dass die Übereinstimmung der Varianz des GMVP mit der Kovarianz des GMVP mit einer beliebigen anderen Anlage Z nicht vorliegt.\nAufgrund der o.g. Übereinstimmung von Kovarianz und Varianz resultiert für alle Anlagen im Portfolio auch ein Betafaktor (in Bezug zum GMVP) von 1:\n\\[ \\beta_n=\\frac{Cov(r_n,r_{GMV})}{\\sigma^2_{GMV}}=\\frac{\\sigma^2_{GMV}}{\\sigma^2_{GMV}}=1 \\]\nDarüber hinaus ist auch der marginale Risikobeitrag für alle Assets des GMVP identisch und entspricht der Standardabweichung des GMVP, wie sich auf Basis der o.g. formalen Ermittlung des marginalen Risikobeitrags (MRB) ergibt:\n\\[ MRB_n=\\frac{\\partial{\\sigma_{GMV}}}{\\partial{w_n}}=\\frac{Cov(r_n,r_{GMV})}{\\sigma_{GMV}}=\\beta_n \\cdot \\sigma_{GMV}=1 \\cdot \\sigma_{GMV}=\\sigma_{GMV} \\]\nDer absolute Risikobeitrag (RB) für jede Anlage n berechnet sich allgemein wiederum in der folgenden Weise: \\(RB_n=w_n \\cdot MRB_n\\). Da hier gilt, dass \\(MRB_n=\\sigma_{GMV}\\), folgt daraus für den Global-Minimum-Varianz-Ansatz:\n\\[ \\textrm{relativer Risikobeitrag} = \\frac{RB_n}{\\sigma_{GMV}}=\\frac{RB_n}{MRB_n}=w^{GMV}_n \\]\nAngemerkt werden kann, dass der Betafaktor des GMVP bzgl. des Gesamtmarktes bzw. Marktportfolios \\((\\beta^M_{GMV})\\) kleiner als 1 sein muss. Aufgrund der Identität der Varianz des GMVP und der Kovarianz des GMVP mit einer anderen Anlage lässt sich folgender Ausdruck ableiten, wobei unterstellt wird, dass keine Nebenbedingungen zur Ermittlung des GMVP berücksichtigt werden müssen:\n\\[ \\sigma^2_{GMVP}&lt;\\sigma^2_M \\rightarrow \\beta^M_{GMV}=\\frac{Cov(r_{GMV}, r_M)}{\\sigma^2_M}=\\frac{\\sigma^2_{GMV}}{\\sigma^2_M}&lt;1 \\]\nIn mehreren bisherigen empirischen Untersuchungen zum Erfolg des GMVP konnte mehrfach ein geringeres Risiko bei einer gleichzeitig höheren Rendite als bei Verwendung der entsprechenden Marktindizes festgestellt werden (siehe Kleeberg, 1995, 2002; Clarke et al., 2006, 2011).\n\n\n8.4.5 Maximum-Diversification-Strategie\nFür das obige Beispiel eines aus den Anlagen A, B, C und D bestehenden Portfolios lassen sich die nachfolgenden Anteile bestimmen. Zunächst als geschlossene Lösung gemäß Formel (7) für den Fall mit nur der Budgetrestriktion als Nebenbedingung.\n\n\nCode\ngewicht_md = inv_Sigma @ Stdev / (iota @ inv_Sigma @ Stdev)\ngewicht_md\n\n\narray([0.20140626, 0.2133736 , 0.38775895, 0.19746119])\n\n\nUnd nun über die numerische Optimierung als Long-only Portfolio.\n\n\nCode\n# Implementierung der numerischen Optimierung:\n\ndef calc_diversification_ratio(w, Sigma):\n    # mit den Portfolioanteilen gewichtete durchschnittliche Vola\n    w_vol = np.dot(np.sqrt(np.diag(Sigma)), w.T)\n    # Portfolio vol\n    port_vol = np.sqrt(calculate_portfolio_var(w, Sigma))\n    diversification_ratio = w_vol/port_vol\n    # Rückgabe negativ da Minimierungsproblem (maximize = minimize -)\n    return -diversification_ratio\n\n\ndef max_div_port(w0, Sigma, bnd=None, long_only=True):\n    # w0: Vektor der Startgewichte\n    # Sigma: Varianz-Kovarianzmatrix\n    # bnd: individuelle Bestandsgrenzen\n    # long only: long-only Nebenbedingung\n    cons = ({'type': 'eq', 'fun': total_weight_constraint},)\n    if long_only: # Hinzufügen der Nichtnegativitätsbedingung\n        cons = cons + ({'type': 'ineq', 'fun':  long_only_constraint},)\n    res = minimize(calc_diversification_ratio, w0, bounds=bnd,\\\n                   args=Sigma, method='SLSQP', constraints=cons, tol=TOLERANCE)\n    return res.x\n\nmax_div_port(gewicht_ew, Sigma)\n\n\narray([0.20140626, 0.21337361, 0.38775895, 0.19746118])\n\n\nDer Vergleich zeigt - wie im Fall des GMVP -, dass das Hinzufügen der Nichtnegativitätsbedingung im Beispiel keinen Einfluss auf die optimale Lösung hat.\n\n\nCode\npd.DataFrame(max_div_port(gewicht_ew, Sigma), index=Assets).\\\n             plot.bar(title='Max Diversification Gewichte',\n             legend=False, figsize=(9, 4));\n\n\n\n\n\n\n\n\n\nAuffällig ist - im Vergleich zu den o.g. Stratgien -, dass beim MD-Ansatz in das Asset C erheblich mehr als in Asset B investiert wird, obwohl das Risiko von C deutlich höher ausfällt. Dies hängt mit den geringen Korrelationen zwischen C und den übrigen Anlagen zusammen.\nFür diese Werte ergibt sich die in der folgenden Tabelle dargestellte gewichtete Varianz-Kovarianmatrix.\n\n\nCode\nwSigma=pd.DataFrame({'A': (Sigma[:,0]*gewicht_md[0]*gewicht_md),\\\n                     'B': (Sigma[:,1]*gewicht_md[1]*gewicht_md),\\\n                     'C': (Sigma[:,2]*gewicht_md[2]*gewicht_md),\\\n                     'D': (Sigma[:,3]*gewicht_md[3]*gewicht_md)},\\\n                    index=Assets, columns=Assets) \nwSigma.columns.name='Gewichtete Kovarianzen' \nwSigma.loc['Summe',:]= wSigma.sum(axis=0)\nwSigma.loc[:,'Summe']= wSigma.sum(axis=1)\nwSigma\n\n\n\n\n\n\n\n\nGewichtete Kovarianzen\nA\nB\nC\nD\nSumme\n\n\n\n\nA\n0.001314\n0.000340\n-0.000225\n0.000515\n0.001945\n\n\nB\n0.000340\n0.000551\n0.000146\n0.000222\n0.001259\n\n\nC\n-0.000225\n0.000146\n0.003849\n-0.000441\n0.003329\n\n\nD\n0.000515\n0.000222\n-0.000441\n0.002246\n0.002543\n\n\nSumme\n0.001945\n0.001259\n0.003329\n0.002543\n0.009076\n\n\n\n\n\n\n\nMit Hilfe der gewichteten Varianz-Kovarianzmatrix kann somit eine Varianz des MD-Portfolios von 0,009076 ermittelt werden, was einer Standardabweichung der Portfoliorendite von 9,52681% entspricht:\n\\[\\sigma_p=\\sqrt{0,009076}=9,52681\\%.\\]\nWie beim Risk Parity-Ansatz können auch für das Maximum-Diversification-Portfolio die absoluten Risikobeiträge (RB), die relativen Risikobeiträge, die Kovarianzen der einzelnen Anlagerenditen mit der Portfoliorendite, die auf das MD-Portfolio bezogenen Betafaktoren und die marginalen Risikobeiträge in einer Tabelle dargestellt werden:\n\n\nCode\n# Berechnung der absoluten Risikobeitrags: Formel (1) und (2)\nrb=np.zeros(4)\nfor i in range(4):\n    rb[i]=(gewicht_md[i]*Sigma[i,:]*np.asmatrix(gewicht_md).T)/0.0952681\n\n# Berechnung der relativen Risikobeitrags\nrrb=np.zeros(4)\nfor i in range(4):\n    rrb[i]=rb[i]/np.sum(rb)\n    \n# Berechnung der Kovarianz der Assetrendite mit der Portfoliorendite: Formel (3)\ncov_ri_rp=np.zeros(4)\nfor i in range(4):\n       cov_ri_rp[i]=Sigma[i,:]*np.asmatrix(gewicht_md).T\n\n# Berechnung des Betas der Assetrendite mit der Portfoliorendite\nbeta_ri=np.zeros(4)\nfor i in range(4):\n        beta_ri[i]=cov_ri_rp[i]/0.0952681**2\n\n# und nun noch der marginale Risikobeitrag\nmrb=np.zeros(4)\nfor i in range(4):\n        mrb[i]=rb[i]/gewicht_md[i]\n        \n# Abschließend stellen wir die Ergebnisse zur MD-Strategie \n# übersichtlich in einer Tabelle dar\n\nergebnisse_md=pd.DataFrame({'absoluter RB (%)': np.round(rb*100,4), \\\n                             'relativer RB (%)': np.round(rrb*100,4),\n                             'Cov(r_i,r_p)':np.round(cov_ri_rp,4),\n                             'Beta': np.round(beta_ri,4),\n                             'MRB (%)': np.round(mrb*100,4)},index=Assets) \nergebnisse_md.loc['Summe',:2]= ergebnisse_md.sum(axis=0)\nergebnisse_md\n\n\n\n\n\n\n\n\n\nabsoluter RB (%)\nrelativer RB (%)\nCov(r_i,r_p)\nBeta\nMRB (%)\n\n\n\n\nA\n2.0418\n21.4317\n0.0097\n1.0641\n10.1375\n\n\nB\n1.3219\n13.8754\n0.0059\n0.6503\n6.1952\n\n\nC\n3.4941\n36.6770\n0.0086\n0.9459\n9.0111\n\n\nD\n2.6690\n28.0159\n0.0129\n1.4188\n13.5167\n\n\nSumme\n9.5268\n100.0000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nFür das MD-Portfolio ergibt sich eine Diversification Ratio von:\n\\[ DR=\\frac{\\Sigma^N_{n=1}w_n \\cdot \\sigma_n}{\\sigma_p}=\\frac{20,1406\\%\\cdot0,18 + 21,3375\\%\\cdot0,11+38,7758\\%\\cdot0,16+19,7461\\%\\cdot0,24}{9,52681\\%} \\]\n\\[=\\frac{16,91562\\%}{9,52681\\%}=1,77558.\\]\nAus den Werten für dieses Beispiel lassen sich die Korrelationen der einzelnen Anlagen mit dem MD-Portfolio bestimmen:\n\\[ Corr(r_A,r_{MD})=\\frac{Cov(r_A,r_{MD})}{\\sigma_A\\cdot\\sigma_{MD}}=\\frac{0,96578\\%}{18\\% \\cdot 9,52681\\%}=0,5632 \\]\n\\[ Corr(r_B,r_{MD})=\\frac{Cov(r_B,r_{MD})}{\\sigma_B\\cdot\\sigma_{MD}}=\\frac{0,59020\\%}{11\\% \\cdot 9,52681\\%}=0,5632 \\]\n\\[ Corr(r_C,r_{MD})=\\frac{Cov(r_C,r_{MD})}{\\sigma_C\\cdot\\sigma_{MD}}=\\frac{0,85847\\%}{16\\% \\cdot 9,52681\\%}=0,5632 \\]\n\\[ Corr(r_D,r_{MD})=\\frac{Cov(r_D,r_{MD})}{\\sigma_D\\cdot\\sigma_{MD}}=\\frac{1,28771\\%}{18\\% \\cdot 9,52681\\%}=0,5632 \\]\nDie jeweiligen Korrelationswerte entsprechen in diesem Fall - wie oben analytisch gezeigt - dem Kehrwert der Diversifiction Ratio:\n\\[ Corr(r_n,r_{MD})=\\frac{1}{DR_{MD}}=\\frac{1}{1,77558}=0,5632 \\]\nZur Maximierung der Diversification Ratio kann sowohl beim Zähler als auch beim Nenner angesetzt werden. Werden mehr risikoreiche Anlagen in das Portfolio aufgenommen, erhöht sich der Wert des Zählers. Werden Anlagen so mit anderen Anlagen kombiniert, dass das Gesamtrisiko möglichst gering ausfällt, verringert sich der Nenner. Entscheidend ist der Unterschied zwischen der Summe der Einzelrisiken und dem kombinierten Gesamtrisiko, der zu maximieren ist, wobei die Korrelationen der Anlagen untereinander eine wesentliche Rolle einnehmen. Allerdings kann der Name “Maximum-Diversification-Portfolio” auch irreführend sein, weil sich mit den gleichen Anlagen möglicherweise auch andere Portfolios zusammenstellen lassen, die ein geringeres Gesamtrisiko aufweisen.\nFalls sich die Standardabweichungen sämtlicher Anlagen im MD-Portfolio entsprechen, so gilt für den Zähler der Diversification Ratio:\n\\[ \\Sigma^N_{n=1}w_n\\cdot \\sigma_n=\\sigma_n \\quad \\textrm{(wobei für alle Anlagen i und j im Portfolio gilt:} \\quad \\sigma_i=\\sigma_j). \\]\nIn diesem Fall wird die DR dann maximiert, wenn \\(\\sigma_p\\) minimiert wird. Aus diesem Grund entsprechen sich in diesem speziellen Fall das MD- und das GMV-Portfolio.\nDarüber hinaus gilt für den weiteren Spezialfall, dass sämtliche Korrelationen zwischen den jeweiligen Anlagen im Portfolio identisch sind, die Übereinstimmung des MD- mit dem ERC- und mit dem ERB-Portfolio.\n\n\n8.4.6 Vergleichende Analyse der fünf ausgewählten Ansätze\nWir beginnen mit einer zusammenfassenden Darstellung der fünf oben ermittelten Gewichtsvektoren, als Tabelle\n\n\nCode\npd.DataFrame({'ERB': gewicht_erb, 'ERC':gewicht_erc,\\\n                         'EW': gewicht_ew, 'GMV': gewicht_gmv,\\\n                         'MD': gewicht_md}, index=Assets)\n\n\n\n\n\n\n\n\n\nERB\nERC\nEW\nGMV\nMD\n\n\n\n\nA\n0.221662\n0.205008\n0.25\n0.110728\n0.201406\n\n\nB\n0.362720\n0.312471\n0.25\n0.486549\n0.213374\n\n\nC\n0.249370\n0.310244\n0.25\n0.305987\n0.387759\n\n\nD\n0.166247\n0.172277\n0.25\n0.096736\n0.197461\n\n\n\n\n\n\n\nund grafisch:\n\n\nCode\npd.DataFrame((np.vstack((gewicht_erb, gewicht_erc, gewicht_ew, gewicht_gmv,\\\n                        gewicht_md))*100).T, index=Assets,\\\ncolumns = ['Equal-Risk-Budget','Equal-Risk-Cont.','Equally-Weighted',\\\n           'Global-Minimum-Var.', 'Max. Diversification']). \\\n                    plot.bar(title='Portfoliogewichte verschiedener Ansätze einer risikogesteuerten Assetallokation (%)',\n                            legend=True, figsize=(9, 4));\n\n\n\n\n\n\n\n\n\n\nEqually-Weighted-Ansatz (EW-Ansatz)\n\nBeim EW-Ansatz erfolgt die Ermittung der Gewichte der Assets im Portfolio unabhängig von erwarteten bzw. statistischen Größen. Vielmehr hängt die Portfoliostruktur lediglich von der Anzahl der Anlagen im Portfolio ab, wobei alle Anlagen das gleiche Gewicht erhalten. Werden in einem Portfolio z.B. in regelmäßigen Abständen die Gewichtungen wieder auf \\(1/N\\) gesetzt, so würde ein Anlagetitel, der seit der letzten Portfolioanpassung eine vergleichsweise positive Entwicklung erfahren hat, wieder auf den Anteil \\(1/N\\) heruntergefahren. Entsprechend wird der Erfolg zu diesem Zeitpunkt realisiert.\nIm Hinblick auf die Gewichtungen führt der EW-Ansatz zu dem am geringsten konzentrierten Portfolio. Sofern aber die Risiken der jeweiligen Anlagen sehr unterschiedlich sind, ist aufgrund der höheren Risikokonzentration im EW-Portfolio der Diversifikationserfolg entsprechend gering. Bei der rigorosen Annahme gleicher erwarteter Renditen und Standardabweichungen sowie einheitlicher Korrelationen zwischen den Anlagen ist das EW-Portfolio allerdings ein gemäß Portfoliotheorie effizientes Portfolio (vgl. Maillard et al., 2009, S. 2; Demey et al., 2010, S. 12).\n\nGlobal-Minimum-Varianz-Ansatz (GMV-Ansatz)\n\nBeim GMV-Ansatz handelt es sich grundsätzlich um das einzige, sich auf der Effizienzlinie gemäß Portfoliotheorie befindende Portfolio, dessen Zusammensetzung nicht von erwarteten Renditen abhängt. Genau wie der EW-Ansatz ist der GMV-Ansatz leicht nachzuvollziehen. Ein weiterer Vorteil ist die geringe Standardabweichung - zumindest auf Ex-ante Basis. Allerdings weist das GMV-Portfolio das Problem auf, dass zwar eine Diversifikation bzgl. der Standardabweichung, nicht aber bzgl. der Gewichtungen der einzelnen Anlagen vorgenommen wird. Infolgedessen kann es häufig vorkommen, dass dieses Portfolio auf nur relativ wenige Anlagen konzentriert ist (vgl. Demey et al., 2010, S. 12).\nWie gezeigt, führt der GMV-Ansatz zu für alle Anlagen des Portfolios identischen Werten für den marginalen Risikobeitrag. Somit würde - zumindest auf Ex-ante Basis - eine infinitesimal kleine Erhöhung des Anteils einer Anlage im GMV-Portfolio bei allen Anlagen zur gleichen Erhöhung des Gesamtportfoliorisikos führen.\n\nMaximum-Diversification-Ansatz (MD-Ansatz)\n\nIm Rahmen des MD-Ansatzes wird das Portfolio mit der maximalen Diversification Ratio (DR) ermittelt. Zur Bestimmung dieses Portfolios ist - wie auch bei den anderen, in dieser Analyse behandelten Ansätzen - die Ermittlung der erwarteten Rendite nicht erforderlich. Bei diesem Ansatz geht es darum, den Quotienten aus Portfoliorisiko ohne Diversifikation und dem (tatsächlichen) Portfoliorisiko mit Diversifikation zu maximieren. Für das in den vorherigen Abschnitten herangezogene Beispielportfolio ergeben sich für die jeweiligen Ansätze die folgenden Diversification Ratios:\n\\[DR_{EW}=1,69221368\\]\n\\[DR_{ERB}=1,70560573\\]\n\\[DR_{ERC}=1,75228375\\]\n\\[DR_{GMV}=1,64746376\\]\n\\[DR_{MD}=1,77558125\\]\n\nRisk Parity-Ansatz\n\nIm Vergleich dazu ist es das Ziel des Risk Parity-Ansatzes, das Risikobudget (ERB-Ansatz) bzw. den Risikobeitrag (ERC-Ansatz) zum Portfoliorisiko für alle Anlagen des Portfolios gleich zu gestalten. Dabei wird im Rahmen der vorliegenden Analyse auf die Standardabweichung als Risikomaß zurückgegriffen. (Der ERC-Ansatz kann auch auf andere Risikomaße übertragen werden, siehe Maillard et al., 2009, S. 3). Der ERB-Ansatz berücksichtigt dabei nicht die Korrelationen zwischen den jeweiligen Anlagen bzw. es werden identische Korrelationen zwischen allen jeweiligen Anlagen im Portfolio unterstellt. Dabei kann Folgendes festgestellt werden: Je niedriger (höher) die Standardabweichung einer Anlage ist, desto höher (niedriger) fällt ihre Gewichtung im ERB-Portfolio aus. Hingegen ist der Anteil beim ERC-Ansatz umgekehrt proportional zu dem Betafaktor der Anlage in Bezug zum ERC-Portfolio. Je niedriger (höher) dieses Beta, desto höher (niedriger) der Anteil. Infolgedessen werden Anlagen mit einer relativ geringen Standardabweichung und einer relativ geringen Korrelation mit dem ERC-Portfolio tendenziell bevorzugt.\nFormal können die in den vorherigen Kapiteln vorgenommenen grundlegenden Überlegungen der einzelnen Ansätze wie folgt zusammengefasst werden:\n\\[ \\textrm{EW-Ansatz}: \\quad w_i=w_j \\]\n\\[ \\textrm{ERB-Ansatz}: \\quad w_i\\cdot \\sigma_i=w_j \\cdot \\sigma_j\\]\n\\[ \\textrm{ERC-Ansatz}: \\quad RB_i=RB_j \\quad \\textrm{bzw.} \\quad w_i\\cdot \\frac{\\partial{\\sigma_{ERC}}}{\\partial{w_i}}=w_j\\cdot \\frac{\\partial{\\sigma_{ERC}}}{\\partial{w_j}}\\]\n\\[ \\textrm{GMV-Ansatz}: \\quad MRB_i=MRB_j \\quad \\textrm{bzw.} \\quad \\frac{\\partial{\\sigma_{GMV}}}{\\partial{w_i}}= \\frac{\\partial{\\sigma_{GMV}}}{\\partial{w_j}}\\]\n\\[ \\textrm{MD-Ansatz}: \\quad \\frac{MRB_i}{\\sigma_i}=\\frac{MRB_j}{\\sigma_j} \\quad \\textrm{bzw.} \\quad \\frac{1}{\\sigma_i}\\cdot \\frac{\\partial{\\sigma_{MD}}}{\\partial{w_i}}=\\frac{1}{\\sigma_j}\\cdot  \\frac{\\partial{\\sigma_{MD}}}{\\partial{w_j}}\\]\nmit:\n\\[ \\sigma_{ERC}, \\sigma_{GMV}, \\sigma_{MD}=\\textrm{Standardabweichung des ERC-, GMV- bzw. MD-Portfolios.} \\]\nDie Gewichtungen der einzelnen Anlagen im Portfolio ergeben sich dann wie folgt, wobei jeweils gilt: \\(\\Sigma^N_{n=1} w_n=1\\):\n\\[ \\textrm{EW-Ansatz}: \\quad w^{EW}_n=\\frac{1}{N} \\]\n\\[ \\textrm{ERB-Ansatz}: \\quad w^{ERB}_n=\\frac{1/\\sigma_n}{\\Sigma^N_{i=1}1/\\sigma_i} \\]\n\\[ \\textrm{GMV-Ansatz}: \\quad w^{GMV}_n=\\frac{RB_n}{\\sigma_{GMV}}=\\frac{RB_n}{MRB_n} \\]\n\\[ \\textrm{ERC-Ansatz}: \\quad w^{ERC}_n=\\frac{1}{N\\cdot\\beta^{ERC}_n} \\]\n\\[ \\textrm{MD-Ansatz}: \\quad w^{MD}_n=\\underset{w}{\\operatorname{max}} DR(w) \\]\nZu beachten ist dabei beim GMV- und beim ERC-Ansatz, dass zur Ermittlung der Gewichtung \\(w_n\\) gemäß den hier dargestellten Formeln das zu erstellende Portfolio bereits bekannt sein muss.\nEs lässt sich zeigen, dass die sich ergebenden Standardabweichungen der Portfolios ex ante wie folgt zusammenhängen (vgl. Roncalli, 2014, S. 174): \\(\\sigma_{GMV}\\leq \\sigma_{ERB} \\leq \\sigma_{EW}\\) bzw. \\(\\sigma_{GMV}\\leq \\sigma_{ERC} \\leq \\sigma_{EW}.\\) Ein Vergleich zwischen ERB- und ERC-Portfolio führt nicht zu eindeutigen Ergebnissen. So kann \\(\\sigma_{ERB}\\) größer, gleich oder kleiner als \\(\\sigma_{ERC}\\) sein. Für das Maximum-Diversification-Portfolio gilt zwar ebenfalls, dass \\(\\sigma_{GMV}\\leq \\sigma_{MD}\\), aber ein Vergleich mit den Standardabweichungen der ERC- und ERB-Portfolios führt nicht zu eindeutigen Ergebnissen.\nDarüber hinaus kann festgestellt werden, dass beim EW-, ERB- und beim ERC-Ansatz (Long-only) alle Anlagen im Portfolio repräsentiert sind, d.h., \\(w_n&gt;0\\). Hingegen kann es sowohl beim GMV-Ansatz als auch beim MD-Ansatz vorkommen, dass einzelne Anlagen nicht im Portfolio enthalten sind, d.h., \\(w_n\\) kann Null werden, wobei hier von einer Long-only-Strategie ausgegangen wird, so dass negative Anteile (Leerverkäufe) ausgeschlossen sind.\nSofern die Korrelationen der einzelnen Anlagen untereinander und damit auch zwischen den einzelnen Anlagen und dem Portfolio jeweils identisch sind, würden sich beim ERC-Ansatz die gleichen Gewichtungen wie beim ERB-Ansatz und beim MD-Ansatz ergeben. Darüber hinaus stimmen das MD-Portfolio und das GMV-Portfolio bei gleichen Standardabweichungen aller Anlagen n überein (vgl. Roncalli, 2014, S. 174; Choueifaty und Coignard, 2008, S. 43). In diesem Fall entsprechen sich auch die Gewichtungen des EW-Portfolios und des ERB-Portfolios.\nERC- und GMV-Portfolio entsprechen sich dann, wenn die Korrelationen zwischen den Anlagen gleich sind und sich zudem dem folgenden (Grenz-) Wert annähern (vgl. Maillard et al., 2009, S. 8 und S. 21):\n\\[ Corr(r_i, r_j)=\\frac{-1}{N-1}.\\]\nWürden die Korrelationen zwischen den Anlagen genau diesen Wet annehmen, dann würde die Varianz des Portfolios gemäß der gewichteten Varianz-Kovarianzmatrix den geringstmöglichen Wert aufweisen (Null). Dieser Wert entspricht auch dem minimal möglichen Varianzwert, d.h., dem Wert des GMV-Portfolios. Daher sind die Gewichtungen des GMV-Portfolios und des ERC-Portfolios bei dem o.g. speziellen Korrelationswert dieselben.\nIm Hinblick auf das zu erwartende Rendite-Risikoverhältnis ist aus portfoliotheoretischer Sicht nur eine Kombination aus risikoloser Anlage und dem in der obigen Abbildung (aus dem Abschnitt zum GMVP) dargestellten Marktportfolio sinnvoll, da alle anderen Portfolios eine geringere Effizienz aufweisen. Diese Kombination bedeutet gleichzeitig die (ex ante) maximale Steigung der Kapitalmarktlinie und damit die (ex ante) maximale Sharpe-Ratio. Entsprechend kann unter Berücksichtigung von Risiko und Rendite die Maximierung der Sharpe-Ratio als Ziel der Assetallokation formuliert werden:\n\\[\\underset{w}{\\operatorname{max}} SR=\\frac{E(r_p)-r_f}{\\sigma_p}, \\quad \\textrm{wobei} \\quad \\Sigma^{N}_{n=1}w_n=1. \\]\nEs lässt sich zeigen, dass das ERC-Portfolio dem Portfolio mit der maximalen Sharpe-Ratio entspricht, wenn identische Korrelationen zwischen den Anlagen und identische Sharpe-Ratios für alle Anlagen im Portfolio unterstellt werden (vgl. Roncalli, 2014, S. 123 ff.). Ferner gilt für den MD-Ansatz, dass in dem Fall einer identischen Sharpe-Ratio für alle Anlagen des Portfolios die Diversification Ratio proportional zur Sharpe-Ratio ist. Dies bedeutet gleichermaßen, dass dann eine Maximierung der Diversification Ratio äquivalent mit der Maximierung der Sharpe-Ratio ist. In diesem speziellen Fall entsprechen sich somit das Maximum Sharpe-Ratio Portfolio bzw. das Marktportfolio der Kapitalmarkttheorie und das MD-Portfolio (vgl. Choueifaty und Coignard, 2008, S. 41; Roncalli, 2014, S. 171). Somit weist das MD-Portfolio nur in dem speziellen Fall identischer Sharpe-Ratios aller einbezogenen Anlagen die höchste Sharpe-Ratio auf. Allerdings spielt die Sharpe-Ratio bei der Ermittlung der Gewichtungen der einzelnen Anlagen im Portfolio keine Rolle, weil das Risiko-Rendite-Profil nicht in die Betrachtung einbezogen wird.\nGrundsätzlich ist bei allen vorgestellten Ansätzen zu beachten, dass es sich bei den in die Ermittlung der Anlagengewichtungen eingehenden Volatilitäten und Korrelationen um Prognosewerte für die künftigen Perioden handelt. Sofern diese Werte aus Vergangenheitsdaten abgeleitet werden, müssen sie somit nicht mit den tatsächlichen Werten in den künftigen Perioden übereinstimmen.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html#lernvideos",
    "href": "kapitel7a.html#lernvideos",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "8.5 Lernvideos",
    "text": "8.5 Lernvideos\n\n8.5.1 Video Teil 1\n\n\n\n8.5.2 Video Teil 2\n\n\n\n8.5.3 Video Teil 3",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel7a.html#literatur",
    "href": "kapitel7a.html#literatur",
    "title": "8  Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite",
    "section": "8.6 Literatur",
    "text": "8.6 Literatur\nChoueifaty, Y., Coignard, Y. (2008). Toward maximum diversification. Journal of Portfolio Management (Fall 2008), S. 40–51.\nChoueifaty, Y., Froidure, T., Reynier, J. (2013). Properties of the most diversified portfolio. Journal of Investment Strategies 2 (Spring 2013), S. 49-70.\nClarke, R., de Silva, H., Thorley, S. (2006). Minimum-variance portfolios in the U.S. equity market. Journal of Portfolio Management (Fall 2006), S. 1-14.\nClarke, R., de Silva, H., Thorley, S. (2011). Minimum-variance portfolio composition. Journal of Portfolio Management (Winter 2011), S. 31-45.\nDemey, P., Maillard, S., Roncalli, T. (2010). Risk-based indexation. Working paper.\nKleeberg, J.M. (1995). Der Anlageerfolg des Minimum-Varianz-Portfolios, Bad Soden.\nKleeberg, J.M. (2002). Internationale Minimum-Varianz-Strategien. In: Kleeberg, J.M. & Rehkugler, H. (Hrsg.): Handbuch Portfoliomanagement, 2. Auflage, Bad Soden/Ts., S. 361-382.\nMaillard, S., Roncalli, T., Teiletche, J. (2009). On the properties of equally-weighted risk contributions portfolios. Working paper, Mai 2009.\nRoncalli, T. (2014). Introduction to risk parity and budgeting, Boca Ration, Florida.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Risikogesteuerte Ansätze: Verzicht auf die Schätzung der erwarteten Rendite</span>"
    ]
  },
  {
    "objectID": "kapitel8a.html",
    "href": "kapitel8a.html",
    "title": "9  Index Tracking",
    "section": "",
    "text": "9.1 Motivation\nDie folgenden Ausführungen sind angelehnt an Kapitel 4 in Poddig et al. (2009).\nUnter dem Begriff “Index Tracking” wird die Nachbildung eines vorgegebenen Zielportfolios (Target Portfolio) durch ein tatsächlich zu haltendes bzw. zu realisierendes Portfolio (Tracking Portfolio) verstanden. Das Target Portfolio kann dabei das Benchmarkportfolio sein, z.B. ein Marktindex für einen speziellen Wertpapiermarkt. Es ist eine geeignete Konstruktion des Tracking Portfolios gesucht, welches mit seiner Wertentwicklung möglichst exakt derjenigen des Target Portfolios gleichen soll.\nGrundsätzlich können die Motivationen für Index Tracking in zwei Gruppen kategorisiert werden: 1) Gründe die in der Anlagephilosophie und der Einstellung der (Portfolio-) Managements liegen oder aus speziellen Handelsstrategien resultieren, und (2) solche, die eher “technischen” Charakter haben.\nDer ersten Gruppe liegt die Unterscheidung zwischen aktivem und passivem Portfoliomanagement zugrunde. Die Portfoliokonstruktion durch Verfahren der absoluten und relativen Optimierung basiert auf der Vorstellung informationsineffizienten Kapitalmärkte und auf dem Glauben des Portfoliomanagements an die eigenen, tendenziell überlegenen Prognosefähigkeiten. Das Portfoliomanagement ist überzeugt, Prognosen über die zukünftige Marktentwicklung in einer Güte bereitstellen zu können, dass die aus deren Umsetzung resultierende systematische (risikoadjustierte) Extrarendite das aktiven Portfolios die Kosten der Informationsbeschaffung, -auswertung und des aktiven Managements übersteigt. Reichen die eigenen Prognosefähigkeiten nicht aus oder erweist sich der gesamte Prozess des aktiven Portfoliomanagements als zu kostenintensiv (relativ zu den erzielbaren Extrarenditen), so ist davon konsequenterweise Abstand zu nehmen. Folgerichtig kann es in diesem Fall nur noch darum gehen, das vorgegebene Benchmarkportfolio möglichst kostengünstig zu implementieren.\nZum anderen können spezielle Handelsstrategien die Replikation eines Index erfordern. Beispielsweise sei hier auf den Handel oder die Emission von Indexprodukten und -derivaten hingewiesen. Ebenso basieren bestimmte Arbitragestrategien auf Indexportfolios.\nDie “technischen” Gründe für ein Index Tracking können sehr vielfältig sein und natürlich auch im Zusammenhang mit der bewussten Entscheidung für ein passives Management oder bei Verwendung spezieller Handelsstrategien auftreten. Diese lassen sich im Wesentlichen auf zwei zentrale Ursachen reduzieren, nämlich dass der Erwerb des Target Portfolios oder Teilen davon (1) unmöglich bzw. unzulässig oder aber (2) zu teuer ist. So kann z.B. als Target Portfolio ein sogenannter synthetischer (Kapitalmarkt-) Index vorgegeben sein, welcher ein nichtkäufliches, fiktives (Wertpapier-) Portfolio darstellt. Ein anderer Grund, warum bestimmte Assets des Target Portfolios nicht oder nicht in dem benötigten Umfang erworben werden können, besteht in rechtlichen, statutarischen oder anlagekonzeptionellen Beschränkungen.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Index Tracking</span>"
    ]
  },
  {
    "objectID": "kapitel8a.html#konstruktion-von-tracking-portfolios",
    "href": "kapitel8a.html#konstruktion-von-tracking-portfolios",
    "title": "9  Index Tracking",
    "section": "9.2 Konstruktion von Tracking Portfolios",
    "text": "9.2 Konstruktion von Tracking Portfolios\n\n9.2.1 Überblick\nZur Nachbildung eines Target Portfolios (Benchmarkportfolio, Marktindex, etc.) existieren vielfältige Möglichkeiten. Eine unmittelbar nahe liegende Variante besteht in der effektiven Nachbildung (Full Replication). Dabei werden alle im nachzubildenden Target Portfolio enthaltenen Assets mit ihrer dort zugrunde gelegten Gewichtung in das Tracking Portfolio aufgenommen. Dieser Ansatz führt per Konstruktion zur exakten Replikation des Target Portfolios, ist aber aus den oben genannten Gründen (u.a. hohe Kosten) in der Praxis nur selten anwendbar. Als Folge resultiert die Notwendigkeit zu einer approximativen Nachbildung (Sampling). Hier weicht das Tracking Portfolio in seiner Zusammensetzung zwar (mitunter deutlich) von dem Target Portfolio ab, soll dieses aber in seiner Wertentwicklung möglichst exakt verfolgen (“tracking”). Die grundlegenden Verfahrensansätze sind dabei einerseits eher heuristischer Natur (Stratifying Sampling) oder basieren auf einem Optimierungsansatz (Optimizing Sampling). Verfahren des Stratifying Sampling werden im Folgenden aufgrund ihrer fehlenden theoretischen Fundierung nicht behandelt. Die nachfolgenden Betrachtungen sind dem Optimizing Sampling gewidmet. Es werden nacheinander Verfahren der quadratischen Optimierung, der Datenanalyse, und der linearen Optimierung vorgestellt.\n\n\n9.2.2 Verfahren der quadratischen Optimierung\n\n9.2.2.1 Relative Optimierung und Index Tracking\nDie folgenden Darstellungen zeigen, wie sich das Verfahren der relativen Optimierung mit nur wenigen Modifiktionen “umrüsten” läßt, um die Struktur eines “optimalen” Tracking Portfolios zu bestimmen.\nGrundsätzlich kann die Aufgabenstellung bei der Konstruktion eines Tracking Portfolios durch zwei Punkte charakterisiert werden:\n\nEs ist ein Target Portfolio (Benchmark, Index, etc.) vorgegeben, dessen Wertentwicklung und Risiko so genau wie möglich mithilfe eines noch zu bestimmenden Tracking Portfolios verfolgt (repliziert) werden soll.\nAufgrund verschiedener Gründe ist das Tracking Portfolio möglicherweise aus Assets zu bilden, die nicht im Target Portfolio enthalten sind. Ebenso könnten nicht alle im Target Portfolio enthaltenen Assets für eine Aufnahme in das Tracking Portfolio zur Verfügung stehen bzw. hinsichtlich des Anteilsgewichts im Tracking Portfolio beschränkt sein. Die Anlageuniversen und Restriktionen von Target und Tracking Portfolio können also sehr unterschiedlich sein.\n\nOffensichtlich ähnelt diese Problemstruktur deutlich derjenigen bei der relativen Optimierung mit unterschiedlichen Anlageuniversen. Allerdings soll hier nicht das Portfolio-Alpha gegen das residuale (oder aktive) Risiko maximiert werden, denn die Zielsetzung bei der relativen Optimierung trifft nicht auf die hier verfolgte Zielsetzung zu.\nFür die Bestimmung des Tracking Portfolios stellt sich daher die Frage, wann das Benchmarkportfolio “möglichst gut” nachgebildet ist. Intuitiv muss das Tracking Portfolio folgende Eigenschaften besitzen:\n\nDas Tracking Portfolio-Alpha (relativ zur Benchmark, dem Target Portfolio) muss gleich null sein (da das Benchmark-Alpha gleich null ist).\nDas Tracking Portfolio-Beta muss gleich eins sein (da das Benchmark-Beta gleich eins ist).\nDas residuale (=aktive) Risiko muss minimal sein.\n\nDie Zielfunktion für die Optimierung leitet sich von dem Gedanken ab, mit dem Tracking Portfolio so eng wie möglich die Benchmark zu verfolgen. Dies entspricht der Minimierung des aktiven Risikos \\(\\sigma^2_{AP}\\), welches sich unter Ausschluss der Timingkomponente (d.h. \\(\\beta_P=1\\)) als residuales Risiko \\(\\sigma^2_{\\epsilon_P}\\) ergibt. Die Zielfunktion lautet somit:\n\\[\n\\begin{split}\n\\\\(1a) \\quad ZF(w) = \\sigma^2_{\\epsilon_P} \\rightarrow \\min_{w}!, \\\\\n\\end{split}\n\\]\nbzw. in Matrizenschreibweise unter Verwendung der bekannten Beziehung \\((\\sigma^2_{\\epsilon_P}=\\sigma^2_P-\\beta^2_P*\\sigma^2_B)\\):\n\\[ (1b) \\quad ZF(w) = w_P^T\\Sigma w_P-(w_P^T\\beta)^2*w_B^T\\Sigma w_B \\rightarrow \\min_{w}! \\]\nDie zentralen Nebenbedingungen entsprechen denen bei der relativen Optimierung:\n\\[\n\\begin{split}\n& \\text{(a)}\\ w^{T}\\iota = 1 \\quad bzw. \\quad \\ w_A^{T}\\iota = 0 \\qquad \\text{(Budgetrestriktion)}, \\\\\n& \\text{(b)}\\ w\\geqq 0 \\qquad \\text{(Leerverkaufsverbot)}, \\\\\n& \\text{(c)}\\ \\beta_P=1 \\quad \\Leftrightarrow \\quad \\beta_{AP}=0 \\quad \\text{(kein Timing)}.\n\\end{split}\n\\]\nUm das Benchmarkportfolio in seinen zentralen Eigenschaften nachzubilden, muss zwingend neben einem Portfolio-Beta \\(\\beta_P\\) von eins ein Portfolio-Alpha \\(\\alpha_P\\) von null gefordert werden:\n\\[\n\\begin{split}\n& \\text{(d)}\\quad \\alpha_P=0 \\quad \\text{(keine Selektion)}.\n\\end{split}\n\\]\nDa das Tracking Portfolio aus anderen Assets als die Benchmark selbst zusammengestellt werden muss, kommt es ungewollt, aber auch unvermeidbar zu einem Selektionseffekt. Die Nebenbedingung nach Gleichung (d) erzwingt zwar, dass kein systematischer Selektionseffekt in Form eines positiven oder negativen Portfolio-Alphas auftritt (oder auftreten darf), temporäre (unsystematische) Abweichungen von Tracking Portfolio- und Benchmarkrendite sind aber unausweichlich. Diese äußern sich unter den gesetzten Nebenbedingungen im unvermeidbaren Selektionsrisiko, welches hier ebenfalls dem unausweichlichen “aktiven” Risiko entspricht. Dieses sollte aber möglichst klein sein, weshalb dasjenige Portfolio gesucht wird, welches das geringstmögliche, unvermeidbare Selektionsrisiko (=aktives Risiko) besitzt.\n\n\n9.2.2.2 Herleitung des Tracking Errors (TE)\nSoweit das Tracking Portfolio nicht exakt dem Benchmarkportfolio entspricht, kann eine Renditedifferenz (=aktive Rendite) zwischen Tracking Portfolio und Benchmarkportfolio entstehen:\n\\[ (2) \\quad r_A=r_P-r_B \\]\nmit\n\n\\(r_{A}\\) : aktive Rendite\n\\(r_{P}\\) : Rendite des Tracking Portfolios\n\\(r_{B}\\) : Rendite des Benchmarkportfolios.\n\nUnter Annahme eines univariaten, linearen Renditegenerierungsprozesses unter Verwendung des Target Portfolios als Benchmark gilt für die Rendite des Tracking Portfolios:\n\\[ (3) \\quad r_P=\\alpha_P + \\beta_P*r_B+\\epsilon_P, \\]\nmit:\n\n\\(\\alpha_P\\): autonome Eigenrendite des Portfolios \\(P\\), Konstante\n\\(\\beta_P\\): Sensitivität gegenüber dem Benchmarkportfolio \\(B\\)\n\\(\\epsilon_P\\): unsystematische, zufällige, nicht erklärbare Restgröße (auch Residualrendite oder residuale Rendite genannt).\n\nDamit folgt für die aktive Rendite unter Verwendung der Nebenbedingungen nach Gleichung (c) und (d):\n\\[ (4) \\quad r_A=r_P-r_B=\\alpha_P + \\beta_P*r_B+\\epsilon_P-r_B=\\alpha_P+\\epsilon_P=\\epsilon_P. \\]\nFür den Erwartungswert der aktiven Rendite folgt unter den Standardannahmen eines Renditegenerierungsprozesses:\n\\[ (5) \\quad E(r_A)=E(\\epsilon_P)=0. \\]\nDie Varianz (bzw. alternativ die Standardabweichung) der aktiven Rendite wird beim Index Tracking als sogenannter Tracking Error (TE) bezeichnet:\n\\[ (6a) \\quad TE=Var(r_A)= Var(r_P-r_B) \\quad bzw. \\\\\n(6b) \\quad TE=\\sqrt{(Var(r_A))}=\\sqrt{Var(r_P-r_B)} \\]\nDa für die Varianz einer Zufallsvariable \\(X\\) gilt: \\(Var(X)=E(X^2)-E(X)^2\\), lässt sich Gleichung (6a) auch in Gleichung (7) überführen:\n\\[ (7) \\quad Var(r_P-r_B)= E((r_P-r_B)^2)-E(r_P-r_B)^2 \\\\\n\\quad = E((r_P-r_B)^2)-E(\\epsilon_P)^2=E((r_P-r_B)^2). \\]\nWie im Kapitel zur relativen Optimierung dargestellt, lässt sich das auf die aktive Position zurückzuführende Risiko, das aktive Risiko, auch über Gleichung (8) definieren:\n\\[ (8) \\quad \\sigma^2_{AP}=w^T_A\\Sigma w_A=Var(r_A) \\]\nwobei \\(w_A\\) den Spaltenvektor der aktiven Gewichte \\((w_A=w_P-w_B)\\) des Tracking Portfolios bezeichnet. Im Kontext des Index Tracking stellt also Gleichung (8) zugleich den Tracking Error dar. Der Tracking Error ist in diesem Kontext also die “aktive” Varianz des Tracking Portfolios. Somit gilt gemäß Gleichung (2) im Abschnitt “Aktives Beta” der relativen Optimierung auch:\n\\[ (9) \\quad TE=\\sigma^2_{AP}=\\beta^2_{AP}\\sigma^2_B + \\sigma^2_{\\epsilon_P} \\]\nWegen der Nebenbedingung nach Gleichung (c) verkürzt sich der Ausdruck nach Gleichung (9) bei diesem Ansatz zu Gleichung (10).\n\\[ (10) \\quad TE=\\sigma^2_{AP}= \\sigma^2_{\\epsilon_P} \\]\nMit der Zielfunktion nach Gleichung (1) wird also bei diesem Ansatz zur Bestimmung des Tracking Portfolios der Tracking Error minimiert, was dem üblichen Vorgehen zur Bestimmung eines Tracking Portfolios entspricht. Unter Berücksichtigung der mit Gleichung (7) hergeleiteten Beziehung gilt bei diesem Ansatz ferner:\n\\[ (10) \\quad TE=\\sigma^2_{AP}= \\sigma^2_{\\epsilon_P}=E((r_P-r_B)^2). \\]\nDie Zielfunktion nach Gleichung (1) lässt sich damit bei diesem Ansatz alternativ nach Gleichung (11) schreiben:\n\\[ (11) \\quad ZF(w)= E((r_P-r_B)^2) \\rightarrow \\min_{w}! \\]\nDamit wird der inhaltliche Gehalt der Zielfunktion nach Gleichung (1) deutlich, denn die Minimierung von Gleichung (1) ist bei diesem Ansatz gleichbedeutend mit der Minimierung des Erwartungswertes der quadrierten Renditedifferenzen zwischen Tracking Portfolio und Benchmark. Insofern wird hier also der (erwartete) Mean Squared Error zwischen den Renditen des Tracking Portfolios und der Benchmark minimiert.\nDas Problem der Bestimmung eines Tracking Portfolios lässt sich also verfahrenstechnisch insgesamt als Spezialfall der relativen Optimierung bei unterschiedlichen Anlageuniversen auffassen. Dazu sind lediglich eine Modifikation der Zielfunktion und das Hinzufügen der Nebenbedingung nach Gleichung (d) erforderlich.\n\n\n9.2.2.3 Index Tracking nach Markowitz (1987)\nAusgangspunkt der folgenden Überlegungen ist wiederum ein Tracking Portfolio, welches in seiner Zusammensetzung (zwangsläufig) vom Target Portfolio abweichen muss, da sich die Anlageuniversen unterscheiden können und aus Kostengründen das Tracking Portfolio in der Regel mit weitaus weniger Assets gebildet werden soll als im Target Portfolio enthalten sind. Das Tracking Portfolio ist daher wie ein aktives Portfolio anzusehen, es besitzt in unvermeidlicher Weise eine aktive Rendite und ein aktives Risiko. Ein ideales Tracking Portfolio hat eine aktive Rendite und ein aktives Risiko von null.\nDie aktive Position ist definiert als Differenzgewichte zwischen gehaltenem (Tracking) Portfolio \\(P\\) und Target Portfolio \\(B\\), welches mit dem Benchmarkportfolio gleichgesetzt werden soll:\n\\[ (1) \\quad w_A= w_P-w_B \\]\nDie erwartete aktive Rendite (Bonus Return) ist die erwartete Renditedifferenz zwischen (Tracking) Portfolio \\(P\\) und Benchmark \\(B\\) (das Target Portfolio):\n\\[ (2) \\quad \\mu_A= \\mu_P-\\mu_B=w^T_P \\mu - w^T_B \\mu = (w^T_P-w^T_B) \\mu = w^T_A \\mu \\]\nmit \\(\\quad \\mu : \\quad\\) Spaltenvektor der erwarteten Assetrenditen.\nDas aktive Risiko (die aktive Varianz) ergibt sich als:\n\\[ (3) \\quad Var(r_A)=\\sigma^2_{AP}=w^T_A \\Sigma w_A. \\]\nDies ist zugleich die übliche Definition für den Tracking Error (vgl. Gleichung (8) oben):\n\\[ (4) \\quad TE=Var(r_A) =Var(r_P-r_B). \\]\nDer Optimierungsansatz besteht nun darin, den Tracking Error unter Berücksichtigung verschiedener Nebenbedingungen zu minimieren. Die Zielfunktion lautet also:\n\\[ (5) \\quad ZF(w)= TE= Var(r_A)=\\sigma^2_{AP}=w^T_A \\Sigma w_A \\rightarrow \\min_{w}! \\]\nAls zentrale Nebenbedingung wird dabei gefordert, dass die erwartete aktive Rendite ein gefordertes Niveau von \\(\\mu^*\\) besitzt, wobei im Regelfall \\(\\mu^*=0\\) gesetzt wird:\n\\[ (6) \\quad \\mu_A=w^T_A \\mu = \\mu^* (=0, i.d.R.) \\]\nDie weiteren Nebenbedingungen betreffen die Budgetrestriktion, die Nichtnegativitätsbedingung für die Anteilsgewichte (sofern Leerverkäufe ausgeschlossen sind), geforderte und zulässige Mindest- und Höchstanteilsgrenzen sowie ggf. weitere sinnvoll erscheinende Restriktionen.\nIn der praktischen Anwendung wird oftmals die Nebenbedingung nach Gleichung (6) vernachlässigt. Dies besitzt zunächst zwei Vorteile. Zum einen wird dadurch das Optimierungproblem vereinfacht. Zum anderen muss keine Schätzung der erwarteten Renditen bereitgestellt werden (die man ja auch gerade durch das Index Tracking vermeiden möchte). Allerdings kann jetzt eine Lösung resultieren, bei welcher die erwartete aktive Rendite negativ ausfällt.\n\n\n9.2.2.4 Vergleich beider Ansätze\nDer Markowitz Ansatz besitzt den vordergründigen Vorteil, mit wenigen und vergleichsweise unproblematisch zu schätzenden Größen auszukommen. Verzichtet man bei der Bestimmung des Tracking Portfolios auf die Nebenbedingung nach Gleichung (6), so ist lediglich eine Schätzung der zukünftigen Varianz-Kovarianzmatrix vorzunehmen. Diese kann mittels der empirischen Varianz-Kovarianzmatrix erfolgen, die in den meisten Fällen durchaus “brauchbare” Schätzungen liefert. Auf die kritische und zugleich sehr schwierige Schätzung der Erwartungswerte der Assetrenditen (auf den Vektor \\(\\mu\\)) wird konsequent verzichtet. Insofern kommt dieser Ansatz mit wenigen und in der Tendenz eher unkritischen sowie einfach zu schätzenden Inputparametern aus.\nIm Gegensatz zu diesem Ansatz erfordert das Index Tracking gemäß relativer Optimierung zusätzlich die eher aufwändigere und zugleich kritischere Schätzung der Alpha- und Beta-Parameter der einzelnen Assets. Auf den ersten Blick ist damit dieser Ansatz im viel stärkeren Ausmaß der Schätzproblematik zukünftiger Größen ausgesetzt.\nDer Markowitz-Ansatz ist jedoch nur deshalb nicht jener zusätzlichen Schätzproblematik ausgesetzt, weil diese schlichtweg ignoriert wird! Ohne Berücksichtigung der Nebenbedingung nach Gleichung (6) ist nämlich nicht ausgeschlossen, dass\n\ndas Tracking Portfolio eine negative aktive Rendite (im Erwartungswert) besitzen wird und dass\nes ein von eins abweichendes Beta haben kann, also eine ungewollte Timing-Komponente aufweisen wird.\n\nWill man diese beiden Effekte kontrollieren, muss die Nebenbedingung nach Gleichung (6) wieder hinzugefügt und eine Schätzung der Erwartungswerte der Assetrenditen vorgenommen werden. Vor diesem Hintergrund sind letztendlich beide Ansätze hinsichtlich der entstehenden Schätzproblematik gleichwertig.\n\n\n\n9.2.3 Regression unter Nebenbedingungen\nDieses Verfahren kann als regressionsanalytischer Ansatz formuliert werden. Die Idee besteht darin, die für einen vergangenen Beobachtungszeitraum \\(t=1, ..., T\\) erhobenen Renditen der Benchmark \\(r_{Bt}\\) (abhängige Variable einer multivariaten linearen Kleinste-Quadrate Regression) durch die Renditen \\(r_{it}\\) von \\(N\\) Assets (unabhängige Variablen) zu erklären. Für einen beliebigen Zeitpunkt \\(t\\) soll also gelten:\n\\[ (1) \\quad r_{Bt}=w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}+\\epsilon_t. \\]\nDas (Regression-) Residuum \\(\\epsilon_t\\) stellt hier den unsystematischen, nicht weiter erklärbaren, zufälligen Restanteil in Bezug auf die Benchmarkrendite dar. Der “Tracking Error” (Renditedifferenz, aktive Rendite) \\(\\epsilon_t\\) ergibt sich als einfache Umformung von Gleichung (1). Der Summenausdruck der rechten Seite von Gleichung (1) bzw. der Klammerausdruck in Gleichung (2) stellt dabei offensichtlich die Rendite des Tracking Portfolios dar:\n\\[ (2) \\quad \\epsilon_t=r_{Bt}-(w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}). \\]\nDas “optimale” Tracking Portfolio besitzt den minimalen “Tracking Error” über \\(T\\) Perioden, erfüllt damit also folgende Bedingung:\n\\[ (3) \\quad \\Sigma^T_{t=1}\\epsilon^2_t=\\Sigma^T_{t=1}(r_{Bt}-(w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}))^2 \\rightarrow \\min_{w}!\\ \\]\nStreng genommen beinhaltet Gleichung (3) eine ex post Forderung an das optimale Tracking Portfolio, wobei die Schätzung der unbekannten, gesuchten Gewichte \\(w_{Pi}\\) anhand von ex ante Beobachtungen vorgenommen wird. Dabei wird die zentrale Annahme gesetzt, dass die in der Vergangenheit beobachteten Verhältnisse (Verteilung der Benchmark- und Assetrenditen) in derselben Weise weiterhin in der Zukunft Bestand haben werden. Die zu minimierende Zielfunktion lautet damit vollständig:\n\\[ (4) \\quad ZF(w)=\\Sigma^T_{t=1}\\epsilon^2_t=\\Sigma^T_{t=1}(r_{Bt}-(w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}))^2 \\rightarrow \\min_{w}!\\ \\]\nVergleich mit den Verfahren der quadratischen Optimierung\nWährend die Zielfunktion dieses Ansatzes in Gleichung (4) eine enge inhaltliche Verwandtschaft zu den vorhergehenden Ansätzen zeigt, ist die Schätztechnik eine völlig andere. Die beiden oben vorgestellten Verfahren der quadratischen Optimierung ermitteln das Tracking Portfolio bei genauer Betrachtung mithilfe zweier separater Schritte;\n\nErmittlung der benötigten Inputparameter für die Optimierung: Dies sind je nach Verfahren und Detaillierungsgrad die Schätzung der Varianz-Kovarianzmatrix \\(\\Sigma\\), des erwarteten Renditevektors \\(\\mu\\) bzw. der Alpha- und Beta-Werte. Diese Schätzungen können, müssen aber nicht auf (einfachen) historischen Schätzungen basieren. Sie können auch mittels gänzlich anderer Verfahren und Vorgehensweisen bereitgestellt werden.\nErmittlung des Tracking Portfolios durch Optimierung einer Zielfunktion, basierend auf den Inputparametern aus Schritt 1.\n\nDer Regressionsansatz verzichtet dagegen auf ein zweistufiges Vorgehen. Die Ermittlung des Tracking Portfolios erfolgt direkt in einem Schritt über die Durchführung einer Kleinste-Quadrate Regression unter Nebenbedingungen. Der Vorteil besteht in dem verfahrenstechnisch sehr einfachen Vorgehen, welches umständliche Zwischenschritte der Schätzung benötigter Inputparameter vermeidet. Gleichzeitig liegt hierin aber auch der entscheidende Nachteil begründet. Bessere Schätzverfahren als die einfache historische Schätzung lassen sich hiermit nicht berücksichtigen. Die Ansätze der quadratischen Optimierung sind diesbezüglich wesentlich flexibler. Bessere Schätzverfahren für die benötigten Inputparameter können jederzeit durch Austausch der betreffenden Verfahren integriert werden, ohne das grundsätzliche Vorgehen zu ändern. Dies stellt einen wesentlichen Vorteil dar.\n\n\n9.2.4 Lineare Optimierung\nBeim im letzten Abschnitt vorgestellten Regressionsansatz zur Bestimmung eines Tracking Portfolios soll die Rendite des Target Portfolios (des Benchmarkportfolios \\(B\\)) für beliebige Zeitpunkte \\(t\\) (in der Zukunft) bestmöglich mittels \\(N\\) Assets nachgebildet werden, wobei ein unvermeidbarer Restfehler \\(\\epsilon_t\\) verbleibt. Die unbekannten, noch gesuchten Größen sind hier die Anteilsgewichte \\(w_{Pi}\\) der \\(N\\) Assets im Tracking Portfolio:\n\\[ (1) \\quad r_{Bt}=w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}+\\epsilon_t. \\]\nWährend die vorher beschriebenen Ansätze nun aber darauf basieren, im Idealfall die Restfehler \\(\\epsilon_t\\) auf \\(\\epsilon_t=0\\) für alle (zukünftigen) Zeitpunkte \\(t\\) zu bringen, wird hier ein anderer Weg gewählt. Die aktive Rendite \\(r_A\\) ist die Differenz zwischen Portfolio- und Benchmarkrendite. Definiert man ferner den Restfehler \\(u_t=-\\epsilon_t\\), so lässt sich Gleichung (1) alternativ nach Gleichung (2) schreiben:\n\\[ (2) \\quad r_{At}=r_{Pt}-r_{Bt}=u_t.  \\]\nEin Investor wird natürlich darauf Wert legen, die Rendite der Benchmark mit dem Tracking Portfolio nicht zu unterschreiten. Er wird also \\(u_t&lt;0\\) auf jeden Fall vermeiden wollen. Dagegen ist es plausibel anzunehmen, dass positive Abweichungen der Rendite des Tracking Portfolios von der Benchmark, also \\(u_t&gt;0\\), durchaus erwünscht sind. Das ideale Tracking Portfolio besitzt nach dieser Auffassung die minimale Summe der Absolutbeträge aller negativen aktiven Renditen (bzw. Restfehler \\(u_t\\)). Es minimiert die erwarteten Verluste des Investors, erhält aber alle Gewinnchancen. Die Zielfunktion zur Bestimmung des Tracking Portfolios lautet damit:\n\\[ (3) \\quad ZF(w)=\\Sigma^T_{t=1\\\\r_{Pt}&lt;r_{Bt}} |r_{Pt}-r_{Bt}| \\rightarrow \\min_{w}! \\]\nDer grundlegende Ansatz lautet also: Bestimme das Tracking Portfolio derart, dass die Summe der Absolutbeträge der (zukünftigen) negativen Renditeabweichungen gegenüber der Benchmark minimiert wird! Dieser Ansatz basiert auf einem einseitigen Risikoverständnis, indem nur Unterschreitungen der Benchmarkrendite als unerwünschte Zustände aufgefasst werden, deren Eintreten vermieden werden soll.\nDie Zielfunktion nach Gleichung (3) bezieht sich streng genommen wiederum auf die Zukunft, beinhaltet also ex post Größen. Für die Optimierung des Tracking Portfolios muss diese wiederum geschätzt werden, wobei die Schätzung üblicherweise anhand von \\(T\\) zurückliegenden Beobachtungsperioden für Benchmark- und Assetrenditen vorgenommen wird (historisch basierte Schätzung).\n\n9.2.4.1 Implementierung der Zielfunktion über die Hilfsvariablen \\(d^+_t\\) und \\(d^-_t\\)\nFür die weitere Darstellung werden zwei Hilfsvariablen eingeführt. Die Hilfsvariable \\(d^+_t\\) bezeichne die positive Differenz zwischen der Rendite des Tracking Portfolios und der der Benchmark als positive Zahl. Umgekehrt wird mit der Hilfsvariable \\(d^-_t\\) die negative Differenz zwischen der Rendite des Tracking Portfolios und der der Benchmark, ebenfalls als positive Zahl, bezeichnet. Die aktive Rendite \\(r_{At}\\) bzw. der Restfehler \\(u_t\\) lässt sich mithilfe dieser beiden Hilfsvariablen schreiben als\n\\[ (4) \\quad r_{At}=u_t=d^+_t-d^-_t \\]\nwobei gilt\n\\[ (5a) \\quad d^+_t=r_{Pt}-r_{Bt},  \\quad wenn \\quad r_{Pt}&gt;r_{Bt} \\\\\nd^+_t=0 \\quad sonst \\]\n\\[ (5b) \\quad d^-_t=r_{Bt}-r_{Pt},  \\quad wenn \\quad r_{Pt}&lt;r_{Bt} \\\\\nd^-_t=0 \\quad sonst. \\]\nPer Definition gilt: \\(d^+_t \\geq 0\\) und \\(d^-_t \\geq 0\\). Außerdem folgt aus \\(d^+_t&gt;0\\) sofort \\(d^-_t=0\\) und umgekehrt, wenn \\(d^-_t&gt;0\\), dann ist \\(d^+_t=0\\). Für jeden Zeitpunkt \\(t\\) gilt damit Gleichung (6), indem Gleichung (4) in Gleichung (2) eingesetzt wird:\n\\[ (6) \\quad r_{Pt}-r_{Bt}=d^+_t-d^-_t.  \\]\nDie Gleichungen (7a) und (7b) sind äquivalent zu Gleichung (6) und gelten ebenfals für jeden Zeitpunkt \\(t\\):\n\\[ (7a) \\quad r_{Pt}-r_{Bt}-d^+_t+d^-_t=0 \\quad bzw. \\\\\n(7b) \\quad r_{Pt}-d^+_t+d^-_t=r_{Bt}.\\]\nSetzt man in (7b) für die Rendite des Tracking Portfolios den bekannten Ausdruck \\(\\Sigma^N_{i=1} w_{Pi}r_{it}\\) ein, so ergibt sich die Variante (7c):\n\\[ (7c) \\quad \\Sigma^N_{i=1} w_{Pi}r_{it}-d^+_t+d^-_t=r_{Bt} . \\]\nDie zu minimierende Zielfunktion nach Gleichung (3) lässt sich unter Verwendung der eingeführten Hilfsvariablen alternativ als Gleichung (8) schreiben:\n\\[ (8) \\quad ZF=\\Sigma^T_{t=1} d^-_t  \\rightarrow \\min! \\]\nIm Zuge der Optimierung sind die Werte der folgenden gesuchten Variablen zu bestimmen:\n\ndie \\(N\\) Anteilsgewichte der Assets \\(w_{Pi}\\).\ndie \\(T\\) Werte für die positiven Renditeabweichungen \\(d^+_t\\) (bzw. positiven aktiven Renditen \\(r_{At}\\) bzw. positiven Restfehler \\(u_t\\)) und\ndie \\(T\\) Werte für die negativen Renditeabweichungen \\(d^-_t\\) (bzw. negativen aktiven Renditen \\(r_{At}\\) bzw. negativen Restfehler \\(u_t\\)),\n\nalso die Werte von \\(N+T+T\\) Problemvariablen. Der Optimierungsansatz besteht hier darin, die Werte der Anteilsgewichte \\((w_{Pi})\\) und der Restfehler \\((d^+_t-d^-_t)\\) gemeinsam so zu ermitteln, dass\n\nin allen \\(t=1, ..., T\\) Perioden die Rendite des Tracking Portfolios abzüglich des Restfehlers der Rendite des Benchmarkportfolios entspricht, also Gleichung (7c) für alle \\(T\\) Perioden erfüllt ist, und\ndie Summe der negativen Restfehler \\(d^-_t\\) dabei ein Minimum annimmt.\n\nDer Optimierungsansatz zur Bestimmung des Tracking Portfolios lautet damit zusammengefasst wie folgt:\n\\[ (9) \\quad ZF=\\Sigma^T_{t=1} d^-_t  \\rightarrow \\min! \\]\nDie zentralen Nebenbedingungen lauten dabei:\n\\[\n\\begin{split}\n& \\text{(10)}\\quad \\Sigma^N_{i=1} w_{Pi}r_{it}-d^+_t+d^-_t=r_{Bt} \\qquad \\text{für alle Zeitpunkte} \\space t=1, ..., T \\\\\n& \\text{(11a)}\\quad d^+_t \\geq0 \\qquad \\text{für alle Zeitpunkte} \\space t=1, ..., T \\\\\n& \\text{(11b)}\\quad d^-_t \\geq0 \\qquad \\text{für alle Zeitpunkte} \\space t=1, ..., T. \\\\\n\\end{split}\n\\]\nHinzu kommen die üblichen Nebenbedingungen wie die Budgetrestriktion, das Leerverkaufsverbot, und eventuell weitere Restriktionen wie geforderte Mindestanteile und zulässige Höchstanteile von Assets im Tracking Portfolio.\nAuch bei diesem Ansatz zur Bestimmung eines Tracking Portfolios besteht eine Schätzproblematik. Die eigentlich zu minimierende Zielfunktion nach Gleichung (3) bezieht sich auf ex post Größen und wird zum Zwecke der konkreten Bestimmung des Tracking Portfolios über ihre ex ante Formulierung, d.h. anhand vergangener Beobachtungen, geschätzt. Die Güte der Schätzung über ihre ex ante Variante ist also dafür entscheidend, ob die Erwartungen an das Tracking Portfolio später auch tatsächlich erfüllt werden. Ein weiterer Aspekt der Schätzproblematik betrifft die Anzahl der gesuchten (Problem-) Variablen bei diesem Ansatz. Neben den eigentlich interessierenden \\(N\\) Anteilsgewichten \\(w_{Pi}\\) des Tracking Portfolios sind bei diesem Optimierungsansatz ferner die Werte der \\(T\\) Hilfsvariablen \\(d^+_t\\) und \\(d^-_t\\) zu bestimmen. Dies sind zusammen \\(N+2T\\) freie Parameter des Optimierungsproblems. Werden beispielsweise für das Tracking Portfolio potenziell 30 Assets vorgesehen und soll die Schätzung der Zielfunktion über einen Beobachtungszeitraum von 240 Monaten auf Basis von Monatsrenditen vorgenommen werden, so resultieren daraus 510 freie, im Zuge der Optimierung zu bestimmende Parameter. Da es sich um ein lineares Optimierungsproblem handelt stellt dies in der Regel aber kein Problem dar.\n\n\n\n9.2.5 Schätzproblematik der Optimierungsparameter\nEin wesentlicher Beweggrund für ein passives Portfoliomanagement ist die Überzeugung, über nicht hinreichende Prognosefähigkeiten zu verfügen, deren Güte im Zuge der aktiven Umsetzung es erlauben würde, ausreichende systematische Extragewinne zu erzielen. Konsequenterweise wird dann auf Prognosen (Schätzungen zukünftiger Größen) verzichtet und die vorgegebene Benchmark über ein Tracking Portfolio verfolgt.\nDie nähere Analyse der Verfahren zur Bestimmung von Tracking Portfolios offenbart aber, dass sobald das passive Management auf die approximative Nachbildung (Sampling) der Benchmark zurückgreift, dieselbe Prognoseproblematik wie beim aktiven Management entsteht. Was wird gewonnen?\nTendenziell wird bei einem Tracking Portfolio, welches\n\ndasselbe Anlageuniversum besitzt wie die Benchmark,\nviele Assets beinhaltet und hinsichtlich der Assetgewichte\neng an die Benchmark orientiert ist,\n\ndie Schätzproblematik weniger ins Gewicht fallen, als bei einem Tracking Portfolio, welches\n\naus einem abweichenden Anlageuniversum zusammengestellt wird bzw. werden muss,\neher wenige Assets beinhaltet und damit bezüglich einbezogener Assets und deren Anteilsgewichte\ndeutlich von der Struktur der Benchmark abweicht.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Index Tracking</span>"
    ]
  },
  {
    "objectID": "kapitel8a.html#beginn-der-fallstudie",
    "href": "kapitel8a.html#beginn-der-fallstudie",
    "title": "9  Index Tracking",
    "section": "9.3 Beginn der Fallstudie",
    "text": "9.3 Beginn der Fallstudie\nWir starten mit dem Import der benötigten Pakete.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nimport statsmodels.regression.linear_model as sm\nimport statsmodels.tools.tools as sm2\n\n\n\n9.3.1 Laden und Beschreiben der Datenbasis\nDer verwendete Datensatz enthält Kurshistorien der folgenden zehn Aktien: Danone, Siemens, BASF, L’Oreal, Allianz, Telecom Italia, Banco Santander, Total, BMW, Vivendi. Zudem ist als elfte Spalte die Indexhistorie des Euro Stoxx 50 verfügbar.\nDie Aufgabenstellung der Fallstudie besteht also darin, auf Basis der zehn Einzeltitel das optimale Tracking Portfolio für das Target Portfolio Euro Stoxx 50 zu erstellen.\nDie Datengrundlage hierfür sind 111 Monatsschlusskurse (“Adjusted Close”) über den Zeitraum vom 31.12.2002 bis zum 28.2.2012.\n\n\nCode\nframe = pd.read_excel('Kapitel A3_4.xlsx', 'Tabelle1', index_col=0, parse_dates=True)\n\n\n\n\nCode\nframe.head(4)\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\nEuroStoxx 50\n\n\n\n\n2002-12-31\n30.2427\n40.50\n18.040\n72.55\n82.025\n2.0558\n5.8537\n33.5794\n28.92\n15.39\n2386.41\n\n\n2003-01-31\n27.6478\n38.15\n17.260\n64.30\n66.860\n2.0199\n5.1466\n30.9888\n27.26\n15.64\n2248.17\n\n\n2003-02-28\n25.9021\n36.78\n16.910\n59.90\n60.137\n1.8927\n5.3256\n30.2486\n26.00\n13.02\n2140.73\n\n\n2003-03-31\n27.2939\n37.80\n17.055\n55.50\n41.080\n2.0074\n5.2361\n28.6202\n25.44\n12.18\n2036.86\n\n\n\n\n\n\n\n\n\n9.3.2 Relative Optimierung und Index Tracking\nDie grundsätzliche Vorgehensweise entspricht der der relativen Optimierung bei unterschiedlichen Anlageuniversen. Auf Basis der Überschussrenditen ermitteln wir den Vektor der zukünftigen erwarteten Assetrenditen \\(\\mu\\) und die zukünftige Varianz-Kovarianzmatrix \\(\\Sigma\\) nach der Methode der historisch basierten Schätzung.\nHinweis: Bei den oben diskutierten Verfahren des Index Trackings ist es unbedeutend, ob von absoluten oder überschüssigen Renditen ausgegangen wird. Wichtig ist nur die konsistente Verwendung.\nSchätz- vs. Validierungszeitraum: Das vorhandene Datenmaterial umfasst insgesamt 111 monatliche Beobachtungen für Kurse bzw. Indexstände, aus denen sich 110 (diskrete) Monatsrenditen für die Einzeltitel und den Index berechnen lassen. Um die Bedeutung der Schätzproblematik zu illustrieren, wird das Datenmaterial in einen Schätzzeitraum, bestehend aus den ersten 60 Monatsrenditen, und einen Validierungszeitraum, bestehend aus den letzten 50 Monatsrenditen, unterteilt. Die Bestimmung der Tracking Portfolios erfolgt stets auf Basis der ersten 60 Beobachtungen (Schätzzeitraum). Nach der Bestimmung des Tracking Portfolios wird anhand des Validierungszeitraums berechnet, welche (mittlere) aktive Rendite und zugehörige Varianz (Tracking Error) das Tracking Portfolio besessen hätte. Bei perfekten Schätzungen der Inputparameter für die jeweiligen Verfahren müssten im Idealfall die Werte für den geschätzten ex ante Tracking Error (anhand des Schätzzeitraums) in etwa mit dem tatsächlichen, ex post Tracking Error des Validierungszeitraums übereinstimmen. Dabei kann zwar eine einzelne Fallstudie keine generellen Aussagen über die Güte der einzelnen Verfahren zulassen, aber dennoch die grundsätzliche Problematik illustrieren.\n\n\nCode\n# calculation based on discrete returns\nreturns = frame.pct_change().dropna()\n\nrf = (1+0.04)**(1/12)-1 # risk-free rate assumed 4% p.a.\nex_returns = returns - rf\n\n# important: use only the first 60 returns!\nmeans = ex_returns.iloc[:60,:].mean().values*100*12 # annualised\nSigma = ex_returns.iloc[:60,:].cov().values # non-annualised\n\n\nDanach berechnen wir auf Basis univariater Regressionen die Alpha- und Beta-Werte relativ zur Benchmark “Euro Stoxx 50”.\n\n\nCode\n# calculating vectors of alphas and betas\nalpha = np.zeros(ex_returns.columns.shape)\nbeta = np.zeros(ex_returns.columns.shape)\n\nx1 = ex_returns['EuroStoxx 50']\nx2 = sm2.add_constant(x1)\n\nfor idx, ticker in enumerate(ex_returns.columns):\n    reg = sm.OLS(ex_returns[ticker].iloc[:60], x2.iloc[:60]).fit()\n    parameter = np.asarray(reg.params)\n    alpha[idx] = parameter[0]\n    beta[idx] = parameter[1]\ndf =pd.DataFrame({'Alpha': alpha, 'Beta': beta}, index=ex_returns.columns)\n\n\n\n\nCode\ndf\n\n\n\n\n\n\n\n\n\nAlpha\nBeta\n\n\n\n\nDanone\n4.099316e-03\n0.594364\n\n\nSiemens\n5.791281e-03\n1.275000\n\n\nBASF\n7.575579e-03\n1.030921\n\n\nL'Oreal\n-4.921888e-03\n1.073291\n\n\nAllianz\n-6.305175e-03\n2.479420\n\n\nTelecom Italia\n-5.946760e-03\n0.570475\n\n\nBanco Santander\n2.719632e-03\n1.214706\n\n\nTotal\n1.871939e-03\n0.600654\n\n\nBMW\n-4.269235e-03\n1.206465\n\n\nVivendi\n1.890327e-03\n1.120708\n\n\nEuroStoxx 50\n2.385245e-18\n1.000000\n\n\n\n\n\n\n\n\n\nCode\nalpha = np.matrix(alpha)\nbeta = np.matrix(beta)\n\n\nWichtige Analogie zum Fall der relativen Optimierung bei unterschiedlichem Anlageuniversum:\nDas Anlageuniversum in der Fallstudie hat elf Assets, nämlich die betrachteten zehn Einzeltitel sowie den EuroStoxx50 Index als “virtuelle” Anlage. Die historisch basierte Berechnung von \\(\\mu\\), \\(\\Sigma\\), \\(\\alpha\\), und \\(\\beta\\) erfolgte oben bereits für diese elf Anlagen.\nIm nächsten Schritt muss der Vektor der (Target Portfolio-) Benchmark-Gewichte derart ausgestaltet sein, dass die ersten zehn Gewichte (für die Einzeltitel) den Wert null und das letzte Gewicht (für den EuroStoxx50) den Wert eins zugewiesen bekommen.\nAls willkürlich gewählte Startlösung wird wieder eine gleichmäßige Aufteilung der Anteilsgewichte auf alle zur Verfügung stehenden Einzeltitel (ein naives Tracking Portfolio) zugrunde gelegt. Hierfür muss der Vektor der Startgewichte für das Tracking Portfolio jeweils den Wert \\(1/10\\) (1/(means.shape[0]-1)) auf den ersten zehn Positionen enthalten, und den Wert null auf der letzten Position.\n\n\nCode\n# calculation of weight vector for tracking portfolio and benchmark/target\n# using EuroStoxx50 as a benchmark implies that all benchmark weights (first N-1)\n# elements are zero and 1 for EuroStoxx50 (last element)\nbench_w = np.zeros(means.shape)\nbench_w[-1]=1.0\nbench_w = np.matrix(bench_w)\n\n# vector of starting weights is equally-weighted for the first N-1 \n# elements and zero for the last element\nWeight_start = np.zeros(means.shape)\nWeight_start[0:-1]=1/(means.shape[0]-1)\nWeight_start = np.matrix(Weight_start)\n\n\nDie Zielfunktion minimiert das residuale Risiko \\(\\sigma^2_{\\epsilon_P} =w_P^T\\Sigma w_P-(w_P^T\\beta)^2*w_B^T\\Sigma w_B\\), welches unter der geforderten Nebenbedingung \\((\\beta_P=1)\\) dem aktiven Risiko \\(\\sigma^2_{AP}\\) und dem Tracking Error \\(E((r_P-r_B)^2)\\) entspricht.\nDie Zielfunktion wird über die Funktion tracking_error1 implementiert.\nDie zusätzliche Nebenbedingung (\\(\\alpha_P=0 \\rightarrow\\) keine Selektion) wird ähnlich wie die Budgetrestriktion und die “No Timing” \\((\\beta_P=1)\\) Restriktion in Form einer lambda-Funktion geschrieben und dem Tuple cons der Nebenbedingungs-Dictionaries hinzugefügt.\n\n\nCode\n# target function: minimize 'residual risk' !\n# alpha, beta, bench_w have to be defined prior as matrices\ndef tracking_error1(w, Sigma):\n    port_w = np.matrix(w) # w is a row (not column!) vector\n    port_alpha = (port_w*alpha.T)[0,0]\n    port_beta = (port_w*beta.T)[0,0]\n    port_var = (port_w * Sigma*port_w.T)[0,0]\n    bench_var = (bench_w * Sigma * bench_w.T)[0,0]\n    resid_var = port_var - port_beta**2*bench_var\n    return resid_var # minimization problem\n\ndef port_beta(w,beta):\n    port_w = np.matrix(w) # w is a row (not column!) vector\n    port_beta = (port_w*beta.T)[0,0]\n    return port_beta\n\ncons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n        {'type': 'eq', 'fun': lambda x: (np.matrix(x)*beta.T)[0,0] - 1},\n        {'type': 'eq', 'fun': lambda x: (np.matrix(x)*alpha.T)[0,0]})\n\nbound = (0.05,0.40)\nbounds = tuple(bound for asset in range(alpha.shape[1]-1))\nbounds += ((0.0, 1e-10), ) # weight of the benchmark is fixed to zero\n\nres1 = minimize(tracking_error1, Weight_start, args=Sigma,\n                        method='SLSQP', bounds=bounds, constraints=cons,tol=1e-10,\n               options={'disp': True})\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.0001331023399440785\n            Iterations: 34\n            Function evaluations: 408\n            Gradient evaluations: 34\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in res1.x],index=ex_returns.columns).T\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\nEuroStoxx 50\n\n\n\n\n0\n0.05\n0.05\n0.0915\n0.1587\n0.05\n0.1203\n0.0987\n0.1969\n0.0585\n0.1254\n0.0\n\n\n\n\n\n\n\nDie beiden zentralen Nebenbedingungen werden eingehalten. Das Tracking Portfolio Alpha ist null und das Beta ist eins.\n\n\nCode\nround(port_beta(res1.x,beta), 6)\n\n\n1.0\n\n\n\n\nCode\nround((np.matrix(res1.x)*alpha.T)[0,0], 6)\n\n\n0.0\n\n\n\n\n9.3.3 Index Tracking nach Markowitz (1987)\nDie Zielfunktion besteht in der Minimierung des Tracking Errors (aktives Risiko):\n\\[ \\quad ZF(w)= TE= Var(r_A)=\\sigma^2_{AP}=w^T_A \\Sigma w_A \\rightarrow \\min_{w}! \\]\nAls zentrale Nebenbedingung wird gefordert:\n\\[ \\quad \\mu_A=w^T_A \\mu =0. \\]\ntracking_error2 implementiert die Zielfunktion und active_return die Berechnung der erwarteten aktiven Rendite. Die Nebenbedingung wird in Form einer lambda-Funktion geschrieben und dem Tuple cons der Nebenbedingungs-Dictionaries hinzugefügt.\n\n\nCode\n# target function: minimize 'active risk'!\n# N.B.: expected active return = 0\ndef tracking_error2(w, Sigma):\n    port_w = np.matrix(w) # w is a row (not column!) vector\n    active_weights = port_w - bench_w\n    active_risk = (active_weights * Sigma * active_weights.T)[0,0]\n    return active_risk # minimization problem\n    \nmeans = np.matrix(means) # means is a row (not column!) vector\n\ndef active_return(w):\n    active_weights = np.matrix(w) - bench_w\n    active_return = (active_weights * means.T)[0,0]\n    return active_return \n\ncons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n        {'type': 'eq', 'fun': lambda x: active_return(x)})\n\nbound = (0.05,0.40)\nbounds = tuple(bound for asset in range(alpha.shape[1]-1))\nbounds += ((0.0, 1e-10), ) # weight of the benchmark is fixed to zero\n\nres2 = minimize(tracking_error2, Weight_start, args=Sigma,\n                method='SLSQP', bounds=bounds, \n                constraints=cons,tol=1e-10, options={'disp': True})\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.00013298691074338728\n            Iterations: 39\n            Function evaluations: 468\n            Gradient evaluations: 39\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in res2.x],index=ex_returns.columns).T\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\nEuroStoxx 50\n\n\n\n\n0\n0.05\n0.05\n0.0902\n0.162\n0.05\n0.1178\n0.1001\n0.1916\n0.0627\n0.1257\n0.0\n\n\n\n\n\n\n\nDie gefundene Lösung genügt allen Nebenbedingungen und besitzt einen minimalen, geschätzten Tracking Error.\n\n\nCode\n# expected active return\nround(((np.matrix(res2.x)-bench_w)*means.T)[0,0], 4)\n\n\n-0.0\n\n\n\n\nCode\n# tracking error\ntracking_error2(res2.x, Sigma)\n\n\n0.00013298691074338728\n\n\nInsofern ist nunmehr die Frage interessant, wie dieses Tracking Portfolio im folgenden Validierungszeitraum abgeschnitten hätte. Um dies zu analysieren, berechnen wir auf Basis der optimierten Gewichte die realisierte aktive Rendite (Variable realized_act_ret) über den gesamten Zeitraum, und weisen dann separat für beide Zeiträume die Varianz und den Mittelwert von realized_act_ret aus.\n\n\nCode\n# calculation of realized TE and mean active return for \n# estimation and validation period\n\n# realized active return\nrealized_act_ret = ex_returns.multiply(res2.x).sum(axis=1)-ex_returns['EuroStoxx 50']\n\n# estimation period\nrealized_eTE = realized_act_ret.iloc[:60].var() # equals tracking_error2(res2.x, Sigma)\nrealized_eAR = realized_act_ret.iloc[:60].mean()\n\n# validation period\nrealized_vTE = realized_act_ret.iloc[60:].var() \nrealized_vAR = realized_act_ret.iloc[60:].mean() \n\n\n\n\nCode\nrealized_eTE\n\n\n0.00013298691074338696\n\n\n\n\nCode\nrealized_vTE\n\n\n0.0004602271724062247\n\n\n\n\nCode\nrealized_eAR\n\n\n-9.776323269446627e-16\n\n\n\n\nCode\nrealized_vAR\n\n\n0.005638212117542039\n\n\nDiskussion der Schätzproblematik\nDas eigentlich auf die Zukunft (hier repräsentiert durch den Validierungszeitraum) bezogene Tracking Portfolio hält gemäß der Schätzung im Schätzzeitraum die Nebenbedingung einer erwarteten aktiven Rendite von null ein und besitzt einen minimalen (geschätzten) Tracking Error. Im Validierungszeitraum wird dann aber tatsächlich die Nebenbedingung \\(\\mu_A=0\\) deutlich verletzt. Der ex post Tracking Error im Validierungszeitraum ist mehr als dreimal höher als nach seiner Schätzung.\nDiese Ergebnisse sollten allerdings nicht falsch interpretiert werden. Sie belegen weder die Untauglichkeit des Markowitz-Verfahrens noch die Unsinnigkeit des Index Tracking. Sie illustrieren lediglich die Schätzproblematik, die auch bei diesem Verfahren besteht und die gerade beim Index Tracking mit wenigen Assets (so wie in dieser Fallstudie) besonders in Erscheinung tritt. Je mehr Assets für die Aufnahme in das Tracking Portfolio zur Verfügung stehen und je enger dieses an der Benchmark orientiert ist, umso geringer wird die Bedeutung der Schätzproblematik.\n\n\n9.3.4 Regression unter Nebenbedingungen\nDie Zielfunktion besteht darin die Summe der quadrierten aktiven Renditen \\(r^2_{At}\\) über die vergangenen \\(T\\) Perioden zu minimieren, unter den üblichen Nebenbedingungen (Budgetrestriktion, Leerverkaufsverbot, Bestandsgrenzen).\n\\[ \\quad ZF(w)=\\Sigma^T_{t=1}r^2_{At}=\\Sigma^T_{t=1}(r_{Bt}-(w_{P1}r_{1t}+w_{P2}r_{2t}+...+w_{PN}r_{Nt}))^2 \\rightarrow \\min_{w}!\\ \\]\nZur Erinnerung: Der Vektor der aktiven Gewichte \\(w_A\\) ist definiert als Differenz der Portfolio- und Benchmarkgewichte, d.h. \\(w_A=w_P-w_B\\).\n\n\nCode\n# target function: minimize 'sum of squared active returns'!\n    \ndef tracking_error3(w, bench_w):\n    active_weights = np.asarray(np.matrix(w) - bench_w)\n    squared_act_ret = (ex_returns.multiply(active_weights).sum(axis=1))**2\n    sum_squares = sum(squared_act_ret[:60])\n    return sum_squares\n\ncons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n\nbound = (0.05,0.40)\nbounds = tuple(bound for asset in range(alpha.shape[1]-1))\nbounds += ((0.0, 1e-10), ) # weight of the benchmark is fixed to zero\n\nres3 = minimize(tracking_error3, Weight_start, args=bench_w,\n                method='SLSQP', bounds=bounds, \n                constraints=cons,tol=1e-10, options={'disp': True})\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.00761896940503493\n            Iterations: 18\n            Function evaluations: 217\n            Gradient evaluations: 18\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in res3.x], \\\n             index=ex_returns.columns, columns=['Weight']).T\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\nEuroStoxx 50\n\n\n\n\nWeight\n0.05\n0.05\n0.1175\n0.148\n0.05\n0.0887\n0.1127\n0.1881\n0.0516\n0.1435\n0.0\n\n\n\n\n\n\n\n\n\nCode\n# tracking error\ntracking_error2(res3.x, Sigma)\n\n\n0.00012866190903562024\n\n\nAuch hier ist ein Vergleich der Tracking Error im Schätz- und Validierungszeitraum aufschlussreich, um die Schätzproblematik zu illustrieren. Im Folgenden werden wieder die Werte für aktive Rendite und Tracking Error im Schätz- und Validierungszeitraum verglichen.\n\n\nCode\n# calculation of realized TE and mean active return for \n# estimation and validation period\n\n# realized active return\nrealized_act_ret = ex_returns.multiply(res3.x).sum(axis=1)-ex_returns['EuroStoxx 50']\n\n# estimation period\nrealized_eTE = realized_act_ret.iloc[:60].var() # equals tracking_error2(res3.x, Sigma)\nrealized_eAR = realized_act_ret.iloc[:60].mean()\n\n# validation period\nrealized_vTE = realized_act_ret.iloc[60:].var() \nrealized_vAR = realized_act_ret.iloc[60:].mean() \n\n\n\n\nCode\nrealized_eTE\n\n\n0.0001286619090356203\n\n\n\n\nCode\nrealized_vTE\n\n\n0.000391144336719732\n\n\nEin Vergleich der Lösungen für das Tracking Portfolio nach dem Markowitz-Verfahren und der Regression unter Nebenbedingungen ist ebenfalls interessant. Die Gegenüberstellung der ermittelten, optimalen Anteilsgewichte zeigt nur geringfügige Abweichungen. Entsprechend fallen die Werte beider Tracking Portfolios für aktive Rendite und Tracking Error sowohl in Schätz- als auch Validierungszeitraum sehr ähnlich aus. Diese Ähnlichkeit ist aber nicht überraschend, denn die theoretische Analyse zeigte ja bereits, dass unter der Nebenbedingung einer erwarteten aktiven Rendite von null die Minimierung des ex ante Tracking Error (Markowitz-Verfahren) äquivalent zur (ex ante) Minimierung des Erwartungswertes der quadrierten aktiven Rendite ist. Insofern müssten eigentlich sogar dieselben Lösungen resultieren. Die Abweichungen erklären sich mit den unterschiedlichen Schätzverfahren, die bei beiden Ansätzen Verwendung finden.\nTrotz der etwas aufwändigeren verfahrenstechnischen Umsetzung des Markowitz-Verfahrens ist dessen Vorteil die höhere Flexibilität, indem nämlich dort die Art der Schätzung der benötigten Inputparameter leicht gegen eine andere ausgetauscht werden kann, während bei diesem Verfahren letztendlich Optimierungsansatz und Schätzverfahren der benötigten Inputparameter untrennbar miteinander verbunden sind. Praktisch lässt sich aber der Vorteil des Markowitz-Verfahrens nur dann realisieren, wenn man wirklich über fortgeschrittenere Schätzverfahren als die hier exemplarisch verwendeten verfügt.\n\n\n9.3.5 Lineare Optimierung\nBei der Bestimmung eines Tracking Portfolios mittels der linearen Optimierung ist die Besonderheit zu beachten, dass der Vektor der zu optimierenden Problemvariablen aus drei Komponenten besteht: 1) dem Vektor der Anteilsgewichte der Einzeltitel und dem (auf null fixiertem) Gewicht der Benchmark, 2) dem Vektor der negativen Restfehler \\(d^-_t\\), und 3) dem Vektor der positiven Restfehler \\(d^+_t\\). Im Rahmen der Fallstudie hat der erste Vektor die Dimension \\(N=11\\) und die beiden anderen jeweils die Dimension \\(T=60\\) (Länge des Schätzzeitraums).\nWir starten mit der Festlegung der Startlösung. Wie üblich verwenden wir ein naives (gleich gewichtetes) Portfolio für die Anteilsgewichte (das letzte Gewicht ist auf null festgelegt für das Target Portfolio/Benchmark).\n\n\nCode\n# vector of starting weights is equally-weighted for the first N-1 \n# elements and zero for the last element\nmeans = ex_returns.iloc[:60,:].mean().values*100*12 # annualised?\nWeight_start = np.zeros(means.shape)\nWeight_start[0:-1]=1/(means.shape[0]-1)\n\n\nFür die Restfehler werden jeweils Startwerte von null verwendet.\n\n\nCode\nD_minus = np.zeros(ex_returns[:60].shape[0])\nD_plus = np.zeros(ex_returns[:60].shape[0])\n\n\nDann “verketten” wir die drei Arrays zum \\((N+2T)\\)-Array der Startwerte, welches wir params0 nennen.\n\n\nCode\n# starting values\nparams0 = np.concatenate([Weight_start, D_minus, D_plus])\n\n\nDie zu minimierende Zielfunktion besteht in der Summe aller negativen Restfehler \\(d^-_t\\). Diese Funktion wird mit tracking_error4 bezeichnet.\nBeachten Sie, dass gemäß der obigen Definition im Array der Problemvariablen die negativen Restfehler an der Stelle [11:71] stehen.\n\n\nCode\ndef tracking_error4(params):\n    sum_d_minus =np.sum(params[11:71])\n    return sum_d_minus\n\n\nDie verfahrenstechnische Schwierigkeit dieses Ansatzes besteht in der Implementierung der zentralen Nebenbedingung:\n\\[ \\quad (\\Sigma^N_{i=1} w_{Pi}r_{it}-d^+_t+d^-_t)-r_{Bt}=0 \\qquad \\text{für alle Zeitpunkte} \\space t=1, ..., T. \\]\nGemäß dieser Nebenbedingung muss für alle 60 Zeitpunkte \\(t\\) die Rendite des Tracking Portfolios abzüglich des positiven Restfehlers \\(d^+_t\\) und zuzüglich des negativen Restfehlers \\(d^-_t\\) derjenigen des Index entsprechen. Im Kern handelt es sich hier also um ein System von \\(T=60\\) strukturidentischen Nebenbedingungen.\nFür ein beliebiges \\(t=1, ..., 60\\) hat eine einzelne Nebenbedingung diese Struktur:\n\n\nCode\n# structure of constraint for a given t=1, ..., 60\nex_returns.iloc[t, :].multiply(params[:11]).sum()\\\n                - params[71+t] + params[11+t] - ex_returns['EuroStoxx 50'][t]\n\n\nWir implementieren dieses System von strukturidentischen Nebenbedingungen über die Funktion constraint_maker. Beachten Sie, dass für i=60 diese Funktion die (gleich null gesetzte) Budgetrestriktion liefert.\n\n\nCode\n# definition of constraints\ndef constraint_maker(i=0):  # i MUST be an optional keyword argument, else it will not work\n    def constraint(params):\n        if i &lt; 60:\n            return  ex_returns.iloc[i, :].multiply(params[:11]).sum()\\\n                - params[71+i] + params[11+i] - ex_returns['EuroStoxx 50'][i]\n        else:\n            return np.sum(params[:11]) - 1\n    return constraint\n\n\nJetzt schreiben wir alle 60 Nebenbedingungen plus die Budgetrestriktion in Form des bekannten Tuples von Dictionaries der Form {'type': 'eq', 'fun': constraint}. Wir starten mit einer leeren List c. Diese füllen wir indem über eine for-Schleife die constraint_maker Funktion für \\(i=1, ..., 61\\) ausgeführt wird und die Ergebnisse (zusammen mit dem Ausdruck 'type': 'eq', 'fun') jeweils der leeren Liste hinzugefügt werden. Abschließend wird die Liste in ein Tuple-Okjekt cons transformiert.\n\n\nCode\n# making tuple with constraint dictionaries\nc=[]\nfor i in range(61):\n    c+=[{'type': 'eq', 'fun': constraint_maker(i)}]\ncons=tuple(c)\n\n\nDie weiteren Nebenbedingungen, dass die Restfehler nicht negativ werden dürfen, implementieren wird analog zum Leerverkaufsverbot bzw. den Bestandsgrenzen für die Anteilsgewichte über das Tuple bounds, das nun aus 131 Elementen, die selbst jeweils wieder Tuple darstellen, besteht.\nNun sind wir bereit für die eigentliche Optimierung!\n\n\nCode\n# setting value constraints for optimizing parameters\nbound = (0.05,0.40) # bounds for portfolio weights\nbounds = tuple(bound for asset in range(means.shape[0]-1))\nbounds += ((0.0, 1e-10), ) # weight of the benchmark is fixed to zero\nbounds += ((0.0, 0.80), )*120 # bounds for D_minus and D_plus\n\nres4 = minimize(tracking_error4, params0,\n                method='SLSQP', bounds=bounds,\n                constraints=cons,tol=1e-10, options={'disp': True})\n\n\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: 0.22318419504788067\n            Iterations: 5\n            Function evaluations: 660\n            Gradient evaluations: 5\n\n\n\n\nCode\npd.DataFrame([round(x,4) for x in res4.x[:11]], \\\n             index=ex_returns.columns, columns=['Weight']).T\n\n\n\n\n\n\n\n\n\nDanone\nSiemens\nBASF\nL'Oreal\nAllianz\nTelecom Italia\nBanco Santander\nTotal\nBMW\nVivendi\nEuroStoxx 50\n\n\n\n\nWeight\n0.0649\n0.0889\n0.1527\n0.0561\n0.05\n0.05\n0.1256\n0.1853\n0.05\n0.1765\n0.0\n\n\n\n\n\n\n\nWie bei der theoretischen Analyse gezeigt, ist die Zielfunktion zur Ermittlung des Tracking Portfolios beim Markowitz-Ansatz und bei der Regression unter Nebenbedingungen weitgehend gleich, sodass unter gewissen Einschränkungen die Ergebnisse für beide Ansätz vergleichbar waren. Bei der linearen Optimierung zur Bestimmung des Tracking Portfolios wird dagegen eine völlig andere Zielfunktion optimiert. Insbesondere der klassische Tracking Error ist daher kein fairer Vergleichsmaßstab, denn er stellt im Wesentlichen die Zielfunktion der ersten beiden Verfahren dar, nicht aber diejenige bei diesem Ansatz. Hier ist die Zielfunktion die Minimierung der Summe aller Absolutbeträge der negativen Restfehler (Summe \\(d^-\\)). Der Vollständigkeit halber wird er aber hier ausgewiesen.\n\n\nCode\n# tracking error\ntracking_error2(res4.x[:11], Sigma)\n\n\n0.00014857682794648544\n\n\nWurde das System der 60 strukturidentischen Nebenbedingungen eingehalten?\n\n\nCode\n# the main 60 constraints\nex_returns.iloc[:60, :].multiply(res4.x[0:11]).sum(axis=1)\\\n        - res4.x[71:131] + res4.x[11:71] - ex_returns['EuroStoxx 50'][:60]\n\n\n2003-01-31    1.183900e-12\n2003-02-28    2.049055e-14\n2003-03-31   -6.702000e-13\n2003-04-30   -9.861556e-14\n2003-05-30    1.027078e-13\n2003-06-30   -6.996764e-13\n2003-07-31    6.922934e-14\n2003-08-29    5.060015e-14\n2003-09-30   -3.373968e-13\n2003-10-31   -1.550690e-12\n2003-11-28    1.321061e-13\n2003-12-31   -3.337955e-13\n2004-01-30    1.227837e-13\n2004-02-27   -8.496676e-14\n2004-03-31    4.060502e-13\n2004-04-30    4.743220e-13\n2004-05-31    1.754361e-13\n2004-06-30   -4.130515e-13\n2004-07-30    8.719622e-13\n2004-08-31   -3.744574e-14\n2004-09-30   -4.076114e-13\n2004-10-29    2.583246e-13\n2004-11-30   -9.510448e-14\n2004-12-31   -2.037641e-13\n2005-01-31   -1.333308e-14\n2005-02-28    2.735798e-13\n2005-03-31    5.278243e-14\n2005-04-29   -3.917699e-14\n2005-05-31   -8.158751e-14\n2005-06-30    3.692879e-13\n2005-07-29    3.459455e-13\n2005-08-31    2.535472e-14\n2005-09-30    2.005340e-13\n2005-10-31   -1.994654e-13\n2005-11-30    1.155673e-13\n2005-12-30    3.311240e-13\n2006-01-31   -8.300652e-14\n2006-02-28    4.661202e-14\n2006-03-31    8.990066e-13\n2006-04-28   -9.701875e-14\n2006-05-31   -8.119477e-13\n2006-06-30   -1.821416e-14\n2006-07-31   -5.789293e-14\n2006-08-31    3.755676e-13\n2006-09-29   -1.379487e-13\n2006-10-31    8.963386e-13\n2006-11-30    2.179160e-14\n2006-12-29   -8.252427e-14\n2007-01-31    3.724052e-13\n2007-02-28   -1.203759e-13\n2007-03-30   -1.878567e-13\n2007-04-30   -4.330286e-13\n2007-05-31    7.901735e-13\n2007-06-29   -2.810842e-13\n2007-07-31   -4.605621e-13\n2007-08-31   -3.289036e-15\n2007-09-28   -1.783400e-13\n2007-10-31    5.477181e-13\n2007-11-30   -3.118304e-13\n2007-12-31   -2.353708e-13\ndtype: float64\n\n\n\n\nCode\n# sum of D_plus\nsum(res4.x[71:131])\n\n\n0.3546793347396383\n\n\n\n\nCode\n# sum of D_minus\nsum(res4.x[11:71])\n\n\n0.22318419504788067\n\n\nNachfolgend stellen wir die Gütemaße für das Tracking Portfolio im Schätz- und Validierungszeitraum zusammen.\n\n\nCode\n# calculation of realized TE and mean active return for \n# estimation and validation period\n\n# realized active return\nrealized_act_ret = ex_returns.multiply(res4.x[:11]).sum(axis=1)-ex_returns['EuroStoxx 50']\n\n# estimation period\nrealized_eTE = realized_act_ret.iloc[:60].var() # equals tracking_error2(res2.x, Sigma)\nrealized_eAR = realized_act_ret.iloc[:60].mean()\n\n# validation period\nrealized_vTE = realized_act_ret.iloc[60:].var() \nrealized_vAR = realized_act_ret.iloc[60:].mean() \n\n\n\n\nCode\nrealized_eTE # estimation period\n\n\n0.00014857682794648528\n\n\n\n\nCode\nrealized_vTE # validation period\n\n\n0.0003251365659092278\n\n\n\n\nCode\nrealized_eAR\n\n\n0.0021915856615420536\n\n\n\n\nCode\nrealized_vAR\n\n\n0.006282117292094598\n\n\n\n\n9.3.6 Vergleich der Ansätze\n\n\nCode\npd.DataFrame({'Relative Opt.' :[round(x,4) for x in res1.x], \n             'Markowitz' : [round(x,4) for x in res2.x],\n              'Linear Reg.' : [round(x,4) for x in res3.x],\n              'Linear Opt.' : [round(x,4) for x in res4.x[:11]]},\n          index=ex_returns.columns)\n\n\n\n\n\n\n\n\n\nRelative Opt.\nMarkowitz\nLinear Reg.\nLinear Opt.\n\n\n\n\nDanone\n0.0500\n0.0500\n0.0500\n0.0649\n\n\nSiemens\n0.0500\n0.0500\n0.0500\n0.0889\n\n\nBASF\n0.0915\n0.0902\n0.1175\n0.1527\n\n\nL'Oreal\n0.1587\n0.1620\n0.1480\n0.0561\n\n\nAllianz\n0.0500\n0.0500\n0.0500\n0.0500\n\n\nTelecom Italia\n0.1203\n0.1178\n0.0887\n0.0500\n\n\nBanco Santander\n0.0987\n0.1001\n0.1127\n0.1256\n\n\nTotal\n0.1969\n0.1916\n0.1881\n0.1853\n\n\nBMW\n0.0585\n0.0627\n0.0516\n0.0500\n\n\nVivendi\n0.1254\n0.1257\n0.1435\n0.1765\n\n\nEuroStoxx 50\n0.0000\n0.0000\n0.0000\n0.0000\n\n\n\n\n\n\n\nObwohl streng genommen ein Vergleich des Tracking Portfolios nach dem Ansatz der linearen Optimierung mit denjenigen der vorhergehenden Ansätze nicht zulässig ist, fallen schlussendlich die Ergebnisse nicht weit auseinander. Die resultierenden Strukturen der Tracking Portfolios sind in gewissen Grenzen doch sehr ähnlich, weshalb auch die Gütemaße im Validierungszeitraum nicht dramatisch voneinander abweichen. Die Erklärung für diese vielleicht etwas überraschende Ähnlichkeit ist aber nicht weiter schwierig. Die beiden vorhergehenden Ansätze (Markowitz-Ansatz, Regression unter Nebenbedingungen) basieren im Grunde auf einer Minimierung des quadratischen Fehlers (aktive Rendite) zwischen der Rendite des Tracking Portfolios und der Benchmark. Die lineare Optimierung minimiert die Summe der (Absolutbeträge der) negativen Fehler. Wenn nun im Schätzzeitraum die beobachteten Renditefehler annähernd symmetrisch um den Nullpunkt verteilt sind und keine gravierenden Ausreißer auftreten, ist die Zielfunktion nach der linearen Optimierung nur in etwa (abgesehen von der Quadrierung der Fehlerterme) anders skaliert als diejenige der ersten beiden Ansätze, was aber dann kaum Auswirkungen auf die Lage des Optimums hat. In diesem Fall resultieren in allen drei Fällen recht ähnliche Strukturen für das Tracking Portfolio.\n\n\nCode\nfrom matplotlib.pyplot import *\nfig, ax = subplots()\ndf = pd.DataFrame({'Relative Opt.' :[round(x,4) for x in res1.x], \n             'Markowitz' : [round(x,4) for x in res2.x],\n              'Linear Reg.' : [round(x,4) for x in res3.x],\n              'Linear Opt.' : [round(x,4) for x in res4.x[:11]]},\n          index=ex_returns.columns).T\ndf.plot(kind='bar',stacked=True, ax=ax, figsize=(10,5))\nax.legend(loc=10);\n\n\n\n\n\n\n\n\n\n\n\nCode\npd.DataFrame({'Relative Opt.' :[round(x,4) for x in res1.x], \n             'Markowitz' : [round(x,4) for x in res2.x],\n              'Linear Reg.' : [round(x,4) for x in res3.x],\n              'Linear Opt.' : [round(x,4) for x in res4.x[:11]]},\n          index=ex_returns.columns).T.plot.barh(stacked=True,\n                                                alpha=.6, figsize=(10,5));",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Index Tracking</span>"
    ]
  },
  {
    "objectID": "kapitel8a.html#lernvideos",
    "href": "kapitel8a.html#lernvideos",
    "title": "9  Index Tracking",
    "section": "9.4 Lernvideos",
    "text": "9.4 Lernvideos\n\n9.4.1 Video Teil 1\n\n\n\n9.4.2 Video Teil 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Index Tracking</span>"
    ]
  },
  {
    "objectID": "projekt.html",
    "href": "projekt.html",
    "title": "10  Abschlußprojekt",
    "section": "",
    "text": "10.1 Allgemeine Informationen\nBonus: Durch die Bearbeitung und Abgabe eines Abschlußprojektes erhalten Sie ein Teilnahmezertifikat für den Webkurs “Grundlagen des quantitativen Portfoliomanagements mit Python”. Dieses Zertifikat wird ausgestellt durch den Lehrstuhl für Banken und Finanzierung (Univ.-Prof. Dr. Thomas Mählmann) der Katholischen Universität Eichstätt-Ingolstadt.\nWas müssen Sie tun, um das Zertifikat zu erhalten?\nGanz einfach, wählen Sie eines der folgenden Themen zu den Kapiteln des Buches aus und bearbeiten Sie die Aufgabenstellung in Form eines Jupyter Notebooks. Reichen Sie dieses Notebook dann per Mail an thomas.maehlmann@ku.de ein, das wär’s!.\nBeachten Sie auch die folgenden Hinweise:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Abschlußprojekt</span>"
    ]
  },
  {
    "objectID": "projekt.html#allgemeine-informationen",
    "href": "projekt.html#allgemeine-informationen",
    "title": "10  Abschlußprojekt",
    "section": "",
    "text": "Kommentieren Sie Ihren Code im Notebook!\nGehen Sie auf den zentralen theoretisch-/konzeptionellen Hintergrund, der für Ihr Thema wichtig ist, ein!\nErläutern/interpretieren und gegebenenfalls visualisieren Sie Ihre Ergebnisse!\nBegründen Sie die von Ihnen vorgenommene Auswahl der Datenbasis bzw. des Analysesettings!\nMachen Sie sich keine Sorgen, es wird keine perfekte Bearbeitung des Themas erwartet, zeigen Sie einfach, was Sie durch das Studium des Webbuchs gelernt haben!\nViel Erfolg!",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Abschlußprojekt</span>"
    ]
  },
  {
    "objectID": "projekt.html#themen-für-das-abschlußprojekt",
    "href": "projekt.html#themen-für-das-abschlußprojekt",
    "title": "10  Abschlußprojekt",
    "section": "10.2 Themen für das Abschlußprojekt",
    "text": "10.2 Themen für das Abschlußprojekt\n\n10.2.1 Thema 1: Strategische Assetklassenallokation\n\nDefinieren Sie relevante Assetklassen (z.B. Aktien, (Staats- oder Unternehmens-) Anleihen, Währungen, Commodities, Loans, Private Equity, etc.) für einen fiktiven institutionellen Kunden (z.B. einen Pensionsfond);\nSuchen Sie (z.B. aus Yahoo Finance) geeignete Indexzeitreihen für die ausgewählten Assetklassen; Verwenden Sie die historischen Total Returns der Indizes; Alternativ: Simulieren Sie die Zeitreihen auf Basis geeigneter Verteilungsannahmen;\nBestimmen Sie die optimale Portfolioallkation über die Assetklassen (statisch und dynamisch);\nVerwenden Sie die absolute Optimierung (z.B. Maximum Sharpe Portfolio); Wie sehen die Effizienzkurven aus?\nWelchen Einfluss haben Restriktionen auf die Allokationen?\nAdd-on: Führen Sie die relative Optimierung gegen eine geeignete Benchmark durch; Welche weiteren Restriktionen könnten in der Praxis relevant sein? Können Sie sie implementieren?\n\n\n\n10.2.2 Thema 2: Schätzung erwarteter Renditen\n\nFühren Sie eine Simulationsstudie zum Vergleich der Qualität von geschrumpften Schätzern und dem arithmetischen Mittelwert durch;\nVerwenden Sie die N-variate Normalverteilung für die simulierten Renditen;\nWie hängt der Vergleich ab von k (Zeitreihenlänge), N (Anzahl Assets), und weiteren Größen (z.B. der Renditekorrelationen)?\nErklären/Interpretieren und visualisieren Sie Ihre Ergebnisse!\nAdd-on: Ziehen Sie Renditerealisationen aus einer anderen parametrischen Verteilung (z.B. der t-Verteilung um fat tails zu modellieren);\n\n\n\n10.2.3 Thema 3: Portfoliomanagerskill\n\nUntersuchen Sie den Einfluss der Renditeprognosequalität des Portfoliomanagers auf die Portfolioperformance am Beispiel des BL-Modells;\nFühren Sie einen rollierenden Backtest der Portfolioperformance für Manager unterschiedlicher Qualität durch;\nHalten Sie das Referenzportfolio (implizite Renditen) und die Managerprognosen konstant und variieren nur die Prognosequalität (d.h., die Varianz der Prognosefehler: \\(Ω_{kk}\\));\nAdd-on: Performancebacktest eines „aktiven“ (τ →1) vs. „passiven“ (τ →0) Managers;\nHinweis zum rollierenden Portfoliobacktest:\n\nPortfoliogewichte bestimmen mit historischen Daten bis t;\nPortfolio halten bis t+1;\nneue Portfoliogewichte bestimmen mit Daten bis t+1;\nPortfolio halten bis t+2, usw.\n\n\n\n\n10.2.4 Thema 4: Performance “Horce Race”\n\nIn out-of-sample Tests erweisen sich \\(μ-σ\\) optimierte Portfolios nicht zwangsläufig überlegen gegenüber einfachen Ansätzen der Portfoliokonstruktion;\nFühren Sie einen Backtest des MVP, des Max. Sharpe und eines „naiven“ (gleichgewichteten) Portfolios durch;\nVerwenden Sie als Testassets die Monatsrenditen der 10 (30 oder 49) Industrieportfolios auf der Seite von K. French (Kenneth R. French - Data Library (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html));\nAdd-on: Verwenden Sie verschiedene risikoadjustierte Maße zur Performancemessung: Sharpe Ratio, CAPM-Alpha, FF3-Alpha, etc.;\n\n\n\n10.2.5 Thema 5: dynamische risikogesteuerte Ansätze\n\nRisikogesteuerte Ansätze zur Portfoliokonstruktion fokussieren auf das Renditerisiko und vernachlässigen erwartete Renditen.\nIn diesem Thema sollen die optimalen Gewichte der klassischen fünf risikogesteuerten Ansätze (ERB, ERC, MD, EW, GMVP) über die Zeit (d.h., dynamisch) für ein gegebenes Anlageuniversum ermittelt werden. Verwenden Sie eine möglichst lange Renditezeitreihe für die Assets des Universums. Ermitteln Sie die optimalen Gewichte rollierend, z.B. jeden Monat oder jedes Quartal neu.\nVerwenden Sie als Anlageuniversum z.B. unterschiedliche (Aktien-) Indizes, die French-Industrieportfolios oder eine Auswahl einzelner Aktien mit langer Datenhistorie.\nWas stellen Sie fest hinsichtlich der Unterschiede in den Gewichten zwischen den Ansätzen über die Zeit? Gibt es bestimmte Perioden in denen Unterschiede besonders groß oder klein sind? Wie sieht es mit dem realisierten Risiko der Portfolios aus? Halten die Ansätze was sie versprechen?\n\n\n\n10.2.6 Thema 6: Index Tracking während Krisenzeiten\n\nEin oft in der Praxis verwendetes Argument für aktives Management ist die behauptete bessere Performance von Aktiv vs. Passiv in Zeiten, wenn der Markt fällt (Krise).\nIm Rahmen dieses Themas gilt es zu untersuchen, wie gut Index Tracking überhaupt in Krisenzeiten funktioniert? D.h. konkret, wie verhält sich der realisierte Tracking Error in der Krise (=Validierungszeitraum), wenn der Schätzzeitraum eine Nicht-Krisen Periode darstellt?\nAufgabe: Replizieren Sie den DAX30/40 mit so wenig Einzelaktien wie Ihnen sinnvoll erscheint (hinsichtlich eines für den Kunden noch akzeptablen Tracking Errors). Wie verhält sich der realisierte Tracking Error z.B. während der Finanzkrise oder der COVID-19 Krise? Schätzen Sie die Gewichte mit Nicht-Krisen Daten!\nAdd-on: Interessant wäre es natürlich auch zu untersuchen, wie gut eine quantitative Portfoliokonstruktion überhaupt in Krisenzeiten funktioniert, wenn Schätzungen, Modellparametrisierungen etc. auf Nicht-Krisen Daten basieren.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Abschlußprojekt</span>"
    ]
  }
]